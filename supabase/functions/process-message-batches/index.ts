import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.50.0';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// Servidor Supabase
const supabase = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
);

Deno.serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  // Extrair informa√ß√µes do trigger
  let triggerInfo = { type: 'unknown', chatId: null };
  try {
    const body = await req.text();
    if (body) {
      const data = JSON.parse(body);
      triggerInfo = {
        type: data.trigger || 'unknown',
        chatId: data.chatId || null
      };
    }
  } catch (e) {
    // Ignore parsing errors for trigger info
  }

  console.log('ü§ñ [PROCESS-BATCHES] Verificando batches pendentes...', {
    trigger: triggerInfo.type,
    chatId: triggerInfo.chatId?.substring(0, 20),
    timestamp: new Date().toISOString()
  });

  try {
    const processingId = `${triggerInfo.type}_${Date.now()}`;
    
    // üß† TIMING INTELIGENTE POR TIPO DE M√çDIA
    let cutoffTime: string;
    const lockTimeout = new Date(Date.now() - 30000).toISOString(); // 30 segundos para timeout
    
    // Verificar tipo de conte√∫do nos batches para determinar timeout
    const { data: batchPreview } = await supabase
      .from('message_batches')
      .select('id, messages, created_at')
      .order('created_at', { ascending: true })
      .limit(5);
    
    let adaptiveTimeout = 3000; // Padr√£o: 3s para texto
    
    if (batchPreview && batchPreview.length > 0) {
      for (const batch of batchPreview) {
        const messages = batch.messages || [];
        const hasAudio = messages.some((msg: any) => 
          (msg.content && typeof msg.content === 'string' && msg.content.includes('üéµ √Åudio')) || msg.messageType === 'audio'
        );
        const hasImage = messages.some((msg: any) => 
          (msg.content && typeof msg.content === 'string' && msg.content.includes('üì∑ Imagem')) || msg.messageType === 'image'
        );
        const hasMixed = hasAudio && hasImage;
        const hasText = messages.some((msg: any) => 
          msg.content && typeof msg.content === 'string' && !msg.content.includes('üéµ √Åudio') && !msg.content.includes('üì∑ Imagem')
        );
        
        if (hasMixed) {
          adaptiveTimeout = Math.max(adaptiveTimeout, 10000); // 10s para misto
        } else if (hasAudio || hasImage) {
          adaptiveTimeout = Math.max(adaptiveTimeout, 8000); // 8s para m√≠dia
        } else if (hasText) {
          adaptiveTimeout = Math.max(adaptiveTimeout, 3000); // 3s para texto
        }
      }
    }
    
    cutoffTime = new Date(Date.now() - adaptiveTimeout).toISOString();
    
    console.log('üß† [ADAPTIVE-TIMING] Timeout calculado:', {
      adaptiveTimeout: `${adaptiveTimeout}ms`,
      tipo: adaptiveTimeout === 10000 ? 'misto (10s)' : adaptiveTimeout === 8000 ? 'm√≠dia (8s)' : 'texto (3s)'
    });
    
    // BUSCAR BATCHES DISPON√çVEIS (n√£o processados E n√£o em processamento)
    const { data: pendingBatches, error } = await supabase
      .from('message_batches')
      .select('*')
      .lt('last_updated', cutoffTime)
      .or(`processing_started_at.is.null,processing_started_at.lt.${lockTimeout}`)
      .order('created_at', { ascending: true })
      .limit(3);

    if (error) {
      console.error('ü§ñ [PROCESS-BATCHES] ‚ùå Erro ao buscar batches:', error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    console.log('ü§ñ [PROCESS-BATCHES] üì¶ Encontrados', pendingBatches?.length || 0, 'batches pendentes');

    if (!pendingBatches || pendingBatches.length === 0) {
      return new Response(JSON.stringify({ 
        success: true, 
        message: 'Nenhum batch pendente',
        processed: 0 
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    // üéµ CORRE√á√ÉO: Aguardar 500ms para garantir que dados de m√≠dia/√°udio estejam salvos
    console.log('üéµ [AUDIO-FIX] ‚è≥ Aguardando 500ms para garantir dados de m√≠dia salvos...');
    await new Promise(resolve => setTimeout(resolve, 500));

    // BLOQUEAR BATCHES PARA PROCESSAMENTO (evitar duplica√ß√£o)
    const batchIds = pendingBatches.map(b => b.id);
    const { data: lockedBatches, error: lockError } = await supabase
      .from('message_batches')
      .update({
        processing_started_at: new Date().toISOString(),
        processing_by: processingId
      })
      .in('id', batchIds)
      .is('processing_started_at', null)
      .select('id');

    if (lockError) {
      console.error('ü§ñ [PROCESS-BATCHES] ‚ùå Erro ao bloquear batches:', lockError);
      return new Response(JSON.stringify({ error: lockError.message }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    const lockedBatchIds = lockedBatches?.map(b => b.id) || [];
    const batchesToProcess = pendingBatches.filter(b => lockedBatchIds.includes(b.id));
    
    console.log('ü§ñ [PROCESS-BATCHES] üîí Bloqueados', lockedBatchIds.length, 'de', batchIds.length, 'batches para processamento');

    if (batchesToProcess.length === 0) {
      return new Response(JSON.stringify({ 
        success: true, 
        message: 'Nenhum batch dispon√≠vel para processamento (j√° sendo processados)',
        processed: 0 
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    let processedCount = 0;
    
    console.log('ü§ñ [PROCESS-BATCHES] üöÄ Processando', batchesToProcess.length, 'batches em paralelo');
    
    const batchPromises = batchesToProcess.map(async (batch) => {
      console.log('ü§ñ [PROCESS-BATCHES] üöÄ Processando batch:', batch.id, 'com', batch.messages?.length || 0, 'mensagens');
      
      try {
        await processBatch(batch);
        return { success: true, batchId: batch.id };
      } catch (error) {
        console.error('ü§ñ [PROCESS-BATCHES] ‚ùå Erro ao processar batch:', batch.id, error);
        return { success: false, batchId: batch.id, error: error.message };
      }
    });
    
    const results = await Promise.allSettled(batchPromises);
    processedCount = results.filter(result => 
      result.status === 'fulfilled' && result.value.success
    ).length;

    return new Response(JSON.stringify({ 
      success: true,
      processed: processedCount,
      total: pendingBatches.length
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });

  } catch (error) {
    console.error('ü§ñ [PROCESS-BATCHES] ‚ùå Erro geral:', error);
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' }
    });
  }
});

/**
 * PROCESSAR UM BATCH ESPEC√çFICO
 */
async function processBatch(batch: any) {
  console.log('ü§ñ [PROCESS-BATCH] Processando batch:', batch.id);

  try {
    const messages = batch.messages || [];
    
    // üîç DETECTAR COMANDOS DE M√çDIA RELACIONADA NO BATCH
    const detectsFutureMedia = (content: string): boolean => {
      if (!content || typeof content !== 'string') return false;
      
      const futureMediaPatterns = [
        /vou.*enviar.*imagem/i,
        /vou.*mandar.*imagem/i,
        /analise.*imagem.*que.*vou/i,
        /olha.*imagem.*que.*vou/i,
        /v√™.*imagem.*que.*vou/i,
        /mando.*imagem/i,
        /envio.*imagem/i,
        /te.*mando/i,
        /te.*envio/i,
        /pr√≥xima.*imagem/i,
        /agora.*imagem/i,
        /depois.*imagem/i
      ];
      
      return futureMediaPatterns.some(pattern => pattern.test(content));
    };

    // üéµ DETEC√á√ÉO MELHORADA DE MENSAGENS DE √ÅUDIO
    const audioMessages = messages.filter((msg: any) => {
      if (msg.messageType === 'audio') return true;
      if (typeof msg.content === 'string' && msg.content.includes('üéµ √Åudio')) return true;
      if (typeof msg.content === 'object' && msg.content?.mimetype?.startsWith('audio/')) return true;
      return false;
    });

    // üñºÔ∏è DETEC√á√ÉO MELHORADA DE MENSAGENS DE IMAGEM
    const imageMessages = messages.filter((msg: any) => {
      if (msg.messageType === 'image') return true;
      if (typeof msg.content === 'string' && msg.content.includes('üì∑ Imagem')) return true;
      if (typeof msg.content === 'object' && msg.content?.mimetype?.startsWith('image/')) return true;
      return false;
    });

    // üìÑ DETEC√á√ÉO DE DOCUMENTOS
    const documentMessages = messages.filter((msg: any) => {
      if (msg.messageType === 'document') return true;
      if (typeof msg.content === 'object' && (msg.content?.fileName || msg.content?.title)) return true;
      if (typeof msg.content === 'object' && msg.content?.mimetype === 'application/pdf') return true;
      return false;
    });

    // üîó VERIFICAR SE H√Å COMANDOS QUE REFERENCIAM M√çDIA FUTURA
    const mediaCommandMessages = messages.filter((msg: any) => {
      const content = typeof msg.content === 'string' ? msg.content : '';
      return detectsFutureMedia(content);
    });

    // üìä LOG DO CONTEXTO DO BATCH
    console.log('üîç [BATCH-CONTEXT] An√°lise do batch:', {
      totalMessages: messages.length,
      audioCount: audioMessages.length,
      imageCount: imageMessages.length,
      documentCount: documentMessages.length,
      mediaCommandCount: mediaCommandMessages.length,
      hasRelatedMedia: mediaCommandMessages.length > 0 && (audioMessages.length > 0 || imageMessages.length > 0)
    });

    if (audioMessages.length > 0) {
      console.log('üéµ [AUDIO-FIX] üîç Detectados', audioMessages.length, '√°udios no batch');
    }

    if (imageMessages.length > 0) {
      console.log('üñºÔ∏è [IMAGE-FIX] üîç Detectados', imageMessages.length, 'imagens no batch');
      
      // Verificar se dados de imagem est√£o dispon√≠veis no banco E em ticket_messages
      for (const imageMsg of imageMessages) {
        console.log('üñºÔ∏è [IMAGE-FIX] üîç Verificando dados de imagem para messageId:', imageMsg.messageId);
        
        // Verificar dados na tabela ticket_messages (para imagens, focamos no image_base64)
        const { data: ticketData } = await supabase
          .from('ticket_messages')
          .select('message_id, image_base64, media_url, media_key, message_type, processing_status')
          .eq('message_id', imageMsg.messageId)
          .single();
        
        console.log('üñºÔ∏è [IMAGE-VERIFICATION] üìä STATUS DOS DADOS:', {
          messageId: imageMsg.messageId,
          ticketMessages: ticketData ? {
            hasImageBase64: !!ticketData.image_base64,
            hasMediaUrl: !!ticketData.media_url,
            hasMediaKey: !!ticketData.media_key,
            messageType: ticketData.message_type,
            processingStatus: ticketData.processing_status
          } : 'N√ÉO ENCONTRADO'
        });

        // ‚úÖ VERIFICAR SE IMAGE_BASE64 EST√Å DISPON√çVEL
        if (!ticketData || !ticketData.image_base64) {
          console.log('‚ö†Ô∏è [IMAGE-VERIFICATION] ‚ö†Ô∏è image_base64 n√£o encontrado, aguardando processamento:', imageMsg.messageId);
          
          // Aguardar tempo para processamento da imagem
          console.log('üñºÔ∏è [IMAGE-VERIFICATION] ‚è≥ Aguardando processamento de imagem...');
          await new Promise(resolve => setTimeout(resolve, 3000));
          
          // Verificar novamente ap√≥s aguardar
          const { data: updatedTicketData } = await supabase
            .from('ticket_messages')
            .select('message_id, image_base64')
            .eq('message_id', imageMsg.messageId)
            .single();
          
          if (updatedTicketData?.image_base64) {
            console.log('‚úÖ [IMAGE-VERIFICATION] ‚úÖ image_base64 dispon√≠vel ap√≥s aguardar:', imageMsg.messageId);
          } else {
            console.log('‚ùå [IMAGE-VERIFICATION] ‚ùå image_base64 ainda n√£o dispon√≠vel:', imageMsg.messageId);
          }
        } else {
          console.log('‚úÖ [IMAGE-VERIFICATION] ‚úÖ image_base64 j√° dispon√≠vel:', imageMsg.messageId);
        }
      }
    }

    // Processar √°udios se houver
    if (audioMessages.length > 0) {
      // Verificar se dados de √°udio est√£o dispon√≠veis no banco E em ticket_messages
      for (const audioMsg of audioMessages) {
        console.log('üéµ [AUDIO-FIX] üîç Verificando dados de √°udio para messageId:', audioMsg.messageId);
        
        // Verificar dados na tabela whatsapp_messages (fonte prim√°ria)
        const { data: whatsappData } = await supabase
          .from('whatsapp_messages')
          .select('message_id, media_url, media_key, file_enc_sha256, message_type, created_at')
          .eq('message_id', audioMsg.messageId)
          .single();
        
        // Verificar dados na tabela ticket_messages
        const { data: ticketData } = await supabase
          .from('ticket_messages')
          .select('message_id, media_url, media_key, file_enc_sha256, message_type, processing_status')
          .eq('message_id', audioMsg.messageId)
          .single();
        
        console.log('üéµ [AUDIO-VERIFICATION] üìä STATUS DOS DADOS:', {
          messageId: audioMsg.messageId,
          whatsappMessages: whatsappData ? {
            hasMediaUrl: !!whatsappData.media_url,
            hasMediaKey: !!whatsappData.media_key,
            hasFileEncSha256: !!whatsappData.file_enc_sha256,
            messageType: whatsappData.message_type
          } : 'N√ÉO ENCONTRADO',
          ticketMessages: ticketData ? {
            hasMediaUrl: !!ticketData.media_url,
            hasMediaKey: !!ticketData.media_key,
            hasFileEncSha256: !!ticketData.file_enc_sha256,
            messageType: ticketData.message_type,
            processingStatus: ticketData.processing_status
          } : 'N√ÉO ENCONTRADO'
        });

        // üéØ SINCRONIZA√á√ÉO AUTOM√ÅTICA: Garantir dados em ticket_messages
        if (whatsappData && whatsappData.media_url && whatsappData.media_key) {
          if (!ticketData || !ticketData.media_url || !ticketData.media_key) {
            console.log('üîß [AUDIO-VERIFICATION] üöÄ SINCRONIZANDO dados para ticket_messages...');
            
            const { error: syncError } = await supabase
              .from('ticket_messages')
              .update({
                media_url: whatsappData.media_url,
                media_key: whatsappData.media_key,
                file_enc_sha256: whatsappData.file_enc_sha256,
                processing_status: 'received'
              })
              .eq('message_id', audioMsg.messageId);
            
            if (!syncError) {
              console.log('‚úÖ [AUDIO-VERIFICATION] üéØ Dados sincronizados com sucesso:', audioMsg.messageId);
            } else {
              console.error('‚ùå [AUDIO-VERIFICATION] Erro ao sincronizar:', audioMsg.messageId, syncError);
            }
          } else {
            console.log('‚úÖ [AUDIO-VERIFICATION] ‚úÖ Dados j√° sincronizados:', audioMsg.messageId);
          }
        } else {
          console.log('‚ö†Ô∏è [AUDIO-VERIFICATION] ‚ö†Ô∏è Dados de √°udio n√£o encontrados:', audioMsg.messageId);
          
          // Aguardar mais tempo para dados de m√≠dia
          console.log('üéµ [AUDIO-VERIFICATION] ‚è≥ Aguardando mais tempo para dados de m√≠dia...');
          await new Promise(resolve => setTimeout(resolve, 2000));
        }
      }
    }

    // BUSCAR TICKET
    const { data: ticketData } = await supabase
      .from('conversation_tickets')
      .select('*')
      .eq('chat_id', batch.chat_id)
      .eq('client_id', batch.client_id)
      .order('created_at', { ascending: false })
      .limit(1)
      .single();

    let ticket = ticketData;

    if (!ticket) {
      console.log('ü§ñ [PROCESS-BATCH] ‚ùå Ticket n√£o encontrado - CRIANDO NOVO TICKET');
      
      // CRIAR TICKET ANTES DE PROCESSAR
      const newTicket = await createTicketFromBatch(batch);
      if (!newTicket) {
        console.error('ü§ñ [PROCESS-BATCH] ‚ùå Falha ao criar ticket');
        await deleteBatch(batch.id);
        return;
      }
      
      // Usar o ticket rec√©m-criado
      ticket = newTicket;
    }

    // üéØ PROCESSAMENTO UNIFICADO: DESCRIPTOGRAFIA + AN√ÅLISE + TRANSCRI√á√ÉO DENTRO DO BATCH
    console.log('üîÑ [UNIFIED-PROCESSING] Iniciando processamento unificado de m√≠dias no batch');
    
    // PROCESSAR DESCRIPTOGRAFIA DE M√çDIAS PRIMEIRO
    await processMediaDecryption(batch, audioMessages, imageMessages);
    
    // PROCESSAR AN√ÅLISE E TRANSCRI√á√ÉO DE M√çDIAS
    await processMediaAnalysis(batch, audioMessages, imageMessages);
    
    // üìù PREPARAR MENSAGENS PARA IA (SIMPLIFICADO - SEM AGUARDAR TRANSCRI√á√ÉO)
    console.log('üìù [PROCESS-BATCH] Mensagens do batch (com transcri√ß√µes):', JSON.stringify(messages, null, 2));
    
    // ‚úÖ L√ìGICA SIMPLIFICADA: Batches agora s√≥ s√£o criados AP√ìS transcri√ß√£o, ent√£o processar diretamente
    const processedMessages = messages.map((msg: any) => {
      console.log('‚úÖ [SIMPLIFIED-PROCESSING] Processando mensagem j√° transcrita:', msg.messageId);
      return msg;
    });

    // üé• DETECTAR COMANDOS DE V√çDEO NO BATCH
    const hasVideoCommands = processedMessages.some((msg: any) => {
      const content = msg.content || '';
      const isVideoCommand = /^video\s+([a-zA-Z0-9_-]+)$/i.test(content.trim());
      console.log('üé• [PROCESS-BATCH] Verificando comando de v√≠deo:', {
        content: content,
        isVideoCommand: isVideoCommand,
        messageId: msg.messageId
      });
      return isVideoCommand;
    });

    console.log('üé• [PROCESS-BATCH] Comandos de v√≠deo detectados no batch:', hasVideoCommands);

    // üîó PROCESSAMENTO CONTEXTUAL INTELIGENTE
    let contextualMessage = '';
    
    // Se h√° comandos de m√≠dia relacionada, criar contexto combinado
    if (mediaCommandMessages.length > 0 && (audioMessages.length > 0 || imageMessages.length > 0)) {
      console.log('üîó [CONTEXTUAL-PROCESSING] Criando contexto combinado para m√≠dia relacionada');
      
      // Combinar comandos de √°udio com imagens subsequentes
      contextualMessage = processedMessages.map(msg => {
        if (msg.content && detectsFutureMedia(msg.content)) {
          return msg.content + ' [Este comando refere-se √† m√≠dia seguinte]';
        }
        return msg.content || (msg.messageType === 'image' ? 'üì∑ Imagem' : 'üéµ √Åudio');
      }).join(' ');
      
      console.log('üîó [CONTEXTUAL-PROCESSING] Contexto combinado criado:', {
        hasCommands: mediaCommandMessages.length > 0,
        hasAudio: audioMessages.length > 0,
        hasImage: imageMessages.length > 0,
        contextLength: contextualMessage.length
      });
    } else {
      // Processamento normal
      contextualMessage = processedMessages.map(msg => msg.content || '').join(' ');
    }

    // CHAMAR IA COM BATCH (usando mensagens com transcri√ß√£o)
    console.log('ü§ñ [PROCESS-BATCH] üß† Chamando IA para ticket:', ticket.id, 'com', processedMessages?.length || 0, 'mensagens');
    console.log('ü§ñ [PROCESS-BATCH] üìÑ Mensagens do batch (com transcri√ß√µes):', JSON.stringify(processedMessages, null, 2));
    
    const aiResponse = await supabase.functions.invoke('ai-assistant-process', {
      body: {
        ticketId: ticket.id,
        messages: processedMessages, // Usar mensagens com transcri√ß√£o
        context: {
          chatId: batch.chat_id,
          customerName: processedMessages[0]?.customerName || 'Cliente',
          phoneNumber: processedMessages[0]?.phoneNumber || '',
          batchInfo: `Batch de ${processedMessages.length} mensagens (${processedMessages.filter(m => m.isTranscribed).length} transcritas)`,
          hasRelatedMedia: mediaCommandMessages.length > 0 && (audioMessages.length > 0 || imageMessages.length > 0),
          contextualMessage: contextualMessage
        }
      }
    });

    console.log('ü§ñ [PROCESS-BATCH] üéØ Resultado da IA:', { 
      success: !aiResponse.error, 
      hasError: !!aiResponse.error,
      errorMsg: aiResponse.error?.message 
    });

    if (!aiResponse.error) {
      console.log('ü§ñ [PROCESS-BATCH] ‚úÖ IA processou com SUCESSO!');
      
      // MARCAR MENSAGENS COMO PROCESSADAS
      await markMessagesAsProcessed(batch.messages);
    }

    // REMOVER BATCH PROCESSADO
    await deleteBatch(batch.id);

  } catch (error) {
    console.error('ü§ñ [PROCESS-BATCH] ‚ùå Erro ao processar batch:', error);
    await deleteBatch(batch.id);
    throw error;
  }
}

/**
 * MARCAR MENSAGENS COMO PROCESSADAS (OTIMIZADO)
 */
async function markMessagesAsProcessed(messages: any[]) {
  const messageIds = messages.map(msg => msg.messageId).filter(Boolean);
  
  if (messageIds.length === 0) return;

  // Verificar quais j√° est√£o processadas para evitar updates desnecess√°rios
  const { data: alreadyProcessed } = await supabase
    .from('whatsapp_messages')
    .select('message_id')
    .in('message_id', messageIds)
    .eq('is_processed', true);

  const alreadyProcessedIds = new Set(alreadyProcessed?.map(m => m.message_id) || []);
  const toProcess = messageIds.filter(id => !alreadyProcessedIds.has(id));

  if (toProcess.length === 0) {
    console.log('ü§ñ [MARK-PROCESSED] ‚ÑπÔ∏è Todas as mensagens j√° est√£o processadas');
    return;
  }

  const { error } = await supabase
    .from('whatsapp_messages')
    .update({ 
      is_processed: true,
      processed_at: new Date().toISOString()
    })
    .in('message_id', toProcess);

  if (error) {
    console.error('ü§ñ [MARK-PROCESSED] ‚ùå Erro ao marcar mensagens:', error);
  } else {
    console.log(`ü§ñ [MARK-PROCESSED] ‚úÖ Marcadas ${toProcess.length} mensagens como processadas (${alreadyProcessedIds.size} j√° estavam processadas)`);
  }
}

/**
 * DELETAR BATCH PROCESSADO
 */
async function deleteBatch(batchId: string) {
  const { error } = await supabase
    .from('message_batches')
    .delete()
    .eq('id', batchId);

  if (error) {
    console.error('ü§ñ [DELETE-BATCH] ‚ùå Erro ao deletar batch:', error);
  } else {
    console.log('ü§ñ [DELETE-BATCH] ‚úÖ Batch deletado:', batchId);
  }
}

/**
 * CRIAR TICKET A PARTIR DO BATCH
 */
async function createTicketFromBatch(batch: any) {
  console.log('ü§ñ [CREATE-TICKET] Criando ticket para batch:', batch.id);
  
  try {
    const firstMessage = batch.messages[0];
    const customerName = firstMessage?.customerName || 'Cliente';
    const phoneNumber = firstMessage?.phoneNumber || '';
    const chatId = batch.chat_id;
    const instanceId = batch.instance_id;
    const clientId = batch.client_id;
    
    // Usar a fun√ß√£o RPC do Supabase para criar/buscar ticket
    const { data: ticketId, error: rpcError } = await supabase.rpc('upsert_conversation_ticket', {
      p_client_id: clientId,
      p_chat_id: chatId,
      p_instance_id: instanceId,
      p_customer_name: customerName,
      p_customer_phone: phoneNumber,
      p_last_message: firstMessage?.content || '',
      p_last_message_at: new Date().toISOString()
    });

    if (rpcError) {
      console.error('ü§ñ [CREATE-TICKET] ‚ùå Erro RPC:', rpcError);
      return null;
    }

    // Buscar o ticket criado
    const { data: ticket, error: fetchError } = await supabase
      .from('conversation_tickets')
      .select('*')
      .eq('id', ticketId)
      .single();

    if (fetchError) {
      console.error('ü§ñ [CREATE-TICKET] ‚ùå Erro ao buscar ticket:', fetchError);
      return null;
    }

    console.log('ü§ñ [CREATE-TICKET] ‚úÖ Ticket criado/encontrado:', ticket.id);
    return ticket;
    
  } catch (error) {
    console.error('ü§ñ [CREATE-TICKET] ‚ùå Erro geral:', error);
    return null;
  }
}

/**
 * üéØ PROCESSAMENTO UNIFICADO: DESCRIPTOGRAFIA DE M√çDIAS DENTRO DO BATCH
 */
async function processMediaDecryption(batch: any, audioMessages: any[], imageMessages: any[]) {
  console.log('üîê [UNIFIED-DECRYPT] Iniciando descriptografia unificada:', {
    totalAudios: audioMessages.length,
    totalImages: imageMessages.length
  });
  
  // Buscar client_id e instance_id para obter business token
  const { data: clientData } = await supabase
    .from('whatsapp_instances')
    .select(`
      client_id,
      instance_id,
      clients!inner (
        business_token
      )
    `)
    .eq('instance_id', batch.instance_id)
    .single();
  
  if (!clientData?.clients?.business_token) {
    console.log('‚ö†Ô∏è [UNIFIED-DECRYPT] Business token n√£o encontrado');
    return;
  }
  
  const businessToken = clientData.clients.business_token;
  const decryptionPromises = [];
  
  // Processar descriptografia de imagens
  for (const imageMsg of imageMessages) {
    decryptionPromises.push(
      processImageDecryption(imageMsg.messageId, batch.instance_id, businessToken)
    );
  }
  
  // Processar descriptografia de √°udios
  for (const audioMsg of audioMessages) {
    decryptionPromises.push(
      processAudioDecryption(audioMsg.messageId, batch.instance_id, businessToken)
    );
  }
  
  if (decryptionPromises.length > 0) {
    console.log(`üîê [UNIFIED-DECRYPT] Processando ${decryptionPromises.length} m√≠dias em paralelo`);
    await Promise.allSettled(decryptionPromises);
    console.log('‚úÖ [UNIFIED-DECRYPT] Descriptografia conclu√≠da');
  }
}

/**
 * üß† PROCESSAMENTO UNIFICADO: AN√ÅLISE DE M√çDIAS DENTRO DO BATCH
 */
async function processMediaAnalysis(batch: any, audioMessages: any[], imageMessages: any[]) {
  console.log('üß† [UNIFIED-ANALYSIS] Iniciando an√°lise unificada:', {
    totalAudios: audioMessages.length,
    totalImages: imageMessages.length
  });
  
  // Buscar configura√ß√£o de OpenAI do cliente
  const { data: aiConfig } = await supabase
    .from('client_ai_configs')
    .select('openai_api_key')
    .eq('client_id', batch.client_id)
    .single();
  
  if (!aiConfig?.openai_api_key) {
    console.log('‚ö†Ô∏è [UNIFIED-ANALYSIS] OpenAI API key n√£o encontrada');
    return;
  }
  
  const analysisPromises = [];
  
  // Processar an√°lise de imagens
  for (const imageMsg of imageMessages) {
    analysisPromises.push(
      processImageAnalysis(imageMsg.messageId, aiConfig.openai_api_key)
    );
  }
  
  // Processar an√°lise de √°udios  
  for (const audioMsg of audioMessages) {
    analysisPromises.push(
      processAudioContextualAnalysis(audioMsg.messageId, aiConfig.openai_api_key)
    );
  }
  
  if (analysisPromises.length > 0) {
    console.log(`üß† [UNIFIED-ANALYSIS] Processando ${analysisPromises.length} an√°lises em paralelo`);
    await Promise.allSettled(analysisPromises);
    console.log('‚úÖ [UNIFIED-ANALYSIS] An√°lise conclu√≠da');
  }
}

/**
 * üñºÔ∏è DESCRIPTOGRAFAR IMAGEM INDIVIDUAL
 */
async function processImageDecryption(messageId: string, instanceId: string, businessToken: string) {
  try {
    console.log('üñºÔ∏è [IMAGE-DECRYPT] Descriptografando:', messageId);
    
    // Buscar dados da imagem
    const { data: imageData } = await supabase
      .from('ticket_messages')
      .select('media_url, media_key, media_mime_type')
      .eq('message_id', messageId)
      .eq('message_type', 'image')
      .single();
    
    if (!imageData?.media_url || !imageData?.media_key) {
      console.log('‚ö†Ô∏è [IMAGE-DECRYPT] Dados incompletos para:', messageId);
      return;
    }
    
    // Chamar API de descriptografia
    const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${instanceId}/media/directly-download`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contentType: 'image',
        url: imageData.media_url,
        mediaKey: imageData.media_key,
        mimetype: imageData.media_mime_type || 'image/jpeg'
      }),
    });
    
    if (response.ok) {
      const result = await response.json();
      
      // Salvar imagem descriptografada
      await supabase
        .from('ticket_messages')
        .update({
          image_base64: result.media,
          processing_status: 'decrypted'
        })
        .eq('message_id', messageId);
      
      console.log('‚úÖ [IMAGE-DECRYPT] Sucesso:', messageId);
    } else {
      console.log('‚ùå [IMAGE-DECRYPT] Falha API:', response.status);
    }
    
  } catch (error) {
    console.error('‚ùå [IMAGE-DECRYPT] Erro:', messageId, error);
  }
}

/**
 * üéµ DESCRIPTOGRAFAR √ÅUDIO INDIVIDUAL
 */
async function processAudioDecryption(messageId: string, instanceId: string, businessToken: string) {
  try {
    console.log('üéµ [AUDIO-DECRYPT] Descriptografando:', messageId);
    
    // ‚úÖ VERIFICA√á√ÉO CR√çTICA: Se j√° est√° processado, n√£o reprocessar
    const { data: currentStatus } = await supabase
      .from('ticket_messages')
      .select('audio_base64, processing_status, media_url, media_key, media_mime_type')
      .eq('message_id', messageId)
      .eq('message_type', 'audio')
      .single();
    
    if (currentStatus?.audio_base64) {
      console.log('‚úÖ [AUDIO-DECRYPT] √Åudio j√° descriptografado - pulando:', messageId);
      return;
    }
    
    if (!currentStatus?.media_url || !currentStatus?.media_key) {
      console.log('‚ö†Ô∏è [AUDIO-DECRYPT] Dados incompletos para:', messageId);
      return;
    }
    
    const audioData = currentStatus;
    
    // üîß CORRE√á√ÉO CR√çTICA: Converter media_key se estiver em formato objeto
    let mediaKey = audioData.media_key;
    if (typeof mediaKey === 'object' && mediaKey !== null) {
      console.log('üîÑ [AUDIO-DECRYPT] Convertendo media_key de objeto para Base64');
      mediaKey = convertToBase64Robust(mediaKey);
      if (!mediaKey) {
        console.error('‚ùå [AUDIO-DECRYPT] Falha na convers√£o de media_key:', messageId);
        return;
      }
    }
    
    // Chamar API de descriptografia
    const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${instanceId}/media/directly-download`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contentType: 'audio',
        url: audioData.media_url,
        mediaKey: mediaKey,
        mimetype: audioData.media_mime_type || 'audio/ogg'
      }),
    });
    
    if (response.ok) {
      const result = await response.json();
      
      // üîß VALIDAR FORMATO DE √ÅUDIO antes de salvar
      const audioBase64 = result.media;
      if (!audioBase64 || typeof audioBase64 !== 'string') {
        console.error('‚ùå [AUDIO-DECRYPT] √Åudio descriptografado inv√°lido:', messageId);
        return;
      }
      
      // Verificar se √© Base64 v√°lido e tem header correto
      try {
        const audioBytes = atob(audioBase64.substring(0, 50)); // Verificar header
        console.log('‚úÖ [AUDIO-DECRYPT] √Åudio descriptografado validado:', {
          messageId,
          size: audioBase64.length,
          headerBytes: audioBytes.slice(0, 10).split('').map(c => c.charCodeAt(0)).join(' ')
        });
      } catch (headerError) {
        console.error('‚ùå [AUDIO-DECRYPT] Header de √°udio inv√°lido:', messageId, headerError);
        return;
      }
      
      // Salvar √°udio descriptografado
      await supabase
        .from('ticket_messages')
        .update({
          audio_base64: audioBase64,
          processing_status: 'decrypted'
        })
        .eq('message_id', messageId);
      
      console.log('‚úÖ [AUDIO-DECRYPT] Sucesso:', messageId);
    } else {
      const errorText = await response.text();
      console.log('‚ùå [AUDIO-DECRYPT] Falha API:', response.status, errorText);
    }
    
  } catch (error) {
    console.error('‚ùå [AUDIO-DECRYPT] Erro:', messageId, error);
    
    // Marcar como failed para evitar loops
    await supabase
      .from('ticket_messages')
      .update({ processing_status: 'failed' })
      .eq('message_id', messageId);
  }
}

/**
 * üîß CONVERTER DADOS PARA BASE64 DE FORMA ROBUSTA
 */
function convertToBase64Robust(data: any): string | null {
  try {
    if (!data) return null;
    
    // Se j√° √© string Base64, retornar como est√°
    if (typeof data === 'string') {
      return data;
    }
    
    // Se √© objeto {0: 165, 1: 232, ...} (Uint8Array serializado)
    if (typeof data === 'object' && !Array.isArray(data)) {
      const keys = Object.keys(data).map(Number).sort((a, b) => a - b);
      if (keys.length > 0 && keys.every(k => !isNaN(k) && k >= 0)) {
        const bytes = new Uint8Array(keys.length);
        keys.forEach((key, index) => {
          bytes[index] = data[key];
        });
        return btoa(String.fromCharCode(...bytes));
      }
    }
    
    // Se √© array de bytes
    if (Array.isArray(data)) {
      const bytes = new Uint8Array(data);
      return btoa(String.fromCharCode(...bytes));
    }
    
    console.warn('üîß [CONVERT-BASE64] Tipo n√£o reconhecido:', typeof data);
    return null;
  } catch (error) {
    console.error('‚ùå [CONVERT-BASE64] Erro:', error);
    return null;
  }
}

/**
 * üñºÔ∏è ANALISAR IMAGEM COM GPT-4 VISION
 */
async function processImageAnalysis(messageId: string, apiKey: string) {
  try {
    console.log('üñºÔ∏è [IMAGE-ANALYSIS] Analisando:', messageId);
    
    // Buscar imagem descriptografada
    const { data: imageData } = await supabase
      .from('ticket_messages')
      .select('image_base64')
      .eq('message_id', messageId)
      .single();
    
    if (!imageData?.image_base64) {
      console.log('‚ö†Ô∏è [IMAGE-ANALYSIS] Imagem n√£o dispon√≠vel:', messageId);
      return;
    }
    
    // Processar com GPT-4 Vision
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'Analise esta imagem de forma detalhada e descreva o que voc√™ v√™. Inclua elementos visuais importantes, texto se houver, objetos, pessoas, a√ß√µes, contexto e qualquer informa√ß√£o relevante para atendimento ao cliente.'
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:image/jpeg;base64,${imageData.image_base64}`
                }
              }
            ]
          }
        ],
        max_tokens: 800
      }),
    });
    
    if (response.ok) {
      const result = await response.json();
      const analysis = result.choices[0].message.content;
      
      // Salvar an√°lise
      await supabase
        .from('ticket_messages')
        .update({
          media_transcription: analysis,
          processing_status: 'analyzed'
        })
        .eq('message_id', messageId);
      
      console.log('‚úÖ [IMAGE-ANALYSIS] An√°lise salva:', messageId);
    } else {
      console.log('‚ùå [IMAGE-ANALYSIS] Falha API:', response.status);
    }
    
  } catch (error) {
    console.error('‚ùå [IMAGE-ANALYSIS] Erro:', messageId, error);
  }
}

/**
 * üéµ AN√ÅLISE CONTEXTUAL DE √ÅUDIO
 */
async function processAudioContextualAnalysis(messageId: string, apiKey: string) {
  try {
    console.log('üéµ [AUDIO-ANALYSIS] Analisando contexto:', messageId);
    
    // Buscar transcri√ß√£o existente
    const { data: audioData } = await supabase
      .from('ticket_messages')
      .select('content, media_transcription')
      .eq('message_id', messageId)
      .single();
    
    if (!audioData?.content || audioData.content === 'üéµ √Åudio') {
      console.log('‚ö†Ô∏è [AUDIO-ANALYSIS] Transcri√ß√£o n√£o dispon√≠vel:', messageId);
      return;
    }
    
    // Se j√° tem an√°lise, pular
    if (audioData.media_transcription) {
      console.log('‚ÑπÔ∏è [AUDIO-ANALYSIS] An√°lise j√° existe:', messageId);
      return;
    }
    
    // Processar an√°lise contextual com GPT-4
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: 'Voc√™ √© um assistente especializado em an√°lise de √°udios para atendimento ao cliente. Analise a transcri√ß√£o fornecida e extraia informa√ß√µes relevantes como: sentimento, inten√ß√£o, urg√™ncia, palavras-chave importantes, e contexto da mensagem.'
          },
          {
            role: 'user',
            content: `Analise esta transcri√ß√£o de √°udio: "${audioData.content}"`
          }
        ],
        max_tokens: 800
      }),
    });
    
    if (response.ok) {
      const result = await response.json();
      const analysis = result.choices[0].message.content;
      
      // Salvar an√°lise contextual
      await supabase
        .from('ticket_messages')
        .update({
          media_transcription: analysis,
          processing_status: 'analyzed'
        })
        .eq('message_id', messageId);
      
      console.log('‚úÖ [AUDIO-ANALYSIS] An√°lise contextual salva:', messageId);
    } else {
      console.log('‚ùå [AUDIO-ANALYSIS] Falha API:', response.status);
    }
    
  } catch (error) {
    console.error('‚ùå [AUDIO-ANALYSIS] Erro:', messageId, error);
  }
}

/**
 * PROCESSAR MENSAGEM INDIVIDUAL (FALLBACK)
 */
async function processSingleMessage(message: any) {
  console.log('ü§ñ [SINGLE-MESSAGE] Processando mensagem individual como fallback');
  return { success: true };
}