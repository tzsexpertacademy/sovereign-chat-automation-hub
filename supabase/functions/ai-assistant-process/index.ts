
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const supabase = createClient(
  Deno.env.get('SUPABASE_URL') ?? '',
  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
);

// Fun√ß√£o para processar padr√µes de √°udio na resposta
function processAudioPatterns(text: string, audioLibrary: any[] = []) {
  console.log('üéµ ===== PROCESSANDO PADR√ïES DE √ÅUDIO =====');
  console.log('üìù Texto original:', text.substring(0, 200));
  console.log('üìö Biblioteca de √°udios:', audioLibrary.length, 'itens');
  
  const patterns = {
    elevenlabs: /audio:\s*(.+?)(?=\n|$)/gi,
    library: /audiogeonomedoaudio:\s*(.+?)(?=\n|$)/gi
  };
  
  const audioInstructions = [];
  let processedText = text;
  
  // Detectar padr√£o ElevenLabs (audio:)
  const elevenLabsMatches = [...text.matchAll(patterns.elevenlabs)];
  console.log('üîç Padr√µes ElevenLabs encontrados:', elevenLabsMatches.length);
  
  for (const match of elevenLabsMatches) {
    const fullMatch = match[0];
    const audioText = match[1].trim();
    
    console.log('üé§ Texto para ElevenLabs:', audioText);
    
    audioInstructions.push({
      type: 'elevenlabs',
      text: audioText,
      originalMatch: fullMatch
    });
    
    // Remover o padr√£o do texto - N√ÉO substituir por placeholder
    processedText = processedText.replace(fullMatch, '');
  }
  
  // Detectar padr√£o biblioteca (audiogeonomedoaudio:)
  const libraryMatches = [...text.matchAll(patterns.library)];
  console.log('üìö Padr√µes de biblioteca encontrados:', libraryMatches.length);
  
  for (const match of libraryMatches) {
    const fullMatch = match[0];
    const trigger = match[1].trim();
    
    console.log('üîç Procurando trigger na biblioteca:', trigger);
    
    // Buscar na biblioteca
    const audioItem = audioLibrary.find(item => 
      item.trigger === trigger || 
      item.trigger === `audiogeonomedoaudio${trigger}` ||
      item.name.toLowerCase().includes(trigger.toLowerCase())
    );
    
    if (audioItem) {
      console.log('‚úÖ √Åudio encontrado na biblioteca:', audioItem.name);
      audioInstructions.push({
        type: 'library',
        audioItem: audioItem,
        originalMatch: fullMatch
      });
      
      processedText = processedText.replace(fullMatch, '');
    } else {
      console.log('‚ùå √Åudio n√£o encontrado na biblioteca para trigger:', trigger);
      processedText = processedText.replace(fullMatch, `[√Åudio n√£o encontrado: ${trigger}]`);
    }
  }
  
  console.log('üìä Resultado do processamento:', {
    audioInstructions: audioInstructions.length,
    processedText: processedText.substring(0, 200),
    hasElevenLabs: audioInstructions.some(a => a.type === 'elevenlabs'),
    hasLibrary: audioInstructions.some(a => a.type === 'library')
  });
  
  return {
    processedText: processedText.trim(),
    audioInstructions,
    hasAudio: audioInstructions.length > 0
  };
}

// FUN√á√ÉO COMPLETAMENTE REESCRITA - DETEC√á√ÉO INTELIGENTE DE AMBIENTE
async function getWhatsAppServerUrl(): Promise<string> {
  console.log('üåê ===== DETEC√á√ÉO INTELIGENTE DO SERVIDOR WHATSAPP =====');
  
  // Detectar ambiente baseado no hostname da URL atual
  const isLocalEnvironment = globalThis.location?.hostname === 'localhost' || 
                            globalThis.location?.hostname === '127.0.0.1' ||
                            Deno.env.get('ENVIRONMENT') === 'local';
  
  console.log('üîç Ambiente detectado:', {
    isLocal: isLocalEnvironment,
    hostname: globalThis.location?.hostname || 'undefined'
  });
  
  const candidates = isLocalEnvironment 
    ? ['http://localhost:4000', 'http://127.0.0.1:4000', 'http://146.59.227.248:4000']
    : ['http://146.59.227.248:4000', 'http://localhost:4000', 'http://127.0.0.1:4000'];
  
  for (const url of candidates) {
    try {
      console.log(`üîç Testando servidor: ${url}`);
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 3000); // 3s timeout
      
      const healthResponse = await fetch(`${url}/health`, {
        method: 'GET',
        headers: { 'Content-Type': 'application/json' },
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (healthResponse.ok) {
        const healthData = await healthResponse.json();
        console.log(`‚úÖ Servidor encontrado: ${url}`, healthData);
        return url;
      }
      
      console.log(`‚ùå Servidor ${url} retornou: HTTP ${healthResponse.status}`);
    } catch (error) {
      console.log(`‚ùå Falha ao conectar ${url}:`, error.message);
    }
  }
  
  // Fallback baseado no ambiente
  const fallbackUrl = isLocalEnvironment ? 'http://localhost:4000' : 'http://146.59.227.248:4000';
  console.log(`‚ö†Ô∏è Usando fallback para ambiente ${isLocalEnvironment ? 'local' : 'produ√ß√£o'}: ${fallbackUrl}`);
  return fallbackUrl;
}

// FUN√á√ÉO NOVA: Converter base64 para Blob tempor√°rio para o WhatsApp
async function convertBase64ToBlob(base64Audio: string, filename: string): Promise<Blob> {
  console.log('üîÑ Convertendo base64 para Blob...');
  
  try {
    // Decodificar base64
    const binaryString = atob(base64Audio);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    
    // Criar blob com o tipo correto baseado na extens√£o
    const mimeType = filename.endsWith('.mp3') ? 'audio/mpeg' : 
                    filename.endsWith('.wav') ? 'audio/wav' :
                    filename.endsWith('.ogg') ? 'audio/ogg' : 'audio/mpeg';
    
    const blob = new Blob([bytes], { type: mimeType });
    
    console.log('‚úÖ Blob criado:', {
      size: blob.size,
      type: blob.type,
      filename: filename
    });
    
    return blob;
  } catch (error) {
    console.error('‚ùå Erro ao converter base64 para blob:', error);
    throw new Error(`Erro na convers√£o de √°udio: ${error.message}`);
  }
}

// FUN√á√ÉO EXPANDIDA: Enviar √°udio para WhatsApp (suporta base64 + arquivos)
async function sendAudioToWhatsApp(clientId: string, chatId: string, audioData: string | Blob, audioText: string = '', isBase64: boolean = true) {
  try {
    console.log('üéµ ===== ENVIANDO √ÅUDIO PARA WHATSAPP (VERS√ÉO EXPANDIDA) =====');
    
    const serverUrl = await getWhatsAppServerUrl();
    console.log('üåê URL do servidor WhatsApp:', serverUrl);
    
    console.log('üìä Par√¢metros de envio:', {
      clientId: clientId.substring(0, 8) + '...',
      chatId: chatId.substring(0, 20) + '...',
      audioSize: isBase64 ? audioData.length : (audioData as Blob).size,
      textPreview: audioText.substring(0, 50),
      isBase64,
      serverUrl
    });

    // FASE 1: VALIDAR SERVIDOR
    console.log('üîç FASE 1: Validando servidor WhatsApp...');
    const healthResponse = await fetch(`${serverUrl}/health`, {
      method: 'GET',
      headers: { 'Content-Type': 'application/json' },
      signal: AbortSignal.timeout(5000)
    });
    
    if (!healthResponse.ok) {
      throw new Error(`Servidor WhatsApp offline: HTTP ${healthResponse.status}`);
    }
    
    const healthData = await healthResponse.json();
    console.log('‚úÖ Servidor WhatsApp online:', healthData);

    // FASE 2: VALIDAR CLIENTE
    console.log('üîç FASE 2: Validando cliente WhatsApp...');
    const statusResponse = await fetch(`${serverUrl}/api/clients/${clientId}/status`, {
      method: 'GET',
      headers: { 'Content-Type': 'application/json' },
      signal: AbortSignal.timeout(5000)
    });
    
    if (!statusResponse.ok) {
      const statusError = await statusResponse.text();
      throw new Error(`Cliente inv√°lido: HTTP ${statusResponse.status} - ${statusError}`);
    }
    
    const statusData = await statusResponse.json();
    console.log('üìä Status do cliente:', statusData);
    
    if (!statusData.success || statusData.status !== 'connected') {
      throw new Error(`Cliente n√£o conectado. Status: ${statusData.status || 'desconhecido'}`);
    }

    // FASE 3: PREPARAR √ÅUDIO (base64 ou blob)
    console.log('üîç FASE 3: Preparando √°udio...');
    
    let audioBlob: Blob;
    
    if (isBase64) {
      console.log('üîÑ Convertendo base64 para blob...');
      audioBlob = await convertBase64ToBlob(audioData as string, 'audio.mp3');
    } else {
      console.log('üìÅ Usando blob fornecido diretamente...');
      audioBlob = audioData as Blob;
    }
    
    console.log('üéµ √Åudio preparado:', {
      size: audioBlob.size,
      type: audioBlob.type,
      isValidSize: audioBlob.size > 100
    });

    if (audioBlob.size < 100) {
      throw new Error('Arquivo de √°udio muito pequeno (poss√≠vel corrup√ß√£o)');
    }

    // FASE 4: CRIAR FORMDATA
    console.log('üîç FASE 4: Criando FormData...');
    const formData = new FormData();
    formData.append('to', chatId);
    formData.append('file', audioBlob, 'voice_message.mp3');
    
    if (audioText && audioText.trim()) {
      formData.append('caption', audioText.trim());
      console.log('üìù Caption adicionada:', audioText.trim());
    }

    // FASE 5: ENVIAR COM RETRY
    console.log('üîç FASE 5: Enviando para WhatsApp...');
    
    const audioEndpointUrl = `${serverUrl}/api/clients/${clientId}/send-audio`;
    console.log('üéØ Endpoint:', audioEndpointUrl);

    const maxRetries = 2;
    let lastError: Error | null = null;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`üöÄ Tentativa ${attempt}/${maxRetries}...`);
        
        const response = await fetch(audioEndpointUrl, {
          method: 'POST',
          body: formData,
          signal: AbortSignal.timeout(60000) // 1 minuto
        });

        console.log('üì° Resposta do servidor:', {
          status: response.status,
          statusText: response.statusText,
          attempt: attempt
        });

        if (!response.ok) {
          let errorDetails;
          try {
            const contentType = response.headers.get('content-type') || '';
            if (contentType.includes('application/json')) {
              errorDetails = await response.json();
            } else {
              errorDetails = await response.text();
            }
          } catch {
            errorDetails = 'Erro desconhecido do servidor';
          }
          
          const errorMessage = `HTTP ${response.status}: ${JSON.stringify(errorDetails)}`;
          console.error(`‚ùå Tentativa ${attempt} falhou:`, errorMessage);
          
          if (attempt === maxRetries) {
            throw new Error(errorMessage);
          }
          
          await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
          continue;
        }

        // Processar resposta de sucesso
        let result;
        try {
          result = await response.json();
          console.log('üì® Resposta JSON:', result);
        } catch (jsonError) {
          console.error('‚ùå Erro ao processar JSON:', jsonError);
          throw new Error('Resposta do servidor n√£o √© JSON v√°lido');
        }

        if (!result.success) {
          console.error('‚ùå API WhatsApp retornou falha:', result);
          throw new Error(result.error || result.message || 'Falha na API do WhatsApp');
        }

        console.log('‚úÖ ===== √ÅUDIO ENVIADO COM SUCESSO =====');
        console.log('üéâ Detalhes:', {
          messageId: result.messageId || result.id,
          status: result.status,
          success: result.success,
          audioSize: audioBlob.size,
          attempt: attempt
        });

        return {
          success: true,
          messageId: result.messageId || result.id,
          status: result.status,
          audioSize: audioBlob.size,
          attempt: attempt,
          ...result
        };
        
      } catch (error) {
        lastError = error as Error;
        console.error(`‚ùå Tentativa ${attempt} falhou:`, error.message);
        
        if (attempt < maxRetries) {
          console.log(`üîÑ Aguardando ${attempt}s antes da pr√≥xima tentativa...`);
          await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
        }
      }
    }
    
    throw lastError || new Error('Todas as tentativas de envio falharam');
    
  } catch (error) {
    console.error('‚ùå ===== ERRO CR√çTICO NO ENVIO DE √ÅUDIO =====');
    console.error('üí• Detalhes:', {
      message: error.message,
      name: error.name,
      timestamp: new Date().toISOString()
    });
    
    if (error.name === 'AbortError') {
      throw new Error('Timeout: Servidor WhatsApp n√£o respondeu em tempo h√°bil');
    } else if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
      throw new Error('Erro de rede: N√£o foi poss√≠vel conectar ao servidor WhatsApp');
    } else if (error.message.includes('n√£o conectado') || error.message.includes('not connected')) {
      throw new Error('Cliente WhatsApp n√£o est√° conectado ou autenticado');
    } else {
      throw new Error(`Erro no envio de √°udio: ${error.message}`);
    }
  }
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { 
      messageText, 
      assistantId, 
      chatId, 
      instanceId,
      messageId,
      isAudioMessage = false 
    } = await req.json();

    console.log('üîç ===== PROCESSAMENTO EDGE FUNCTION =====');
    console.log('üì® Dados recebidos:', {
      assistantId,
      chatId,
      instanceId,
      messageLength: messageText?.length,
      isAudio: isAudioMessage
    });

    // BUSCAR ASSISTENTE
    const { data: assistant, error: assistantError } = await supabase
      .from('assistants')
      .select('*, advanced_settings')
      .eq('id', assistantId)
      .single();

    if (assistantError || !assistant) {
      console.error('‚ùå ASSISTENTE n√£o encontrado:', assistantError);
      throw new Error('Assistente n√£o encontrado');
    }

    console.log('‚úÖ ASSISTENTE encontrado:', assistant.name);

    // PARSE CONFIGURA√á√ïES AVAN√áADAS
    let settings: any = {};
    try {
      settings = assistant.advanced_settings ? 
        (typeof assistant.advanced_settings === 'string' ? 
          JSON.parse(assistant.advanced_settings) : assistant.advanced_settings) : {};
    } catch (error) {
      console.error('‚ùå ERRO ao fazer parse das configura√ß√µes:', error);
      settings = {};
    }

    const temperature = settings.temperature ?? 0.7;
    const maxTokens = settings.max_tokens ?? 1000;
    const audioLibrary = settings.audio_library || [];
    
    console.log('üéõÔ∏è CONFIGURA√á√ïES IA:', { 
      temperature, 
      maxTokens, 
      audioLibrarySize: audioLibrary.length,
      hasElevenLabsConfig: !!(settings.eleven_labs_api_key && settings.eleven_labs_voice_id)
    });
    
    // BUSCAR CONFIG AI DO CLIENTE
    const { data: aiConfig, error: configError } = await supabase
      .from('client_ai_configs')
      .select('*')
      .eq('client_id', assistant.client_id)
      .single();

    if (configError || !aiConfig) {
      console.error('‚ùå CONFIG IA n√£o encontrada:', configError);
      throw new Error('Configura√ß√£o de IA n√£o encontrada para este cliente');
    }

    console.log('üîë CONFIG API encontrada');

    let processedText = messageText;

    // PROCESSAMENTO DE √ÅUDIO SE HABILITADO
    if (isAudioMessage && settings.audio_processing_enabled) {
      console.log('üéµ PROCESSANDO mensagem de √°udio...');
      
      const speechResponse = await supabase.functions.invoke('speech-to-text', {
        body: {
          audio: messageText,
          openaiApiKey: aiConfig.openai_api_key
        }
      });

      if (speechResponse.error) {
        throw new Error(`Erro na transcri√ß√£o: ${speechResponse.error.message}`);
      }

      const speechResult = speechResponse.data;
      if (speechResult.error) {
        throw new Error(`Erro na transcri√ß√£o: ${speechResult.error}`);
      }
      
      processedText = speechResult.text;
      console.log('üéµ √ÅUDIO transcrito:', processedText);
    }

    // MARCAR IN√çCIO DO PROCESSAMENTO
    if (messageId) {
      await supabase
        .from('whatsapp_messages')
        .update({
          processing_started_at: new Date().toISOString(),
          is_processed: false
        })
        .eq('message_id', messageId);
    }

    // DELAY DE RESPOSTA SE CONFIGURADO
    if (settings.response_delay_seconds > 0) {
      console.log(`‚è≥ AGUARDANDO ${settings.response_delay_seconds}s...`);
      await new Promise(resolve => setTimeout(resolve, settings.response_delay_seconds * 1000));
    }

    // INDICADOR DE DIGITA√á√ÉO
    if (settings.typing_indicator_enabled && chatId && instanceId) {
      console.log('‚å®Ô∏è MOSTRANDO indicador de digita√ß√£o...');
      await supabase
        .from('whatsapp_chats')
        .update({
          is_typing: true,
          typing_started_at: new Date().toISOString()
        })
        .eq('chat_id', chatId)
        .eq('instance_id', instanceId);
    }

    // CONSTRUIR PROMPT DO SISTEMA
    let systemMessage = assistant.prompt;
    if (settings.custom_files?.length > 0) {
      systemMessage += `\n\nArquivos de refer√™ncia dispon√≠veis: ${settings.custom_files.map((f: any) => f.name).join(', ')}`;
    }

    // ADICIONAR INSTRU√á√ïES DE √ÅUDIO AO PROMPT
    if (settings.voice_cloning_enabled || audioLibrary.length > 0) {
      systemMessage += `\n\nINSTRU√á√ïES DE √ÅUDIO:`;
      
      if (settings.voice_cloning_enabled) {
        systemMessage += `\n- Para responder com √°udio gerado por IA, use: audio: [sua resposta]`;
      }
      
      if (audioLibrary.length > 0) {
        systemMessage += `\n- Para usar √°udios pr√©-gravados, use: audiogeonomedoaudio: [trigger]`;
        systemMessage += `\n- √Åudios dispon√≠veis: ${audioLibrary.map((a: any) => `${a.trigger} (${a.name})`).join(', ')}`;
      }
    }

    console.log('ü§ñ PROCESSANDO com OpenAI...');

    // CHAMAR OPENAI
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${aiConfig.openai_api_key}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: assistant.model || aiConfig.default_model || 'gpt-4o-mini',
        messages: [
          { 
            role: 'system', 
            content: systemMessage
          },
          { role: 'user', content: processedText }
        ],
        max_tokens: maxTokens,
        temperature: temperature
      }),
    });

    const aiResult = await openaiResponse.json();
    if (aiResult.error) {
      console.error('‚ùå ERRO da OpenAI:', aiResult.error);
      throw new Error(`Erro da OpenAI: ${aiResult.error.message}`);
    }

    console.log('‚úÖ RESPOSTA da OpenAI recebida');

    const responseText = aiResult.choices[0].message.content;

    // PROCESSAR PADR√ïES DE √ÅUDIO NA RESPOSTA
    const audioProcessing = processAudioPatterns(responseText, audioLibrary);
    let finalResponse = audioProcessing.processedText;
    let audioResponses = [];

    // PROCESSAR INSTRU√á√ïES DE √ÅUDIO (CORRIGIDO)
    if (audioProcessing.hasAudio) {
      console.log('üéµ ===== PROCESSANDO INSTRU√á√ïES DE √ÅUDIO =====');
      
      for (const instruction of audioProcessing.audioInstructions) {
        try {
          if (instruction.type === 'elevenlabs' && settings.voice_cloning_enabled) {
            console.log('üé§ GERANDO √°udio com ElevenLabs:', instruction.text);
            
            const ttsResponse = await supabase.functions.invoke('text-to-speech', {
              body: {
                text: instruction.text,
                voiceId: settings.eleven_labs_voice_id,
                apiKey: settings.eleven_labs_api_key,
                model: settings.eleven_labs_model || 'eleven_multilingual_v2',
                voiceSettings: settings.voice_settings
              }
            });

            if (ttsResponse.error) {
              console.error('‚ùå Erro na Edge Function TTS:', ttsResponse.error);
              throw new Error(`Erro TTS: ${ttsResponse.error.message}`);
            }

            const ttsResult = ttsResponse.data;
            if (!ttsResult.success) {
              console.error('‚ùå Erro no resultado TTS:', ttsResult.error);
              throw new Error(`Erro TTS: ${ttsResult.error}`);
            }

            console.log('‚úÖ √Åudio ElevenLabs gerado:', {
              base64Length: ttsResult.audioBase64?.length || 0,
              format: 'MP3'
            });
            
            // ENVIAR √ÅUDIO PARA WHATSAPP (VERS√ÉO CORRIGIDA)
            try {
              console.log('üì§ Enviando √°udio ElevenLabs para WhatsApp...');
              const whatsappResult = await sendAudioToWhatsApp(
                assistant.client_id, 
                chatId, 
                ttsResult.audioBase64, 
                instruction.text,
                true // √© base64
              );
              
              audioResponses.push({
                type: 'elevenlabs',
                text: instruction.text,
                sent: true,
                sentAt: new Date().toISOString(),
                audioFormat: 'MP3',
                whatsappMessageId: whatsappResult.messageId,
                whatsappResult: whatsappResult
              });
              
              console.log('‚úÖ √Åudio ElevenLabs enviado com sucesso:', whatsappResult.messageId);
            } catch (whatsappError) {
              console.error('‚ùå Falha ao enviar √°udio ElevenLabs:', whatsappError.message);
              
              audioResponses.push({
                type: 'elevenlabs',
                text: instruction.text,
                sent: false,
                error: whatsappError.message,
                sentAt: new Date().toISOString(),
                audioFormat: 'MP3'
              });
              
              // IMPORTANTE: Se √°udio falha, N√ÉO adicionar ao texto final
              console.log('‚ö†Ô∏è √Åudio falhou - n√£o adicionando ao texto de resposta');
            }
            
          } else if (instruction.type === 'library' && instruction.audioItem) {
            console.log('üìö USANDO √°udio da biblioteca:', instruction.audioItem.name);
            
            audioResponses.push({
              type: 'library',
              audioUrl: instruction.audioItem.url,
              audioName: instruction.audioItem.name,
              sent: false
            });
          }
        } catch (audioError) {
          console.error('‚ùå Erro no processamento de √°udio:', audioError);
          audioResponses.push({
            type: 'error',
            error: audioError.message,
            sentAt: new Date().toISOString()
          });
        }
      }
    }

    // REMOVER INDICADOR DE DIGITA√á√ÉO
    if (settings.typing_indicator_enabled && chatId && instanceId) {
      console.log('‚å®Ô∏è REMOVENDO indicador de digita√ß√£o...');
      await supabase
        .from('whatsapp_chats')
        .update({
          is_typing: false,
          typing_started_at: null
        })
        .eq('chat_id', chatId)
        .eq('instance_id', instanceId);
    }

    // MARCAR MENSAGEM COMO PROCESSADA
    if (messageId) {
      await supabase
        .from('whatsapp_messages')
        .update({
          is_processed: true
        })
        .eq('message_id', messageId);
    }

    console.log('‚úÖ PROCESSAMENTO conclu√≠do');
    console.log('üì§ RESPOSTA final:', {
      textLength: finalResponse.length,
      audioCount: audioResponses.length,
      hasText: !!finalResponse.trim(),
      hasAudio: audioResponses.length > 0,
      audiosSentToWhatsApp: audioResponses.filter(a => a.sent).length,
      audiosWithError: audioResponses.filter(a => !a.sent && a.error).length
    });

    // DECIS√ÉO INTELIGENTE: Se h√° √°udio enviado com sucesso, texto √© opcional
    const shouldSendText = finalResponse.trim().length > 0;
    const hasSuccessfulAudio = audioResponses.some(a => a.sent);

    return new Response(JSON.stringify({ 
      response: shouldSendText ? finalResponse : '',
      audioResponses: audioResponses,
      hasAudio: audioResponses.length > 0,
      hasSuccessfulAudio: hasSuccessfulAudio,
      processed: true,
      audioFormat: 'MP3',
      settings: {
        temperature,
        maxTokens,
        model: assistant.model || aiConfig.default_model || 'gpt-4o-mini'
      }
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('‚ùå ERRO CR√çTICO na fun√ß√£o edge:', error);
    return new Response(JSON.stringify({ 
      error: error.message,
      timestamp: new Date().toISOString()
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});
