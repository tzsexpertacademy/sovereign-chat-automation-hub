
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.50.0';

const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
const supabase = createClient(supabaseUrl, supabaseKey);

const globalOpenAIApiKey = Deno.env.get('OPENAI_API_KEY');

// Sistema de controle de duplica√ß√£o
const processingLocks = new Map<string, { timestamp: number; promise: Promise<any> }>();
const LOCK_TIMEOUT = 30000; // 30 segundos

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('ü§ñ [AI-ASSISTANT] Processando requisi√ß√£o');
    
    const { 
      ticketId, 
      message, 
      clientId, 
      instanceId,
      assistant,
      context 
    } = await req.json();

    // üîí CONTROLE DE DUPLICA√á√ÉO: Verificar se j√° est√° sendo processado
    const lockKey = `${ticketId}_${message?.slice(0, 50)}`;
    const existingLock = processingLocks.get(lockKey);
    
    if (existingLock) {
      const elapsed = Date.now() - existingLock.timestamp;
      if (elapsed < LOCK_TIMEOUT) {
        console.log('‚è≥ [AI-ASSISTANT] Requisi√ß√£o j√° sendo processada, ignorando duplicata');
        return new Response(
          JSON.stringify({ 
            success: false, 
            message: 'Mensagem j√° sendo processada',
            duplicate: true 
          }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      } else {
        console.log('üßπ [AI-ASSISTANT] Lock expirado, removendo...');
        processingLocks.delete(lockKey);
      }
    }

    // üîç VERIFICAR SE MENSAGEM J√Å FOI PROCESSADA
    const { data: existingMessage } = await supabase
      .from('ticket_messages')
      .select('id')
      .eq('ticket_id', ticketId)
      .eq('content', message)
      .eq('is_ai_response', false)
      .order('created_at', { ascending: false })
      .limit(1)
      .single();

    if (existingMessage) {
      console.log('üîÑ [AI-ASSISTANT] Mensagem j√° processada anteriormente');
      return new Response(
        JSON.stringify({ 
          success: false, 
          message: 'Mensagem j√° foi processada',
          alreadyProcessed: true 
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // üîë PRIORIZA√á√ÉO DE API KEYS: Cliente espec√≠fico > Global
    let openAIApiKey = globalOpenAIApiKey;
    let keySource = 'global';

    try {
      // Tentar buscar API Key espec√≠fica do cliente
      const { data: clientConfig } = await supabase
        .from('client_ai_configs')
        .select('openai_api_key, default_model')
        .eq('client_id', clientId)
        .single();

      if (clientConfig?.openai_api_key) {
        openAIApiKey = clientConfig.openai_api_key;
        keySource = 'client';
        console.log('üîë [AI-ASSISTANT] Usando API Key espec√≠fica do cliente');
      } else {
        console.log('üîë [AI-ASSISTANT] Cliente n√£o tem API Key pr√≥pria, usando global');
      }
    } catch (error) {
      console.log('üîë [AI-ASSISTANT] Erro ao buscar config do cliente, usando global:', error.message);
    }

    console.log('ü§ñ [AI-ASSISTANT] Dados recebidos:', {
      ticketId,
      instanceId,
      assistantName: assistant?.name,
      messageLength: message?.length || 0,
      customerName: context?.customerName,
      keySource,
      hasOpenAIKey: !!openAIApiKey
    });

    // Verificar se OpenAI API key est√° configurada
    if (!openAIApiKey) {
      console.error('‚ùå [AI-ASSISTANT] OpenAI API key n√£o configurada');
      return new Response(
        JSON.stringify({ 
          error: 'OpenAI API key not configured',
          message: keySource === 'client' 
            ? 'Cliente precisa configurar sua API Key da OpenAI'
            : 'Configure OPENAI_API_KEY global nas Edge Function Secrets'
        }),
        { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Buscar hist√≥rico recente de mensagens do ticket para contexto
    const { data: recentMessages } = await supabase
      .from('ticket_messages')
      .select('content, from_me, sender_name, timestamp')
      .eq('ticket_id', ticketId)
      .order('timestamp', { ascending: false })
      .limit(10);

    // Construir contexto da conversa
    let conversationContext = '';
    if (recentMessages && recentMessages.length > 0) {
      conversationContext = recentMessages
        .reverse() // Ordenar cronologicamente
        .map(msg => `${msg.from_me ? 'Assistente' : msg.sender_name}: ${msg.content}`)
        .join('\n');
    }

    // Construir prompt do assistente
    const systemPrompt = `${assistant.prompt || 'Voc√™ √© um assistente √∫til e prestativo.'}

Contexto da conversa:
Cliente: ${context?.customerName || 'Cliente'}
Telefone: ${context?.phoneNumber || 'N/A'}

Hist√≥rico recente da conversa:
${conversationContext}

Instru√ß√µes importantes:
- Responda de forma natural e humana
- Seja √∫til e prestativo
- Mantenha o contexto da conversa
- Se n√£o souber algo, seja honesto
- Responda em portugu√™s brasileiro
- Seja conciso mas completo`;

    console.log('ü§ñ [AI-ASSISTANT] Chamando OpenAI API com modelo:', assistant.model || 'gpt-4o-mini');

    // Chamar OpenAI API
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openAIApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: assistant.model || 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: message }
        ],
        temperature: 0.7,
        max_tokens: 500
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [AI-ASSISTANT] Erro na OpenAI API:', response.status, response.statusText, errorText);
      throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
    }

    const aiData = await response.json();
    const aiResponse = aiData.choices[0].message.content;

    console.log('‚úÖ [AI-ASSISTANT] Resposta da IA gerada:', {
      responseLength: aiResponse?.length || 0,
      model: assistant.model || 'gpt-4o-mini'
    });

    // Salvar resposta da IA no ticket
    const messageId = `ai_response_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    const { error: saveError } = await supabase
      .from('ticket_messages')
      .insert({
        ticket_id: ticketId,
        message_id: messageId,
        content: aiResponse,
        from_me: true,
        is_ai_response: true,
        sender_name: assistant.name || 'Assistente IA',
        timestamp: new Date().toISOString(),
        processing_status: 'processed'
      });

    if (saveError) {
      console.error('‚ùå [AI-ASSISTANT] Erro ao salvar resposta:', saveError);
      throw saveError;
    }

    console.log('üíæ [AI-ASSISTANT] Resposta salva no ticket');

    // üîí CRIAR LOCK para este processamento
    const processingPromise = processAIResponseWithHumanization(instanceId, context?.chatId, aiResponse, assistant);
    processingLocks.set(lockKey, { timestamp: Date.now(), promise: processingPromise });

    try {
      const sendResult = await processingPromise;
      
      // Limpar lock ap√≥s processamento
      processingLocks.delete(lockKey);
      
      console.log('‚úÖ [AI-ASSISTANT] Processamento completo');

      return new Response(
        JSON.stringify({
          success: true,
          response: aiResponse,
          messageId: messageId,
          timestamp: new Date().toISOString(),
          sentViaCodeChat: sendResult.success
        }),
        {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        }
      );
    } catch (error) {
      // Limpar lock em caso de erro
      processingLocks.delete(lockKey);
      throw error;
    }

  } catch (error) {
    console.error('‚ùå [AI-ASSISTANT] Erro cr√≠tico:', error);
    
    return new Response(
      JSON.stringify({
        error: 'Failed to process AI assistant request',
        message: error.message
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  }
});

// üì§ Fun√ß√£o para enviar resposta via CodeChat v2.2.1
async function sendResponseViaCodeChat(instanceId: string, chatId: string, message: string): Promise<{ success: boolean; error?: string }> {
  try {
    console.log('üì§ [CODECHAT-SEND] Enviando resposta via CodeChat v2.2.1:', {
      instanceId,
      chatId,
      messageLength: message.length
    });

    // Buscar business_token da inst√¢ncia via cliente
    const { data: instanceData } = await supabase
      .from('whatsapp_instances')
      .select(`
        instance_id,
        client_id,
        clients:client_id (
          business_token
        )
      `)
      .eq('instance_id', instanceId)
      .single();

    if (!instanceData?.clients?.business_token) {
      console.error('‚ùå [CODECHAT-SEND] Business token n√£o encontrado para inst√¢ncia:', instanceId);
      return { success: false, error: 'Business token not found' };
    }

    const businessToken = instanceData.clients.business_token;
    console.log('üîß [CODECHAT-SEND] Usando CodeChat v2.2.1 para inst√¢ncia:', instanceId);

    // ENDPOINT CORRETO: v2.2.1 usa /api/v2/instance/:instanceId/send/text
    const endpoint = `https://api.yumer.com.br/api/v2/instance/${instanceId}/send/text`;
    
    // Preparar dados para CodeChat v2.2.1 - ESTRUTURA CORRETA
    const codeChatData = {
      number: chatId,
      text: message,
      options: {
        delay: 1200,
        presence: 'composing'
      }
    };

    console.log('üìã [CODECHAT-SEND] Dados para CodeChat API v2.2.1:', {
      endpoint,
      data: codeChatData
    });

    // Chamar CodeChat v2.2.1 com endpoint e headers corretos
    const codeChatResponse = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      },
      body: JSON.stringify(codeChatData)
    });

    if (!codeChatResponse.ok) {
      const errorText = await codeChatResponse.text();
      console.error('‚ùå [CODECHAT-SEND] Erro ao enviar via CodeChat API v2.2.1:', {
        status: codeChatResponse.status,
        statusText: codeChatResponse.statusText,
        error: errorText,
        instanceId,
        endpoint
      });
      return { success: false, error: `HTTP ${codeChatResponse.status}: ${errorText}` };
    }

    const result = await codeChatResponse.json();
    console.log('‚úÖ [CODECHAT-SEND] Mensagem enviada com sucesso via CodeChat v2.2.1:', {
      messageId: result.key?.id,
      chatId: chatId,
      response: result
    });

    return { success: true };

  } catch (error) {
    console.error('‚ùå [CODECHAT-SEND] Erro ao enviar via CodeChat v2.2.1:', error);
    return { success: false, error: error.message };
  }
}

// ü§ñ Fun√ß√£o para processar resposta da IA com humaniza√ß√£o
async function processAIResponseWithHumanization(instanceId: string, chatId: string, message: string, assistant: any): Promise<{ success: boolean; error?: string }> {
  try {
    console.log('üé≠ [HUMANIZATION] Iniciando processamento humanizado...');
    
    // Implementar presence 'composing' antes de enviar
    await setPresence(instanceId, chatId, 'composing');
    
    // Calcular delay baseado no tamanho da mensagem (simular tempo de digita√ß√£o)
    const typingDelay = calculateTypingDelay(message);
    console.log(`‚è±Ô∏è [HUMANIZATION] Simulando digita√ß√£o por ${typingDelay}ms`);
    
    // Aguardar delay de digita√ß√£o
    await new Promise(resolve => setTimeout(resolve, typingDelay));
    
    // Dividir mensagem em chunks se necess√°rio
    const messageChunks = splitMessageIntelligently(message);
    
    if (messageChunks.length > 1) {
      console.log(`üìù [HUMANIZATION] Enviando mensagem em ${messageChunks.length} partes`);
      
      for (let i = 0; i < messageChunks.length; i++) {
        const chunk = messageChunks[i];
        const isLast = i === messageChunks.length - 1;
        
        // Enviar chunk
        const result = await sendResponseViaCodeChat(instanceId, chatId, chunk);
        if (!result.success) {
          return result;
        }
        
        // Delay entre chunks (exceto no √∫ltimo)
        if (!isLast) {
          const interChunkDelay = Math.random() * 1000 + 500; // 500-1500ms
          console.log(`‚è±Ô∏è [HUMANIZATION] Aguardando ${interChunkDelay}ms entre chunks`);
          await new Promise(resolve => setTimeout(resolve, interChunkDelay));
        }
      }
    } else {
      // Enviar mensagem √∫nica
      const result = await sendResponseViaCodeChat(instanceId, chatId, message);
      if (!result.success) {
        return result;
      }
    }
    
    // Definir presence como 'available' ap√≥s envio
    await setPresence(instanceId, chatId, 'available');
    
    console.log('‚úÖ [HUMANIZATION] Processamento humanizado conclu√≠do');
    return { success: true };
    
  } catch (error) {
    console.error('‚ùå [HUMANIZATION] Erro no processamento humanizado:', error);
    return { success: false, error: error.message };
  }
}

// üé≠ Fun√ß√£o para definir presence via CodeChat v2.2.1
async function setPresence(instanceId: string, chatId: string, presence: 'available' | 'composing' | 'unavailable'): Promise<void> {
  try {
    // Buscar business_token
    const { data: instanceData } = await supabase
      .from('whatsapp_instances')
      .select(`
        clients:client_id (
          business_token
        )
      `)
      .eq('instance_id', instanceId)
      .single();

    if (!instanceData?.clients?.business_token) {
      console.warn('‚ö†Ô∏è [PRESENCE] Business token n√£o encontrado para presence');
      return;
    }

    const businessToken = instanceData.clients.business_token;
    
    // ENDPOINT CORRETO: v2.2.1 usa /api/v2/instance/:instanceId/send/presence
    const endpoint = `https://api.yumer.com.br/api/v2/instance/${instanceId}/send/presence`;
    
    const presenceData = {
      number: chatId,
      presence: presence
    };

    console.log('üé≠ [PRESENCE] Enviando presence via CodeChat v2.2.1:', {
      endpoint,
      presence,
      chatId
    });

    await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      },
      body: JSON.stringify(presenceData)
    });

    console.log(`üé≠ [PRESENCE] Status definido para: ${presence}`);
  } catch (error) {
    console.warn('‚ö†Ô∏è [PRESENCE] Erro ao definir presence via CodeChat v2.2.1:', error.message);
  }
}

// ‚è±Ô∏è Fun√ß√£o para calcular delay de digita√ß√£o realista
function calculateTypingDelay(message: string): number {
  // Simular velocidade de digita√ß√£o humana (40-60 palavras por minuto)
  const words = message.split(' ').length;
  const baseDelay = words * 200; // ~50 WPM
  const variation = baseDelay * 0.3; // 30% de varia√ß√£o
  const randomVariation = (Math.random() - 0.5) * variation;
  
  // Limites m√≠nimo e m√°ximo
  const delay = Math.max(1000, Math.min(8000, baseDelay + randomVariation));
  
  return Math.round(delay);
}

// üìù Fun√ß√£o para dividir mensagem inteligentemente
function splitMessageIntelligently(message: string): string[] {
  const maxLength = 160; // Limite t√≠pico do WhatsApp
  
  if (message.length <= maxLength) {
    return [message];
  }
  
  // Dividir por frases primeiro
  const sentences = message.split(/(?<=[.!?])\s+/);
  const chunks: string[] = [];
  let currentChunk = '';
  
  for (const sentence of sentences) {
    if ((currentChunk + ' ' + sentence).length > maxLength) {
      if (currentChunk) {
        chunks.push(currentChunk.trim());
        currentChunk = sentence;
      } else {
        // Frase muito longa, dividir por palavras
        const words = sentence.split(' ');
        let wordChunk = '';
        for (const word of words) {
          if ((wordChunk + ' ' + word).length > maxLength) {
            if (wordChunk) {
              chunks.push(wordChunk.trim());
              wordChunk = word;
            } else {
              chunks.push(word); // Palavra muito longa
            }
          } else {
            wordChunk = wordChunk ? wordChunk + ' ' + word : word;
          }
        }
        if (wordChunk) {
          currentChunk = wordChunk;
        }
      }
    } else {
      currentChunk = currentChunk ? currentChunk + ' ' + sentence : sentence;
    }
  }
  
  if (currentChunk) {
    chunks.push(currentChunk.trim());
  }
  
  return chunks.filter(chunk => chunk.length > 0);
}
