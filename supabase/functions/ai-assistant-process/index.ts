
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.50.0';

// ===== INTERFACES PARA HUMANIZA√á√ÉO =====
interface HumanizedPersonality {
  id: string;
  name: string;
  tone: 'formal' | 'casual' | 'friendly' | 'professional' | 'empathetic';
  responseDelay: { min: number; max: number };
  typingSpeed: number; // WPM
  reactionProbability: number; // 0-1
}

// ===== INTERFACE PARA RETRY LOGIC =====
interface RetryOptions {
  maxAttempts: number;
  initialDelay: number;
  maxDelay: number;
  backoffMultiplier: number;
}

// ===== FUN√á√ÉO DE RETRY COM BACKOFF =====
async function retryWithBackoff<T>(
  operation: () => Promise<T>,
  options: RetryOptions = {
    maxAttempts: 3,
    initialDelay: 1000,
    maxDelay: 10000,
    backoffMultiplier: 2
  },
  operationName: string = 'Operation'
): Promise<T> {
  let lastError: Error;
  
  for (let attempt = 1; attempt <= options.maxAttempts; attempt++) {
    try {
      console.log(`üîÑ [RETRY] ${operationName} - Tentativa ${attempt}/${options.maxAttempts}`);
      const result = await operation();
      
      if (attempt > 1) {
        console.log(`‚úÖ [RETRY] ${operationName} sucedeu na tentativa ${attempt}`);
      }
      
      return result;
    } catch (error: any) {
      lastError = error;
      console.warn(`‚ö†Ô∏è [RETRY] ${operationName} falhou na tentativa ${attempt}:`, error.message);
      
      if (attempt === options.maxAttempts) {
        console.error(`‚ùå [RETRY] ${operationName} falhou ap√≥s ${options.maxAttempts} tentativas`);
        break;
      }
      
      // Calcular delay com backoff exponencial
      const delay = Math.min(
        options.initialDelay * Math.pow(options.backoffMultiplier, attempt - 1),
        options.maxDelay
      );
      
      console.log(`‚è≥ [RETRY] Aguardando ${delay}ms antes da pr√≥xima tentativa...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw lastError;
}

interface HumanizedConfig {
  enabled: boolean;
  personality: HumanizedPersonality;
  behavior: {
    typing: {
      enabled: boolean;
      minDuration: number;
      maxDuration: number;
    };
    presence: {
      enabled: boolean;
      showTyping: boolean;
    };
    messageHandling: {
      splitLongMessages: boolean;
      maxCharsPerChunk: number;
      delayBetweenChunks: number;
    };
  };
}

// ===== PERSONALIDADES PADR√ÉO =====
const defaultPersonalities: HumanizedPersonality[] = [
  {
    id: 'friendly-assistant',
    name: 'Assistente Amig√°vel',
    tone: 'friendly',
    responseDelay: { min: 2000, max: 4000 },
    typingSpeed: 45,
    reactionProbability: 0.7
  },
  {
    id: 'professional-support',
    name: 'Suporte Profissional',
    tone: 'professional',
    responseDelay: { min: 1500, max: 3000 },
    typingSpeed: 60,
    reactionProbability: 0.3
  }
];

// ===== CONFIGURA√á√ÉO HUMANIZADA PADR√ÉO =====
const defaultHumanizedConfig: HumanizedConfig = {
  enabled: true,
  personality: defaultPersonalities[0],
  behavior: {
    typing: {
      enabled: true,
      minDuration: 1000,
      maxDuration: 5000
    },
    presence: {
      enabled: true,
      showTyping: true
    },
    messageHandling: {
      splitLongMessages: true,
      maxCharsPerChunk: 350,
      delayBetweenChunks: 2500
    }
  }
};

const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
const supabase = createClient(supabaseUrl, supabaseKey);

const globalOpenAIApiKey = Deno.env.get('OPENAI_API_KEY');

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('ü§ñ [AI-ASSISTANT] üöÄ PROCESSANDO REQUISI√á√ÉO - TIMESTAMP:', new Date().toISOString());
    
    const requestBody = await req.json();
    console.log('üìã [AI-ASSISTANT] Body completo recebido:', JSON.stringify(requestBody, null, 2));
    
    let { 
      ticketId, 
      message, 
      messages,
      clientId,
      instanceId,
      assistant,
      context 
    } = requestBody;
    
    // üîç CORRE√á√ÉO: Se ticketId √© um objeto, extrair o ID real
    if (ticketId && typeof ticketId === 'object' && ticketId.id) {
      console.log('üîß [AI-ASSISTANT] ticketId √© objeto, extraindo ID:', ticketId.id);
      ticketId = ticketId.id;
    }
    
    // üîç LOGS DETALHADOS DOS PAR√ÇMETROS
    console.log('üîç [AI-ASSISTANT] Par√¢metros extra√≠dos:', {
      ticketId: ticketId,
      hasMessage: !!message,
      hasMessages: !!messages,
      messagesLength: messages ? messages.length : 0,
      clientId: clientId,
      instanceId: instanceId,
      assistantId: assistant?.id,
      assistantName: assistant?.name,
      assistantModel: assistant?.model,
      contextCustomerName: context?.customerName,
      contextPhoneNumber: context?.phoneNumber,
      contextChatId: context?.chatId
    });
    
    // ===== VERIFICAR DUPLICA√á√ÉO DE MENSAGENS =====
    if (messages && messages.length > 0) {
      console.log('üîç [AI-ASSISTANT] Verificando duplica√ß√£o de mensagens...');
      
      const messageIds = messages.map(msg => msg.messageId).filter(Boolean);
      if (messageIds.length > 0) {
        const { data: existingMessages } = await supabase
          .from('ticket_messages')
          .select('message_id')
          .in('message_id', messageIds)
          .eq('is_ai_response', true);
        
        if (existingMessages && existingMessages.length > 0) {
          console.log('‚ö†Ô∏è [AI-ASSISTANT] Mensagens j√° processadas detectadas:', existingMessages.map(m => m.message_id));
          
          // Se todas as mensagens j√° foram processadas, retornar sucesso sem processar
          if (existingMessages.length === messageIds.length) {
            console.log('üîÑ [AI-ASSISTANT] Todas as mensagens j√° foram processadas - evitando duplica√ß√£o');
            return new Response(JSON.stringify({
              success: true,
              message: 'Mensagens j√° processadas - duplica√ß√£o evitada',
              duplicateCount: existingMessages.length
            }), {
              headers: { ...corsHeaders, 'Content-Type': 'application/json' }
            });
          }
          
          // Filtrar mensagens j√° processadas
          const processedIds = existingMessages.map(m => m.message_id);
          messages = messages.filter(msg => !processedIds.includes(msg.messageId));
          console.log('üîÑ [AI-ASSISTANT] Filtradas mensagens duplicadas, restantes:', messages.length);
        }
      }
    }

    // üîç BUSCAR DADOS FALTANTES DO TICKET NO BANCO (fallback cr√≠tico)
    let resolvedClientId = clientId;
    let resolvedInstanceId = instanceId;
    let resolvedContext = context;
    let resolvedAssistant = assistant;
    
    if (!clientId || !instanceId || !context?.chatId || !assistant) {
      console.log('üîç [AI-ASSISTANT] Buscando dados faltantes no banco...');
      
      const { data: ticketData, error: ticketError } = await supabase
        .from('conversation_tickets')
        .select(`
          client_id, 
          instance_id, 
          chat_id, 
          customer_id, 
          assigned_assistant_id,
          assigned_queue_id,
          customers(name, phone),
          assistants(id, name, model, prompt, triggers, advanced_settings, is_active)
        `)
        .eq('id', ticketId)
        .single();
      
      if (ticketError) {
        console.error('‚ùå [AI-ASSISTANT] Erro ao buscar dados do ticket:', ticketError);
        throw new Error(`Ticket n√£o encontrado: ${ticketId}`);
      }
      
      // ‚úÖ VALIDA√á√ÉO CR√çTICA: Verificar se o ticket tem fila associada
      if (!ticketData.assigned_queue_id) {
        console.log('üö´ [AI-ASSISTANT] Ticket sem fila associada - IA n√£o deve responder');
        console.log('üìä [AI-ASSISTANT] Detalhes do ticket sem fila:', {
          ticketId,
          clientId: ticketData.client_id,
          chatId: ticketData.chat_id,
          customerName: ticketData.customers?.name,
          assignedQueueId: ticketData.assigned_queue_id
        });
        
        return new Response(JSON.stringify({
          success: false,
          message: 'Ticket sem fila associada - IA n√£o processar√° mensagens',
          reason: 'NO_QUEUE_ASSIGNED',
          ticketId,
          timestamp: new Date().toISOString()
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
      }
      
      // üîç BUSCAR ASSISTENTE DA FILA (n√£o do ticket)
      console.log('üîç [AI-ASSISTANT] Buscando assistente da fila:', ticketData.assigned_queue_id);
      
      const { data: queueData, error: queueError } = await supabase
        .from('queues')
        .select(`
          id,
          name,
          assistant_id,
          is_active,
          assistants(id, name, model, prompt, triggers, advanced_settings, is_active)
        `)
        .eq('id', ticketData.assigned_queue_id)
        .eq('is_active', true)
        .single();
      
      if (queueError || !queueData) {
        console.log('üö´ [AI-ASSISTANT] Fila n√£o encontrada ou inativa:', {
          queueId: ticketData.assigned_queue_id,
          error: queueError?.message
        });
        
        return new Response(JSON.stringify({
          success: false,
          message: 'Fila n√£o encontrada ou inativa - IA n√£o processar√° mensagens',
          reason: 'QUEUE_NOT_FOUND_OR_INACTIVE',
          queueId: ticketData.assigned_queue_id,
          timestamp: new Date().toISOString()
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
      }
      
      if (!queueData.assistants || !queueData.assistants.is_active) {
        console.log('üö´ [AI-ASSISTANT] Fila sem assistente ou assistente inativo:', {
          queueId: queueData.id,
          queueName: queueData.name,
          assistantId: queueData.assistant_id,
          hasAssistant: !!queueData.assistants,
          assistantActive: queueData.assistants?.is_active
        });
        
        return new Response(JSON.stringify({
          success: false,
          message: 'Fila sem assistente ativo - IA n√£o processar√° mensagens',
          reason: 'NO_ACTIVE_ASSISTANT',
          queueId: queueData.id,
          queueName: queueData.name,
          timestamp: new Date().toISOString()
        }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        });
      }
      
      // ‚úÖ TUDO V√ÅLIDO: Resolver dados
      resolvedClientId = clientId || ticketData.client_id;
      resolvedInstanceId = instanceId || ticketData.instance_id;
      resolvedContext = context || {
        chatId: ticketData.chat_id,
        customerName: ticketData.customers?.name || 'Cliente',
        phoneNumber: ticketData.customers?.phone || 'N/A'
      };
      
      // Usar assistente da fila
      resolvedAssistant = queueData.assistants;
      console.log('‚úÖ [AI-ASSISTANT] Assistente da fila encontrado:', {
        assistantName: resolvedAssistant.name,
        queueName: queueData.name,
        queueId: queueData.id
      });
      
      console.log('‚úÖ [AI-ASSISTANT] Dados resolvidos do banco:', {
        clientId: resolvedClientId,
        instanceId: resolvedInstanceId,
        chatId: resolvedContext.chatId,
        customerName: resolvedContext.customerName,
        assistantName: resolvedAssistant?.name || 'Assistente Padr√£o'
      });
    }

    // üìù SUPORTAR BATCHES: Combinar m√∫ltiplas mensagens como contexto √∫nico
    const isBatch = messages && Array.isArray(messages) && messages.length > 0;
    
    let messageContent: string;
    if (isBatch) {
      // Processar batch de mensagens
      const messageTexts = messages.map(msg => msg.content).filter(Boolean);
      messageContent = messageTexts.join(' ');
      console.log(`üì¶ [BATCH-IA] Processando batch de ${messages.length} mensagens: "${messageContent}"`);
    } else {
      messageContent = message;
      console.log(`üìù [SINGLE-IA] Processando mensagem √∫nica: "${messageContent}"`);
    }

    // ‚úÖ VALIDA√á√ÉO CR√çTICA: Verificar se os dados essenciais est√£o presentes
    if (!ticketId) {
      throw new Error('ticketId √© obrigat√≥rio');
    }
    
    if (!messageContent && !message && (!messages || messages.length === 0)) {
      throw new Error('Nenhum conte√∫do de mensagem fornecido');
    }

    // üéµ INTERCEPTA√á√ÉO PRECOCE SUPER AGRESSIVA: Detectar comandos ANTES da IA
    const libraryCommandMatch = messageContent.match(/^audio\s+([a-zA-Z0-9]+)$/i);
    const imageCommandMatch = messageContent.match(/^image\s+([a-zA-Z0-9_-]+)$/i);
    
    // üé• M√öLTIPLAS VERIFICA√á√ïES PARA V√çDEO - CAPTURA SUPER AGRESSIVA
    const videoRegexStrict = /^video\s+([a-zA-Z0-9_-]+)$/i;
    const videoRegexLoose = /video\s+([a-zA-Z0-9_-]+)/i;
    const messageClean = messageContent.trim().toLowerCase();
    
    // M√∫ltiplas formas de capturar comando de v√≠deo
    let videoCommandMatch = messageContent.trim().match(videoRegexStrict);
    if (!videoCommandMatch) {
      videoCommandMatch = messageContent.trim().match(videoRegexLoose);
    }
    
    // üö® FALLBACK SUPER AGRESSIVO: Se cont√©m "video" E "teste2", for√ßar captura
    const containsVideo = messageClean.includes('video');
    const containsTeste2 = messageClean.includes('teste2');
    const forceVideoCapture = containsVideo && containsTeste2;
    
    if (forceVideoCapture && !videoCommandMatch) {
      console.log('üö® [EARLY-INTERCEPT] FALLBACK ATIVADO: For√ßando captura de comando video teste2');
      videoCommandMatch = ['video teste2', 'teste2']; // Simular match
    }
    
    console.log('üîç [EARLY-INTERCEPT] ===== DIAGN√ìSTICO ULTRA-DETALHADO DE COMANDOS =====');
    console.log('üîç [EARLY-INTERCEPT] MessageContent RAW:', JSON.stringify(messageContent));
    console.log('üîç [EARLY-INTERCEPT] MessageContent chars:', messageContent.split('').map(c => `"${c}" (${c.charCodeAt(0)})`));
    console.log('üîç [EARLY-INTERCEPT] MessageClean:', JSON.stringify(messageClean));
    console.log('üîç [EARLY-INTERCEPT] Verifica√ß√µes de v√≠deo:', {
      regexStrict: videoRegexStrict.test(messageContent.trim()),
      regexLoose: videoRegexLoose.test(messageContent.trim()),
      containsVideo: containsVideo,
      containsTeste2: containsTeste2,
      forceVideoCapture: forceVideoCapture,
      finalVideoMatch: !!videoCommandMatch
    });
    console.log('üîç [EARLY-INTERCEPT] Detectando comandos FINAIS:', {
      messageContent: messageContent,
      libraryCommandMatch: !!libraryCommandMatch,
      imageCommandMatch: !!imageCommandMatch,
      videoCommandMatch: !!videoCommandMatch,
      imageCommandValue: imageCommandMatch ? imageCommandMatch[1] : null,
      videoCommandValue: videoCommandMatch ? videoCommandMatch[1] : null,
      forceVideoCapture: forceVideoCapture
    });
    console.log('üîç [EARLY-INTERCEPT] ===== FIM DO DIAGN√ìSTICO =====');
    
    if (libraryCommandMatch) {
      console.log('üéµ [EARLY-INTERCEPT] ‚ö° COMANDO DE BIBLIOTECA DETECTADO - PROCESSANDO IMEDIATAMENTE');
      console.log('üéµ [EARLY-INTERCEPT] Comando:', libraryCommandMatch[0]);
      console.log('üéµ [EARLY-INTERCEPT] Nome do √°udio:', libraryCommandMatch[1]);
      
      // Buscar business token ANTES do processamento
      const { data: client } = await supabase
        .from('clients')
        .select('business_token')
        .eq('id', resolvedClientId)
        .single();
      
      if (client?.business_token) {
        console.log('‚úÖ [EARLY-INTERCEPT] Business token encontrado para processamento imediato');
        
        // Processar comando de biblioteca imediatamente sem passar pela IA
        const audioResult = await processAudioCommands(messageContent, ticketId, resolvedAssistant, resolvedInstanceId, client.business_token);
        
        if (audioResult.hasAudioCommands && audioResult.processedCount > 0) {
          console.log('‚úÖ [EARLY-INTERCEPT] Comando de biblioteca processado com sucesso - RETORNANDO IMEDIATAMENTE');
          
          return new Response(JSON.stringify({
            success: true,
            message: 'Comando de √°udio da biblioteca processado',
            audioCommandsProcessed: audioResult.processedCount,
            onlyAudioCommands: true,
            timestamp: new Date().toISOString()
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' }
          });
        }
      } else {
        console.warn('‚ö†Ô∏è [EARLY-INTERCEPT] Business token n√£o encontrado - comando de biblioteca ser√° ignorado');
      }
    }
    
    // üñºÔ∏è INTERCEPTA√á√ÉO PRECOCE: Detectar comandos de imagem ANTES da IA
    if (imageCommandMatch) {
      console.log('üñºÔ∏è [EARLY-INTERCEPT] ‚ö° COMANDO DE IMAGEM DETECTADO - PROCESSANDO IMEDIATAMENTE');
      console.log('üñºÔ∏è [EARLY-INTERCEPT] Comando:', imageCommandMatch[0]);
      console.log('üñºÔ∏è [EARLY-INTERCEPT] Trigger da imagem:', imageCommandMatch[1]);
      
      // Buscar business token ANTES do processamento
      const { data: client } = await supabase
        .from('clients')
        .select('business_token')
        .eq('id', resolvedClientId)
        .single();
      
      if (client?.business_token) {
        console.log('‚úÖ [EARLY-INTERCEPT] Business token encontrado para processamento de imagem');
        
        // Processar comando de imagem SEGUINDO A MESMA L√ìGICA DO √ÅUDIO
        const imageResult = await processImageCommands(messageContent, {
          assistantId: resolvedAssistant.id,
          instanceId: resolvedInstanceId,
          chatId: resolvedContext.chatId,
          businessToken: client.business_token
        });
        
        if (imageResult.hasImageCommands && imageResult.processedCount > 0) {
          console.log('‚úÖ [EARLY-INTERCEPT] Comando de imagem processado com sucesso - PARANDO EXECU√á√ÉO');
          console.log('üõë [EARLY-INTERCEPT] RETORNO IMEDIATO EXECUTADO - Edge function finalizar√° aqui');
          
          // Salvar informa√ß√£o de que a mensagem foi processada para evitar duplica√ß√£o
          try {
            await supabase
              .from('ticket_messages')
              .update({ ai_processed: true, ai_response_timestamp: new Date().toISOString() })
              .eq('ticket_id', ticketId)
              .eq('content', messageContent);
            console.log('‚úÖ [EARLY-INTERCEPT] Mensagem marcada como processada');
          } catch (error) {
            console.log('‚ö†Ô∏è [EARLY-INTERCEPT] Erro ao marcar mensagem como processada:', error);
          }
          
          return new Response(JSON.stringify({
            success: true,
            message: 'Comando de imagem da biblioteca processado',
            imageCommandsProcessed: imageResult.processedCount,
            onlyImageCommands: true,
            earlyIntercept: true,
            timestamp: new Date().toISOString()
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' }
          });
        }
      } else {
        console.warn('‚ö†Ô∏è [EARLY-INTERCEPT] Business token n√£o encontrado - comando de imagem ser√° ignorado');
      }
    }
    
    // üé• INTERCEPTA√á√ÉO PRECOCE: Detectar comandos de v√≠deo ANTES da IA
    if (videoCommandMatch) {
      console.log('üé• [EARLY-INTERCEPT] ‚ö° COMANDO DE V√çDEO DETECTADO - PROCESSANDO IMEDIATAMENTE');
      console.log('üé• [EARLY-INTERCEPT] Comando:', videoCommandMatch[0]);
      console.log('üé• [EARLY-INTERCEPT] Trigger do v√≠deo:', videoCommandMatch[1]);
      console.log('üé• [EARLY-INTERCEPT] MessageContent original:', messageContent);
      console.log('üé• [EARLY-INTERCEPT] Regex match completo:', JSON.stringify(videoCommandMatch));
      
      // Buscar business token ANTES do processamento
      const { data: client } = await supabase
        .from('clients')
        .select('business_token')
        .eq('id', resolvedClientId)
        .single();
      
      if (client?.business_token) {
        console.log('‚úÖ [EARLY-INTERCEPT] Business token encontrado para processamento de v√≠deo');
        
        // Processar comando de v√≠deo SEGUINDO A MESMA L√ìGICA DO √ÅUDIO E IMAGEM
        const videoResult = await processVideoCommands(messageContent, {
          assistantId: resolvedAssistant.id,
          instanceId: resolvedInstanceId,
          chatId: resolvedContext.chatId,
          businessToken: client.business_token
        });
        
        if (videoResult.hasVideoCommands && videoResult.processedCount > 0) {
          console.log('‚úÖ [EARLY-INTERCEPT] Comando de v√≠deo processado com sucesso - PARANDO EXECU√á√ÉO');
          console.log('üõë [EARLY-INTERCEPT] RETORNO IMEDIATO EXECUTADO - Edge function finalizar√° aqui');
          
          // Salvar informa√ß√£o de que a mensagem foi processada para evitar duplica√ß√£o
          try {
            await supabase
              .from('ticket_messages')
              .update({ ai_processed: true, ai_response_timestamp: new Date().toISOString() })
              .eq('ticket_id', ticketId)
              .eq('content', messageContent);
            console.log('‚úÖ [EARLY-INTERCEPT] Mensagem marcada como processada');
          } catch (error) {
            console.log('‚ö†Ô∏è [EARLY-INTERCEPT] Erro ao marcar mensagem como processada:', error);
          }
          
          return new Response(JSON.stringify({
            success: true,
            message: 'Comando de v√≠deo da biblioteca processado',
            videoCommandsProcessed: videoResult.processedCount,
            onlyVideoCommands: true,
            earlyIntercept: true,
            timestamp: new Date().toISOString()
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' }
          });
        }
      } else {
        console.warn('‚ö†Ô∏è [EARLY-INTERCEPT] Business token n√£o encontrado - comando de v√≠deo ser√° ignorado');
      }
    }

    // üîí VERIFICA√á√ÉO ANTI-DUPLICA√á√ÉO AP√ìS EARLY INTERCEPT
    console.log('üîÑ [FLOW-CHECK] Continuando para processamento normal da IA...');
    console.log('üîÑ [FLOW-CHECK] Se chegou aqui, early intercept N√ÉO foi executado ou falhou');
    
    // üîë PRIORIZA√á√ÉO DE API KEYS: Cliente espec√≠fico > Global
    let openAIApiKey = globalOpenAIApiKey;
    let keySource = 'global';

    // ‚úÖ BUSCAR CONFIGURA√á√ïES COM RETRY LOGIC
    console.log('üîç [CONFIG] Buscando configura√ß√µes do cliente com retry...');
    
    const [clientConfigResult, memoryResult, messagesResult] = await Promise.allSettled([
      // Buscar API Key espec√≠fica do cliente com retry
      retryWithBackoff(
        () => supabase
          .from('client_ai_configs')
          .select('openai_api_key, default_model')
          .eq('client_id', resolvedClientId)
          .single(),
        { maxAttempts: 3, initialDelay: 500, maxDelay: 2000, backoffMultiplier: 2 },
        'Buscar config do cliente'
      ),
      
      // Buscar mem√≥ria conversacional com retry
      retryWithBackoff(
        () => supabase
          .from('conversation_context')
          .select('*')
          .eq('client_id', resolvedClientId)
          .eq('chat_id', resolvedContext.chatId)
          .eq('instance_id', resolvedInstanceId)
          .single(),
        { maxAttempts: 2, initialDelay: 300, maxDelay: 1000, backoffMultiplier: 2 },
        'Buscar mem√≥ria conversacional'
      ),
      
      // Buscar hist√≥rico de mensagens com retry
      retryWithBackoff(
        () => supabase
          .from('ticket_messages')
          .select('content, from_me, sender_name, timestamp, message_id')
          .eq('ticket_id', ticketId)
          .order('timestamp', { ascending: false })
          .limit(50),
        { maxAttempts: 2, initialDelay: 300, maxDelay: 1000, backoffMultiplier: 2 },
        'Buscar hist√≥rico de mensagens'
      )
    ]);

    // ‚úÖ PROCESSAR API KEY DO CLIENTE COM RETRY
    if (clientConfigResult.status === 'fulfilled' && clientConfigResult.value?.data?.openai_api_key) {
      openAIApiKey = clientConfigResult.value.data.openai_api_key;
      keySource = 'client';
      console.log('üîë [AI-ASSISTANT] ‚úÖ API Key espec√≠fica do cliente encontrada');
    } else {
      console.log('üîë [AI-ASSISTANT] ‚ö†Ô∏è Cliente sem API Key - usando global:', 
        clientConfigResult.status === 'rejected' ? clientConfigResult.reason?.message : 'sem config');
    }

    // ‚úÖ VALIDA√á√ÉO CR√çTICA: Business Token ANTES de qualquer opera√ß√£o
    console.log('üîê [AI-ASSISTANT] Verificando business token para cliente:', resolvedClientId);
    
    let businessToken: string | null = null;
    try {
      const businessTokenResult = await retryWithBackoff(
        async () => {
          const { data: instanceData, error } = await supabase
            .from('whatsapp_instances')
            .select(`
              instance_id,
              client_id,
              yumer_instance_name,
              clients:client_id (
                business_token
              )
            `)
            .eq('instance_id', resolvedInstanceId)
            .single();
          
          if (error) throw error;
          if (!instanceData?.clients?.business_token) {
            throw new Error('Business token n√£o encontrado');
          }
          
          return instanceData.clients.business_token;
        },
        { maxAttempts: 3, initialDelay: 500, maxDelay: 2000, backoffMultiplier: 2 },
        'Buscar business token'
      );
      
      businessToken = businessTokenResult;
      console.log('‚úÖ [AI-ASSISTANT] Business token encontrado para cliente');
      
    } catch (error) {
      console.error('‚ùå [AI-ASSISTANT] ERRO CR√çTICO - Business token n√£o encontrado:', error);
      return new Response(JSON.stringify({
        success: false,
        error: 'Business token n√£o configurado para este cliente',
        reason: 'MISSING_BUSINESS_TOKEN',
        clientId: resolvedClientId,
        timestamp: new Date().toISOString()
      }), {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      });
    }

    console.log('ü§ñ [AI-ASSISTANT] Dados recebidos:', {
      ticketId,
      instanceId,
      assistantName: assistant?.name,
      messageLength: messageContent?.length || 0,
      isBatch: !!messages,
      batchSize: messages?.length || 1,
      customerName: context?.customerName,
      keySource,
      hasOpenAIKey: !!openAIApiKey
    });
    
    // üì¶ LOG ESPEC√çFICO PARA BATCHES
    if (isBatch) {
      console.log('üì¶ [BATCH-IA] Processando batch com as seguintes mensagens:');
      messages.forEach((msg, index) => {
        console.log(`  ${index + 1}. "${msg.content}" (${new Date(msg.timestamp).toLocaleTimeString()})`);
      });
      console.log(`üì¶ [BATCH-IA] Contexto combinado: "${messageContent}"`);
    }

    // Verificar se OpenAI API key est√° configurada
    if (!openAIApiKey) {
      console.error('‚ùå [AI-ASSISTANT] OpenAI API key n√£o configurada');
      return new Response(
        JSON.stringify({ 
          error: 'OpenAI API key not configured',
          message: keySource === 'client' 
            ? 'Cliente precisa configurar sua API Key da OpenAI'
            : 'Configure OPENAI_API_KEY global nas Edge Function Secrets'
        }),
        { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // Processar mem√≥ria conversacional
    let conversationMemory = null;
    if (memoryResult.status === 'fulfilled' && memoryResult.value.data) {
      conversationMemory = memoryResult.value.data;
      console.log('üß† [CONTEXT] Mem√≥ria conversacional carregada:', {
        hasMemory: !!conversationMemory,
        customerName: conversationMemory?.customer_name,
        keyInfoKeys: conversationMemory?.key_information ? Object.keys(conversationMemory.key_information) : [],
        topicsCount: conversationMemory?.last_topics?.length || 0
      });
    } else {
      console.log('üß† [CONTEXT] Nenhuma mem√≥ria conversacional encontrada (primeira conversa)');
    }

    // Processar hist√≥rico de mensagens
    const allRecentMessages = messagesResult.status === 'fulfilled' && messagesResult.value.data 
      ? messagesResult.value.data 
      : [];

    // üßπ REMOVER MENSAGENS DUPLICADAS por message_id e conte√∫do
    const uniqueMessages = [];
    const seenMessageIds = new Set();
    const seenContentKey = new Set();
    
    if (allRecentMessages && allRecentMessages.length > 0) {
      for (const msg of allRecentMessages) {
        const contentKey = `${msg.from_me}-${msg.content}-${msg.sender_name}`;
        
        if (!seenMessageIds.has(msg.message_id) && !seenContentKey.has(contentKey)) {
          seenMessageIds.add(msg.message_id);
          seenContentKey.add(contentKey);
          uniqueMessages.push(msg);
        }
      }
    }

    console.log('üßπ [CONTEXT] Limpeza de duplicatas:', {
      totalMessages: allRecentMessages?.length || 0,
      uniqueMessages: uniqueMessages.length,
      duplicatesRemoved: (allRecentMessages?.length || 0) - uniqueMessages.length
    });

    // üîÑ CONSTRUIR CONTEXTO CONVERSACIONAL ENRIQUECIDO
    let conversationContext = '';
    if (uniqueMessages.length > 0) {
      // Pegar apenas os √∫ltimos 25 para n√£o sobrecarregar o contexto
      const contextMessages = uniqueMessages.slice(0, 25).reverse(); // Ordenar cronologicamente
      
      conversationContext = contextMessages
        .map(msg => {
          const sender = msg.from_me ? 'Assistente' : (msg.sender_name || 'Cliente');
          return `${sender}: ${msg.content}`;
        })
        .join('\n');
    }

    // üß† ADICIONAR INFORMA√á√ïES DA MEM√ìRIA CONVERSACIONAL
    let memoryContext = '';
    if (conversationMemory) {
      const memoryParts = [];
      
      if (conversationMemory.customer_name) {
        memoryParts.push(`Nome do cliente: ${conversationMemory.customer_name}`);
      }
      
      if (conversationMemory.conversation_summary) {
        memoryParts.push(`Resumo da conversa: ${conversationMemory.conversation_summary}`);
      }
      
      if (conversationMemory.key_information && Object.keys(conversationMemory.key_information).length > 0) {
        memoryParts.push(`Informa√ß√µes importantes: ${JSON.stringify(conversationMemory.key_information)}`);
      }
      
      if (conversationMemory.last_topics && conversationMemory.last_topics.length > 0) {
        memoryParts.push(`T√≥picos recentes: ${conversationMemory.last_topics.join(', ')}`);
      }
      
      if (conversationMemory.personality_notes) {
        memoryParts.push(`Notas de personalidade: ${conversationMemory.personality_notes}`);
      }
      
      if (memoryParts.length > 0) {
        memoryContext = '\n\n--- CONTEXTO DA CONVERSA ---\n' + memoryParts.join('\n') + '\n--- FIM DO CONTEXTO ---\n';
      }
    }

    // ‚úÖ VALIDA√á√ÉO DO ASSISTENTE: Garantir que existe e tem configura√ß√µes m√≠nimas
    const safeAssistant = resolvedAssistant || {
      id: 'default',
      name: 'Assistente IA',
      model: 'gpt-4o-mini',
      prompt: 'Voc√™ √© um assistente √∫til e prestativo.'
    };

    console.log('ü§ñ [AI-ASSISTANT] Usando assistente:', {
      id: safeAssistant.id,
      name: safeAssistant.name,
      model: safeAssistant.model,
      hasPrompt: !!safeAssistant.prompt
    });

    // ‚úÖ NOVA: Detec√ß√£o e processamento autom√°tico de m√≠dia
    let mediaAnalysis = '';
    let processedContent = messageContent;
    
    // Buscar mensagens de m√≠dia n√£o processadas
    const { data: unprocessedMessages } = await supabase
      .from('ticket_messages')
      .select('*')
      .eq('ticket_id', ticketId)
      .in('message_type', ['image', 'video', 'audio', 'document'])
      .is('media_transcription', null)
      .order('timestamp', { ascending: false })
      .limit(5);

    if (unprocessedMessages && unprocessedMessages.length > 0) {
      console.log('üé¨ [MULTIMEDIA] Encontradas mensagens de m√≠dia para processar:', unprocessedMessages.length);
      
      for (const mediaMsg of unprocessedMessages) {
        try {
          let analysis = '';
          
          switch (mediaMsg.message_type) {
            case 'image':
              if (mediaMsg.image_base64) {
                analysis = await processImageWithVision(mediaMsg.image_base64, openAIApiKey);
                mediaAnalysis += `\n[IMAGEM ANALISADA]: ${analysis}`;
              }
              break;
              
            case 'audio':
              if (mediaMsg.audio_base64) {
                analysis = await processAudioTranscription(mediaMsg.audio_base64, openAIApiKey);
                mediaAnalysis += `\n[√ÅUDIO TRANSCRITO]: ${analysis}`;
              }
              break;
              
            case 'video':
              if (mediaMsg.video_base64) {
                analysis = await processVideoAnalysis(mediaMsg.video_base64, openAIApiKey);
                mediaAnalysis += `\n[V√çDEO ANALISADO]: ${analysis}`;
              }
              break;
              
            case 'document':
              if (mediaMsg.document_base64) {
                analysis = await processDocumentExtraction(mediaMsg.document_base64, mediaMsg.media_mime_type);
                mediaAnalysis += `\n[DOCUMENTO EXTRA√çDO]: ${analysis}`;
              }
              break;
          }
          
          // Salvar an√°lise no banco
          if (analysis) {
            await supabase
              .from('ticket_messages')
              .update({ media_transcription: analysis })
              .eq('id', mediaMsg.id);
          }
          
        } catch (error) {
          console.error('‚ùå [MULTIMEDIA] Erro ao processar m√≠dia:', error);
        }
      }
    }

    // Adicionar an√°lises de m√≠dia ao contexto
    if (mediaAnalysis) {
      processedContent = `${messageContent}\n\n--- M√çDIAS ANALISADAS ---${mediaAnalysis}\n--- FIM DAS AN√ÅLISES ---`;
    }

    // üéØ CONSTRUIR PROMPT PARA BATCH: Considerar todas as mensagens como contexto √∫nico
    const isBatchProcessing = messages && Array.isArray(messages) && messages.length > 1;
    const contextMessage = isBatchProcessing 
      ? `\n\nNOTA IMPORTANTE: O usu√°rio enviou ${messages.length} mensagens em sequ√™ncia r√°pida. Estas mensagens devem ser consideradas como uma √∫nica conversa cont√≠nua. Analise todo o contexto e responda de forma unificada, n√£o responda cada mensagem separadamente.`
      : '';
    
    const systemPrompt = `${safeAssistant.prompt || 'Voc√™ √© um assistente √∫til e prestativo.'}${memoryContext}

CONTEXTO DA CONVERSA:
Cliente: ${resolvedContext?.customerName || 'Cliente'}
Telefone: ${resolvedContext?.phoneNumber || 'N/A'}${contextMessage}

HIST√ìRICO RECENTE DA CONVERSA:
${conversationContext}

INSTRU√á√ïES IMPORTANTES PARA CONTINUIDADE:
- Voc√™ est√° em uma conversa cont√≠nua com ${resolvedContext?.customerName || 'este cliente'}
- N√ÉO se reapresente se j√° conversaram antes - mantenha a naturalidade da conversa
- Use o contexto da conversa anterior para responder de forma coerente
- Se o cliente mencionar algo que foi discutido antes, reconhe√ßa e continue a partir dali
- Seja natural e conversacional, como se fosse uma pessoa real
- Mantenha a personalidade e tom estabelecidos na conversa
- Responda de forma √∫til e prestativa
- Se n√£o souber algo, seja honesto
- Responda em portugu√™s brasileiro
- Seja conciso mas completo
${isBatchProcessing ? '- Considere todas as mensagens como uma √∫nica solicita√ß√£o do usu√°rio' : ''}
- IMPORTANTE: Esta √© uma conversa em andamento - n√£o comece do zero!`;

    console.log('ü§ñ [AI-ASSISTANT] üß† INICIANDO CHAMADA OPENAI - TIMESTAMP:', new Date().toISOString());
    console.log('ü§ñ [AI-ASSISTANT] Modelo:', safeAssistant.model || 'gpt-4o-mini');
    console.log('ü§ñ [AI-ASSISTANT] System prompt length:', systemPrompt.length);
    console.log('ü§ñ [AI-ASSISTANT] Message content length:', messageContent.length);

    // Chamar OpenAI API
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openAIApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: safeAssistant.model || 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: messageContent }
        ],
        temperature: 0.7,
        max_tokens: 500
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [AI-ASSISTANT] Erro na OpenAI API:', response.status, response.statusText, errorText);
      throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
    }

    const aiData = await response.json();
    const aiResponse = aiData.choices[0].message.content;

    console.log('ü§ñ [AI-ASSISTANT] ‚úÖ OPENAI RESPONDEU - TIMESTAMP:', new Date().toISOString());
    console.log('ü§ñ [AI-ASSISTANT] Response length:', aiResponse?.length || 0);
    console.log('ü§ñ [AI-ASSISTANT] Response preview:', aiResponse?.substring(0, 100) + '...');
    console.log('ü§ñ [AI-ASSISTANT] Model usado:', safeAssistant.model || 'gpt-4o-mini');

    // üîê BUSCAR BUSINESS TOKEN PARA COMANDOS DE √ÅUDIO
    console.log('üîê [AI-ASSISTANT] Verificando business token para cliente:', resolvedClientId);
    
    const { data: client, error: clientError } = await supabase
      .from('clients')
      .select('business_token')
      .eq('id', resolvedClientId)
      .single();
    
    if (clientError) {
      console.error('‚ùå [AI-ASSISTANT] Erro ao buscar cliente:', clientError);
      throw new Error(`Cliente n√£o encontrado: ${resolvedClientId}`);
    }
    
    if (!client?.business_token) {
      console.warn('‚ö†Ô∏è [AI-ASSISTANT] Business token n√£o encontrado - comandos de √°udio ser√£o ignorados');
    } else {
      console.log('‚úÖ [AI-ASSISTANT] Business token encontrado para cliente');
    }

    // üéµ DETECTAR E PROCESSAR COMANDOS DE √ÅUDIO COM TIMEOUT E FALLBACK
    console.log('üéµ [AUDIO-COMMANDS] Iniciando processamento de comandos de √°udio...');
    let finalResponse = aiResponse;
    
    // ‚úÖ CORRIGIR ESCOPO: Declarar audioCommands fora do try-catch
    let audioCommands = { hasAudioCommands: false, processedCount: 0, remainingText: aiResponse };
    
    try {
      // Processar comandos de √°udio sem timeout agressivo
      audioCommands = await processAudioCommands(aiResponse, ticketId, safeAssistant, resolvedInstanceId, client?.business_token || '');
      
      if (audioCommands.hasAudioCommands) {
        console.log('üéµ [AUDIO-COMMANDS] ‚úÖ Comandos de √°udio processados:', audioCommands.processedCount);
        finalResponse = audioCommands.remainingText;
      } else {
        console.log('üéµ [AUDIO-COMMANDS] ‚ÑπÔ∏è Nenhum comando de √°udio detectado');
      }
      
      // üñºÔ∏è PROCESSAR COMANDOS DE IMAGEM
      const imageCount = await processImageCommands(finalResponse, {
        assistantId: safeAssistant.id,
        instanceId: resolvedInstanceId,
        chatId: resolvedContext.chatId,
        businessToken: client?.business_token || ''
      });
      
      if (imageCount > 0) {
        console.log(`üñºÔ∏è [IMAGE-COMMANDS] ‚úÖ ${imageCount} comandos de imagem processados`);
        finalResponse = finalResponse.replace(/image\s*:\s*[^\s]+/gi, '').trim();
      }
    } catch (audioError) {
      console.error('‚ö†Ô∏è [AUDIO-COMMANDS] Erro no processamento de √°udio (continuando com texto):', audioError);
      // FALLBACK: Continuar com resposta de texto mesmo se √°udio falhar
      finalResponse = aiResponse;
    }

    // Se n√£o h√° texto restante ap√≥s comandos de √°udio, finalizar aqui
    if (!finalResponse || finalResponse.trim() === '') {
      console.log('‚úÖ [AI-ASSISTANT] Processamento finalizado - apenas comandos de √°udio');
      return Response.json({ 
        success: true, 
        type: 'audio_only', 
        audioCommandsProcessed: audioCommands.processedCount,
        response: 'Comandos de √°udio processados'
      });
    }

    // Salvar resposta da IA no ticket
    const messageId = `ai_response_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    const { error: saveError } = await supabase
      .from('ticket_messages')
      .insert({
        ticket_id: ticketId,
        message_id: messageId,
        content: finalResponse,
        from_me: true,
        is_ai_response: true,
        sender_name: safeAssistant.name || 'Assistente IA',
        timestamp: new Date().toISOString(),
        processing_status: 'processed'
      });

    if (saveError) {
      console.error('‚ùå [AI-ASSISTANT] Erro ao salvar resposta:', saveError);
      throw saveError;
    }

    console.log('üíæ [AI-ASSISTANT] Resposta salva no ticket');

    // ü§ñ BUSCAR CONFIGURA√á√ÉO HUMANIZADA DO ASSISTENTE
    const humanizedConfig = await getHumanizedConfig(safeAssistant.id);
    
    // üì§ ENVIAR RESPOSTA VIA SERVI√áO UNIFICADO SIMPLIFICADO
    console.log('üì§ [AI-ASSISTANT] Enviando resposta via servi√ßo unificado...');
    
    // ‚úÖ VALIDA√á√ÉO CR√çTICA: instanceId √© obrigat√≥rio
    if (!resolvedInstanceId || typeof resolvedInstanceId !== 'string') {
      console.error('‚ùå [AI-ASSISTANT] instanceId inv√°lido ou ausente:', resolvedInstanceId);
      throw new Error('instanceId √© obrigat√≥rio para enviar a mensagem');
    }
    
    // ‚úÖ VALIDA√á√ÉO CR√çTICA: Contexto e chatId s√£o obrigat√≥rios
    if (!resolvedContext || !resolvedContext.chatId) {
      console.error('‚ùå [AI-ASSISTANT] Contexto ou chatId ausente:', resolvedContext);
      throw new Error('context.chatId √© obrigat√≥rio para enviar a mensagem');
    }
    
    // ‚úÖ VALIDA√á√ÉO CR√çTICA: clientId √© obrigat√≥rio  
    if (!resolvedClientId) {
      console.error('‚ùå [AI-ASSISTANT] clientId ausente');
      throw new Error('clientId √© obrigat√≥rio para buscar business token');
    }
    
    // Usar yumerApiV2 diretamente com ID correto
    let realInstanceId = resolvedInstanceId;
    
    // Verificar se √© UUID interno e buscar o instance_id real (se cont√©m h√≠fen)
    if (resolvedInstanceId.includes('-')) {
      console.log('üîç [AI-ASSISTANT] Resolvendo ID interno para real:', resolvedInstanceId);
      
      const { data: instanceData, error: instanceError } = await supabase
        .from('whatsapp_instances')
        .select('instance_id')
        .eq('id', resolvedInstanceId)
        .single();
      
      if (instanceError || !instanceData) {
        console.error('‚ùå [AI-ASSISTANT] Erro ao buscar instance_id real:', instanceError);
        throw new Error(`Inst√¢ncia n√£o encontrada: ${resolvedInstanceId}`);
      }
      
      realInstanceId = instanceData.instance_id;
      console.log('‚úÖ [AI-ASSISTANT] ID real da inst√¢ncia:', {
        internal: resolvedInstanceId,
        real: realInstanceId
      });
    }

    // Business token j√° foi obtido anteriormente para comandos de √°udio

    // üì± CONFIGURAR PROFILE ONLINE SE HABILITADO
    try {
      const { data: aiConfig } = await supabase
        .from('client_ai_configs')
        .select('online_status_config')
        .eq('client_id', resolvedClientId)
        .single();

      if (aiConfig?.online_status_config?.enabled) {
        const config = aiConfig.online_status_config;
        console.log('üîí [PROFILE] Aplicando configura√ß√µes de perfil online');
        
        // Configurar privacidade online para "todos" verem
        const onlineResponse = await fetch(`https://api.yumer.com.br/api/v2/instance/${realInstanceId}/whatsapp/update/profile-online-privacy`, {
          method: 'PATCH',
          headers: {
            'Authorization': `Bearer ${client.business_token}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ action: config.onlinePrivacy || 'all' })
        });
        console.log(`üîí [ONLINE-PRIVACY] Response: ${await onlineResponse.text()}`);
        
        // Configurar privacidade visto por √∫ltimo
        const seenResponse = await fetch(`https://api.yumer.com.br/api/v2/instance/${realInstanceId}/whatsapp/update/profile-seen-privacy`, {
          method: 'PATCH',
          headers: {
            'Authorization': `Bearer ${client.business_token}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ action: config.seenPrivacy || 'all' })
        });
        console.log(`üëÅÔ∏è [SEEN-PRIVACY] Response: ${await seenResponse.text()}`);
        
        // Configurar status do perfil
        if (config.profileStatus) {
          const statusResponse = await fetch(`https://api.yumer.com.br/api/v2/instance/${realInstanceId}/whatsapp/update/profile-status`, {
            method: 'PATCH',
            headers: {
              'Authorization': `Bearer ${client.business_token}`,
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({ profileStatus: config.profileStatus })
          });
          console.log(`üìù [PROFILE-STATUS] Response: ${await statusResponse.text()}`);
        }
        
        console.log('‚úÖ [PROFILE] Configura√ß√µes de perfil aplicadas com sucesso');
      }
    } catch (profileError) {
      console.warn('‚ö†Ô∏è [PROFILE] Erro ao aplicar configura√ß√µes de perfil:', profileError);
    }

    // üö´ REMOVIDO: Presen√ßa via chat/presence - endpoint n√£o existe mais
    // A presen√ßa √© controlada automaticamente via configura√ß√µes de perfil

    // üöÄ USAR SISTEMA DE BLOCOS QUANDO NECESS√ÅRIO
    const shouldUseChunks = finalResponse.length > humanizedConfig.behavior.messageHandling.maxCharsPerChunk;
    
    console.log('ü§ñ [AI-ASSISTANT] DECIS√ÉO DE ENVIO:', {
      responseLength: finalResponse.length,
      maxCharsPerChunk: humanizedConfig.behavior.messageHandling.maxCharsPerChunk,
      splitLongMessages: humanizedConfig.behavior.messageHandling.splitLongMessages,
      shouldUseChunks,
      willUseChunks: shouldUseChunks && humanizedConfig.behavior.messageHandling.splitLongMessages
    });

    let sendResult;
    try {
      if (shouldUseChunks && humanizedConfig.behavior.messageHandling.splitLongMessages) {
        // ENVIO EM BLOCOS
        console.log('üì¶ [AI-ASSISTANT] Enviando em blocos...');
        
        const chunks = splitMessageIntoChunks(
          finalResponse,
          humanizedConfig.behavior.messageHandling.maxCharsPerChunk
        );
        
        console.log('üî¢ [AI-ASSISTANT] Blocos criados:', {
          totalChunks: chunks.length,
          chunks: chunks.map(c => c.substring(0, 50) + '...')
        });

        const messageIds: string[] = [];
        let chunkIndex = 0;

        for (const chunk of chunks) {
          chunkIndex++;
          
          console.log(`üì§ [AI-ASSISTANT] Enviando bloco ${chunkIndex}/${chunks.length}:`, {
            length: chunk.length,
            preview: chunk.substring(0, 100) + '...'
          });

          const sendOptions = {
            delay: humanizedConfig.behavior.messageHandling.delayBetweenChunks,
            presence: 'composing',
            externalAttributes: `source=ai;humanized=true;timestamp=${Date.now()}`
          };

          const sendData = {
            recipient: resolvedContext.chatId,
            textMessage: {
              text: chunk
            },
            options: sendOptions
          };

          const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${realInstanceId}/send/text`, {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${client.business_token}`,
              'Content-Type': 'application/json'
            },
            body: JSON.stringify(sendData)
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error(`‚ùå [AI-ASSISTANT] Erro no bloco ${chunkIndex}:`, errorText);
            throw new Error(`HTTP ${response.status}: ${errorText}`);
          }

          const result = await response.json();
          messageIds.push(result.key?.id || `ai_chunk_${chunkIndex}_${Date.now()}`);
          
          console.log(`‚úÖ [AI-ASSISTANT] Bloco ${chunkIndex}/${chunks.length} enviado com sucesso`);

          // Aguardar delay entre chunks (exceto no √∫ltimo) - timing inteligente
          if (chunkIndex < chunks.length) {
            // Delay baseado no tamanho do pr√≥ximo bloco
            const nextChunk = chunks[chunkIndex]; // pr√≥ximo bloco (array √© 0-indexed)
            const baseDelay = humanizedConfig.behavior.messageHandling.delayBetweenChunks;
            const intelligentDelay = Math.min(
              Math.max(baseDelay, nextChunk.length * 12), // 12ms por caractere
              4500 // m√°ximo 4.5 segundos
            );
            
            console.log(`‚è±Ô∏è [AI-ASSISTANT] Aguardando ${intelligentDelay}ms antes do pr√≥ximo bloco (baseado em ${nextChunk.length} chars)`);
            await new Promise(resolve => setTimeout(resolve, intelligentDelay));
          }
        }

        sendResult = {
          success: true,
          messageId: messageIds[0], // Primeiro bloco como ID principal
          messageIds,
          totalChunks: chunks.length,
          details: { type: 'chunked', chunks: chunks.length }
        };

        console.log('‚úÖ [AI-ASSISTANT] Todos os blocos enviados com sucesso:', {
          totalChunks: chunks.length,
          messageIds
        });

      } else {
        // ENVIO DIRETO (mensagem curta ou sistema de blocos desabilitado)
        console.log('üì§ [AI-ASSISTANT] Enviando mensagem direta (sem blocos)...');
        
        const sendOptions = {
          delay: 1200,
          presence: 'composing',
          externalAttributes: `source=ai-assistant;ticketId=${ticketId};assistantId=${safeAssistant.id};timestamp=${Date.now()}`
        };
        
        const sendData = {
          recipient: resolvedContext.chatId,
          textMessage: {
            text: finalResponse
          },
          options: sendOptions
        };

        const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${realInstanceId}/send/text`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${client.business_token}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(sendData)
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`HTTP ${response.status}: ${errorText}`);
        }

        const result = await response.json();
        
        sendResult = {
          success: true,
          messageId: result.key?.id || `ai_msg_${Date.now()}`,
          details: result
        };
        
        console.log('‚úÖ [AI-ASSISTANT] Mensagem enviada com sucesso via API direta:', {
          realInstanceId,
          chatId: resolvedContext.chatId,
          messageId: sendResult.messageId
        });
      }
      
    } catch (sendError: any) {
      console.error('‚ùå [AI-ASSISTANT] Erro ao enviar via API direta:', sendError);
      
      sendResult = {
        success: false,
        error: sendError.message || 'Erro no envio',
        details: sendError
      };
    }

    // üî• CORRE√á√ÉO: Marcar mensagens do usu√°rio como processadas ap√≥s resposta da IA
    await markUserMessagesAsProcessed(ticketId, resolvedContext?.chatId);

    // üß† ATUALIZAR MEM√ìRIA CONVERSACIONAL
    await updateConversationMemory(
      resolvedClientId,
      resolvedContext.chatId,
      resolvedInstanceId,
      resolvedContext.customerName || 'Cliente',
      resolvedContext.phoneNumber,
      messageContent,
      finalResponse,
      conversationMemory
    );

    console.log('üéâ [AI-ASSISTANT] SUCESSO TOTAL! Assistente processou e enviou resposta:', {
      ticketId: ticketId,
      assistantName: safeAssistant?.name,
      responseLength: finalResponse?.length || 0,
      sendSuccess: sendResult?.success,
      messageId: messageId,
      timestamp: new Date().toISOString()
    });

    console.log('üèÅ [AI-ASSISTANT] ‚úÖ RETORNANDO SUCESSO - TIMESTAMP:', new Date().toISOString());
    console.log('üèÅ [AI-ASSISTANT] Final response length:', finalResponse?.length || 0);
    console.log('üèÅ [AI-ASSISTANT] Message ID:', messageId);
    console.log('üèÅ [AI-ASSISTANT] Sent via Yumer:', sendResult.success);

    return new Response(
      JSON.stringify({
        success: true,
        response: finalResponse,
        messageId: messageId,
        timestamp: new Date().toISOString(),
        sentViaYumer: sendResult.success
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );

  } catch (error) {
    console.error('‚ùå [AI-ASSISTANT] Erro cr√≠tico:', error);
    
    return new Response(
      JSON.stringify({
        error: 'Failed to process AI assistant request',
        message: error.message
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  }
});

// ===== FUN√á√ÉO PARA MARCAR MENSAGENS COMO PROCESSADAS =====

// üî• Marcar mensagens do usu√°rio como processadas ap√≥s IA responder
async function markUserMessagesAsProcessed(ticketId: string, chatId?: string) {
  try {
    console.log('üîÑ [MARK-PROCESSED] Marcando mensagens como processadas para ticket:', ticketId);
    
    if (chatId) {
      // Buscar mensagens n√£o processadas do usu√°rio no chat espec√≠fico
      const { data: messages } = await supabase
        .from('whatsapp_messages')
        .select('id, message_id')
        .eq('chat_id', chatId)
        .eq('from_me', false)
        .eq('is_processed', false);
      
      if (messages && messages.length > 0) {
        console.log(`üîÑ [MARK-PROCESSED] Encontradas ${messages.length} mensagens para marcar como processadas`);
        
        // Marcar como processadas
        const { error } = await supabase
          .from('whatsapp_messages')
          .update({ 
            is_processed: true,
            processed_at: new Date().toISOString()
          })
          .eq('chat_id', chatId)
          .eq('from_me', false)
          .eq('is_processed', false);
        
        if (error) {
          console.error('‚ùå [MARK-PROCESSED] Erro ao marcar mensagens:', error);
        } else {
          console.log(`‚úÖ [MARK-PROCESSED] ${messages.length} mensagens marcadas como processadas`);
        }
      }
    }
  } catch (error) {
    console.error('‚ùå [MARK-PROCESSED] Erro cr√≠tico:', error);
  }
}

// ===== FUN√á√ïES DE HUMANIZA√á√ÉO =====

// üé≠ Buscar configura√ß√£o humanizada do assistente
async function getHumanizedConfig(assistantId: string): Promise<HumanizedConfig> {
  try {
    const { data: assistant } = await supabase
      .from('assistants')
      .select('advanced_settings')
      .eq('id', assistantId)
      .single();

    if (assistant?.advanced_settings) {
      const advancedSettings = typeof assistant.advanced_settings === 'string' 
        ? JSON.parse(assistant.advanced_settings) 
        : assistant.advanced_settings;
      
      if (advancedSettings.humanization) {
        console.log('üé≠ [HUMANIZED-CONFIG] Configura√ß√£o customizada encontrada:', advancedSettings.humanization);
        return { ...defaultHumanizedConfig, ...advancedSettings.humanization };
      }
    }

    console.log('üé≠ [HUMANIZED-CONFIG] Usando configura√ß√£o padr√£o');
    return defaultHumanizedConfig;
  } catch (error) {
    console.error('‚ùå [HUMANIZED-CONFIG] Erro ao buscar configura√ß√£o:', error);
    return defaultHumanizedConfig;
  }
}

// üìù Dividir mensagem em chunks inteligentes
function splitMessage(text: string, maxChars: number): string[] {
  if (text.length <= maxChars) {
    return [text];
  }

  const chunks: string[] = [];
  let remaining = text;

  while (remaining.length > maxChars) {
    let splitIndex = maxChars;
    
    // Procurar quebra natural
    const naturalBreaks = ['. ', ', ', '\n', '; ', '! ', '? '];
    for (const breakChar of naturalBreaks) {
      const lastBreak = remaining.lastIndexOf(breakChar, maxChars);
      if (lastBreak > maxChars * 0.5) {
        splitIndex = lastBreak + breakChar.length;
        break;
      }
    }

    chunks.push(remaining.substring(0, splitIndex).trim());
    remaining = remaining.substring(splitIndex).trim();
  }

  if (remaining.length > 0) {
    chunks.push(remaining);
  }

  return chunks;
}

// ‚è±Ô∏è Calcular dura√ß√£o de typing baseada no texto
function calculateTypingDuration(text: string, typingSpeed: number, config: HumanizedConfig): number {
  const words = text.split(' ').length;
  const baseTypingTime = (words / typingSpeed) * 60 * 1000;
  
  // Aplicar varia√ß√£o natural (80% a 120% do tempo base)
  const duration = baseTypingTime * (0.8 + Math.random() * 0.4);
  
  return Math.max(
    config.behavior.typing.minDuration,
    Math.min(config.behavior.typing.maxDuration, duration)
  );
}

// üì§ Enviar resposta humanizada via CodeChat v2.2.1
async function sendHumanizedResponse(
  instanceId: string, 
  chatId: string, 
  message: string, 
  config: HumanizedConfig
): Promise<{ success: boolean; chunks: number; error?: string }> {
  try {
    if (!config.enabled) {
      // Fallback para envio simples se humaniza√ß√£o desabilitada
      const result = await sendSimpleMessage(instanceId, chatId, message);
      return { success: result.success, chunks: 1, error: result.error };
    }

    console.log('ü§ñ [HUMANIZED-SEND] Iniciando envio humanizado:', {
      instanceId,
      chatId,
      messageLength: message.length,
      personality: config.personality.name,
      splitEnabled: config.behavior.messageHandling.splitLongMessages
    });

    // 1. Dividir mensagem em chunks se necess√°rio
    const chunks = config.behavior.messageHandling.splitLongMessages 
      ? splitMessage(message, config.behavior.messageHandling.maxCharsPerChunk)
      : [message];

    console.log(`üìù [HUMANIZED-SEND] Dividido em ${chunks.length} chunks`);

    // 2. Buscar token de autentica√ß√£o
    const { data: instanceData } = await supabase
      .from('whatsapp_instances')
      .select(`
        instance_id,
        client_id,
        yumer_instance_name,
        clients:client_id (
          business_token
        )
      `)
      .eq('instance_id', instanceId)
      .single();

    if (!instanceData?.clients?.business_token) {
      console.error('‚ùå [HUMANIZED-SEND] Business token n√£o encontrado para inst√¢ncia:', instanceId);
      return { success: false, chunks: 0, error: 'Business token not found' };
    }

    let businessToken = instanceData.clients.business_token;

    // üîë VERIFICAR SE O TOKEN EST√Å V√ÅLIDO (N√ÉO EXPIRADO)
    try {
      const tokenParts = businessToken.split('.');
      if (tokenParts.length === 3) {
        const payload = JSON.parse(atob(tokenParts[1]));
        const expirationTime = payload.exp * 1000;
        const currentTime = Date.now();

        if (currentTime >= expirationTime) {
          console.warn('‚ö†Ô∏è [HUMANIZED-SEND] Token expirado, regenerando...');
          
          // Regenerar token
          if (instanceData.yumer_instance_name) {
            const jose = await import('jose');
            const jwtSecret = Deno.env.get('AUTHENTICATION_JWT_SECRET') || 'your-secret-key';
            
            const now = Math.floor(Date.now() / 1000);
            const exp = now + (4 * 60 * 60); // 4 horas
            
            const newPayload = {
              instanceName: instanceData.yumer_instance_name,
              apiName: "whatsapp-api",
              tokenId: crypto.randomUUID(),
              iat: now,
              exp: exp,
              sub: "g-t"
            };
            
            const secret = new TextEncoder().encode(jwtSecret);
            businessToken = await new jose.SignJWT(newPayload)
              .setProtectedHeader({ alg: 'HS256', typ: 'JWT' })
              .setIssuedAt(now)
              .setExpirationTime(exp)
              .setSubject('g-t')
              .sign(secret);

            // Salvar o novo token no banco
            await supabase
              .from('clients')
              .update({ business_token: businessToken })
              .eq('id', instanceData.client_id);

            console.log('‚úÖ [HUMANIZED-SEND] Token regenerado com sucesso');
          }
        }
      }
    } catch (tokenError) {
      console.warn('‚ö†Ô∏è [HUMANIZED-SEND] Erro ao verificar token:', tokenError);
    }

    // 3. Enviar cada chunk com comportamento humanizado
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      console.log(`üì§ [HUMANIZED-SEND] Enviando chunk ${i + 1}/${chunks.length}: "${chunk.substring(0, 50)}..."`);

      // 3a. Detectar se √© mensagem de √°udio
      const isAudioMessage = chunk.toLowerCase().includes('audio:') || chunk.toLowerCase().includes('.ogg') || chunk.toLowerCase().includes('.oga');
      const presenceType: 'composing' | 'recording' = isAudioMessage ? 'recording' : 'composing';

      // 3b. Simular typing/recording se habilitado
      if (config.behavior.typing.enabled && config.behavior.presence.showTyping) {
        const typingDuration = calculateTypingDuration(chunk, config.personality.typingSpeed, config);
        console.log(`‚å®Ô∏è [HUMANIZED-SEND] Simulando ${presenceType} por ${typingDuration}ms`);
        
        // Aguardar tempo de typing/recording ANTES de enviar
        await new Promise(resolve => setTimeout(resolve, typingDuration));
      }

      // 3c. Enviar mensagem real via CodeChat v2.2.1 com presen√ßa aplicada
      const presenceToUse = (config.behavior.typing.enabled && config.behavior.presence.showTyping) ? presenceType : 'available';
      const chunkResult = await sendCodeChatMessage(instanceId, chatId, chunk, businessToken, presenceToUse);
      
      if (!chunkResult.success) {
        console.error(`‚ùå [HUMANIZED-SEND] Erro no chunk ${i + 1}:`, chunkResult.error);
        return { success: false, chunks: i, error: chunkResult.error };
      }

      // 3c. Delay entre chunks (exceto no √∫ltimo)
      if (i < chunks.length - 1) {
        const chunkDelay = config.behavior.messageHandling.delayBetweenChunks + 
          (Math.random() - 0.5) * 1000; // ¬±500ms de varia√ß√£o
        console.log(`‚è±Ô∏è [HUMANIZED-SEND] Aguardando ${chunkDelay}ms antes do pr√≥ximo chunk`);
        await new Promise(resolve => setTimeout(resolve, chunkDelay));
      }
    }

    // 4. N√£o precisamos mais definir presen√ßa separadamente - integrada na mensagem

    console.log(`‚úÖ [HUMANIZED-SEND] Todos os ${chunks.length} chunks enviados com sucesso`);
    return { success: true, chunks: chunks.length };

  } catch (error) {
    console.error('‚ùå [HUMANIZED-SEND] Erro no envio humanizado:', error);
    return { 
      success: false, 
      chunks: 0, 
      error: error instanceof Error ? error.message : 'Erro desconhecido' 
    };
  }
}

// üì§ Enviar mensagem via CodeChat v2.2.1 com presen√ßa integrada
async function sendCodeChatMessage(
  instanceId: string, 
  chatId: string, 
  message: string, 
  businessToken: string,
  presence: 'available' | 'composing' | 'recording' = 'available'
): Promise<{ success: boolean; error?: string }> {
  try {
    // Se a mensagem estiver vazia, n√£o enviar nada (CodeChat v2.2.1 n√£o aceita mensagens vazias)
    if (!message || message.trim() === '') {
      console.log(`‚ö†Ô∏è [CODECHAT-SEND] Pulando envio de mensagem vazia com presen√ßa: ${presence}`);
      return { success: true };
    }

    const codeChatData = {
      recipient: chatId,
      textMessage: {
        text: message
      },
      options: {
        delay: 0, // Controlamos o delay manualmente
        presence: presence // Integrar presen√ßa diretamente na mensagem
      }
    };

    console.log('üìã [CODECHAT-SEND] Dados para CodeChat v2.2.1:', {
      recipient: chatId,
      textLength: message.length,
      presence: presence
    });

    const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${instanceId}/send/text`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(codeChatData)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [CODECHAT-SEND] Erro ao enviar via CodeChat v2.2.1:', {
        status: response.status,
        statusText: response.statusText,
        error: errorText,
        instanceId,
        url: `https://api.yumer.com.br/api/v2/instance/${instanceId}/send/text`
      });
      return { success: false, error: `HTTP ${response.status}: ${errorText}` };
    }

    const result = await response.json();
    console.log('‚úÖ [CODECHAT-SEND] Mensagem enviada com sucesso via CodeChat v2.2.1:', {
      messageId: result.messageId,
      chatId: chatId,
      presence: presence
    });

    return { success: true };

  } catch (error) {
    console.error('‚ùå [CODECHAT-SEND] Erro ao enviar via CodeChat v2.2.1:', error);
    return { success: false, error: error.message };
  }
}

// üë§ Fun√ß√£o de presen√ßa removida - agora integrada nas options da mensagem
// A presen√ßa agora √© controlada via options.presence em cada mensagem enviada

// üì§ Envio simples (fallback)
async function sendSimpleMessage(instanceId: string, chatId: string, message: string): Promise<{ success: boolean; error?: string }> {
  try {
    console.log('üì§ [SIMPLE-SEND] Enviando mensagem simples:', {
      instanceId,
      chatId,
      messageLength: message.length
    });

    // Buscar business_token da inst√¢ncia via cliente
    const { data: instanceData } = await supabase
      .from('whatsapp_instances')
      .select(`
        instance_id,
        client_id,
        yumer_instance_name,
        clients:client_id (
          business_token
        )
      `)
      .eq('instance_id', instanceId)
      .single();

    if (!instanceData?.clients?.business_token) {
      console.error('‚ùå [SIMPLE-SEND] Business token n√£o encontrado para inst√¢ncia:', instanceId);
      return { success: false, error: 'Business token not found' };
    }

    let businessToken = instanceData.clients.business_token;

    // üîë VERIFICAR SE O TOKEN EST√Å V√ÅLIDO (N√ÉO EXPIRADO)
    try {
      const tokenParts = businessToken.split('.');
      if (tokenParts.length === 3) {
        const payload = JSON.parse(atob(tokenParts[1]));
        const expirationTime = payload.exp * 1000;
        const currentTime = Date.now();

        if (currentTime >= expirationTime) {
          console.warn('‚ö†Ô∏è [SIMPLE-SEND] Token expirado, regenerando...');
          
          // Regenerar token se expirado
          if (instanceData.yumer_instance_name) {
            const jose = await import('jose');
            const jwtSecret = Deno.env.get('AUTHENTICATION_JWT_SECRET') || 'your-secret-key';
            
            const now = Math.floor(Date.now() / 1000);
            const exp = now + (4 * 60 * 60); // 4 horas
            
            const newPayload = {
              instanceName: instanceData.yumer_instance_name,
              apiName: "whatsapp-api",
              tokenId: crypto.randomUUID(),
              iat: now,
              exp: exp,
              sub: "g-t"
            };
            
            const secret = new TextEncoder().encode(jwtSecret);
            businessToken = await new jose.SignJWT(newPayload)
              .setProtectedHeader({ alg: 'HS256', typ: 'JWT' })
              .setIssuedAt(now)
              .setExpirationTime(exp)
              .setSubject('g-t')
              .sign(secret);

            // Salvar o novo token no banco
            await supabase
              .from('clients')
              .update({ business_token: businessToken })
              .eq('id', instanceData.client_id);

            console.log('‚úÖ [SIMPLE-SEND] Token regenerado com sucesso');
          }
        }
      }
    } catch (tokenError) {
      console.warn('‚ö†Ô∏è [SIMPLE-SEND] Erro ao verificar token:', tokenError);
    }

    return await sendCodeChatMessage(instanceId, chatId, message, businessToken);

  } catch (error) {
    console.error('‚ùå [SIMPLE-SEND] Erro no envio simples:', error);
    return { success: false, error: error.message };
  }
}

// üß† ATUALIZAR MEM√ìRIA CONVERSACIONAL
async function updateConversationMemory(
  clientId: string,
  chatId: string,
  instanceId: string,
  customerName: string,
  customerPhone: string,
  userMessage: string,
  aiResponse: string,
  existingMemory: any = null
): Promise<void> {
  try {
    console.log('üß† [MEMORY] Atualizando mem√≥ria conversacional:', {
      clientId,
      chatId: chatId.substring(0, 20) + '...',
      customerName,
      hasExisting: !!existingMemory
    });

    // Extrair t√≥picos da mensagem atual
    const currentTopics = extractTopicsFromMessage(userMessage, aiResponse);
    
    // Extrair informa√ß√µes-chave da conversa
    const keyInfo = extractKeyInformation(userMessage, aiResponse, existingMemory?.key_information || {});
    
    // Criar resumo da conversa atual (combinar com existente)
    const conversationSummary = generateConversationSummary(
      userMessage, 
      aiResponse, 
      existingMemory?.conversation_summary,
      customerName
    );
    
    // Gerar notas de personalidade
    const personalityNotes = generatePersonalityNotes(
      userMessage, 
      aiResponse, 
      existingMemory?.personality_notes
    );

    // Manter apenas os √∫ltimos 10 t√≥picos
    const lastTopics = existingMemory?.last_topics || [];
    const updatedTopics = [...currentTopics, ...lastTopics].slice(0, 10);

    const memoryData = {
      client_id: clientId,
      chat_id: chatId,
      instance_id: instanceId,
      customer_name: customerName,
      customer_phone: customerPhone,
      conversation_summary: conversationSummary,
      key_information: keyInfo,
      last_topics: updatedTopics,
      personality_notes: personalityNotes,
      updated_at: new Date().toISOString()
    };

    const { error } = await supabase
      .from('conversation_context')
      .upsert(memoryData, {
        onConflict: 'client_id,chat_id,instance_id'
      });

    if (error) {
      console.error('‚ùå [MEMORY] Erro ao salvar mem√≥ria:', error);
    } else {
      console.log('‚úÖ [MEMORY] Mem√≥ria conversacional atualizada:', {
        topicsCount: updatedTopics.length,
        keyInfoKeys: Object.keys(keyInfo).length,
        summaryLength: conversationSummary?.length || 0
      });
    }

  } catch (error) {
    console.error('‚ùå [MEMORY] Erro ao atualizar mem√≥ria conversacional:', error);
  }
}

// üéØ Extrair t√≥picos de uma mensagem
function extractTopicsFromMessage(userMessage: string, aiResponse: string): string[] {
  const topics: string[] = [];
  const text = `${userMessage} ${aiResponse}`.toLowerCase();
  
  // Palavras-chave que indicam t√≥picos importantes
  const topicKeywords = [
    'problema', 'ajuda', 'd√∫vida', 'servi√ßo', 'produto', 'pedido', 'compra',
    'pagamento', 'entrega', 'suporte', 'atendimento', 'informa√ß√£o', 'pre√ßo',
    'hor√°rio', 'agendamento', 'consulta', 'reserva', 'cancelamento', 'troca',
    'devolu√ß√£o', 'garantia', 'instala√ß√£o', 'configura√ß√£o', 'bug', 'erro'
  ];
  
  for (const keyword of topicKeywords) {
    if (text.includes(keyword) && !topics.includes(keyword)) {
      topics.push(keyword);
    }
  }
  
  return topics.slice(0, 5); // M√°ximo 5 t√≥picos por conversa
}

// üíé Extrair informa√ß√µes-chave da conversa
function extractKeyInformation(userMessage: string, aiResponse: string, existingInfo: any = {}): any {
  const keyInfo = { ...existingInfo };
  const fullText = `${userMessage} ${aiResponse}`;
  
  // Detectar nome se mencionado
  const nameMatch = fullText.match(/meu nome √© (\w+)|me chamo (\w+)|sou (\w+)/i);
  if (nameMatch) {
    keyInfo.userName = nameMatch[1] || nameMatch[2] || nameMatch[3];
  }
  
  // Detectar prefer√™ncias
  if (fullText.includes('gosto de') || fullText.includes('prefiro')) {
    if (!keyInfo.preferences) keyInfo.preferences = [];
    keyInfo.preferences.push(fullText.match(/(?:gosto de|prefiro) ([^.!?]+)/i)?.[1]);
  }
  
  // Detectar problemas recorrentes
  if (fullText.includes('problema') || fullText.includes('erro')) {
    if (!keyInfo.commonIssues) keyInfo.commonIssues = [];
    const issueMatch = fullText.match(/problema (?:com|em|no) ([^.!?]+)/i);
    if (issueMatch) keyInfo.commonIssues.push(issueMatch[1]);
  }
  
  return keyInfo;
}

// üìù Gerar resumo da conversa
function generateConversationSummary(
  userMessage: string, 
  aiResponse: string, 
  existingSummary?: string,
  customerName?: string
): string {
  const newExchange = `${customerName || 'Cliente'}: ${userMessage} | Assistente: ${aiResponse}`;
  
  if (!existingSummary) {
    return newExchange.substring(0, 500);
  }
  
  // Combinar com resumo existente, mantendo no m√°ximo 500 caracteres
  const combined = `${existingSummary} | ${newExchange}`;
  if (combined.length <= 500) {
    return combined;
  }
  
  // Se muito longo, manter apenas as √∫ltimas trocas
  const exchanges = combined.split(' | ');
  const recentExchanges = exchanges.slice(-3); // √öltimas 3 trocas
  return recentExchanges.join(' | ').substring(0, 500);
}

// üé≠ Gerar notas de personalidade
function generatePersonalityNotes(
  userMessage: string, 
  aiResponse: string, 
  existingNotes?: string
): string {
  const notes: string[] = existingNotes ? [existingNotes] : [];
  const fullText = `${userMessage} ${aiResponse}`.toLowerCase();
  
  // Detectar tom da conversa
  if (fullText.includes('obrigado') || fullText.includes('valeu')) {
    notes.push('Cliente educado e agradecido');
  }
  
  if (fullText.includes('urgente') || fullText.includes('r√°pido')) {
    notes.push('Cliente valoriza rapidez');
  }
  
  if (fullText.includes('detalhes') || fullText.includes('explicar')) {
    notes.push('Cliente gosta de explica√ß√µes detalhadas');
  }
  
  // Manter apenas as √∫ltimas 3 notas
  const uniqueNotes = [...new Set(notes)].slice(-3);
  return uniqueNotes.join('; ');
}

// Aplicar configura√ß√µes de perfil em sequ√™ncia ordenada
async function applyProfileConfigSequence(instanceId: string, businessToken: string, chatId: string) {
  const YUMER_BASE_URL = 'https://api.yumer.com.br';
  
  try {
    // 1. Configurar privacidade online (quem pode ver quando estou online)
    console.log('üîí [PROFILE-1] Aplicando privacidade online...');
    const onlinePrivacyResponse = await fetch(`${YUMER_BASE_URL}/api/v2/instance/${instanceId}/whatsapp/update/profile-online-privacy`, {
      method: 'PATCH',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${businessToken}`
      },
      body: JSON.stringify({ action: 'all' })
    });

    if (!onlinePrivacyResponse.ok) {
      throw new Error(`Online privacy failed: ${onlinePrivacyResponse.status}`);
    }

    const onlinePrivacyResult = await onlinePrivacyResponse.json();
    console.log('üîí [ONLINE-PRIVACY] Response:', JSON.stringify(onlinePrivacyResult));

    // Aguardar antes da pr√≥xima configura√ß√£o
    await new Promise(resolve => setTimeout(resolve, 500));

    // 2. Configurar privacidade do visto por √∫ltimo
    console.log('üëÅÔ∏è [PROFILE-2] Aplicando privacidade do visto por √∫ltimo...');
    const seenPrivacyResponse = await fetch(`${YUMER_BASE_URL}/api/v2/instance/${instanceId}/whatsapp/update/profile-seen-privacy`, {
      method: 'PATCH',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${businessToken}`
      },
      body: JSON.stringify({ action: 'all' })
    });

    if (!seenPrivacyResponse.ok) {
      throw new Error(`Seen privacy failed: ${seenPrivacyResponse.status}`);
    }

    const seenPrivacyResult = await seenPrivacyResponse.json();
    console.log('üëÅÔ∏è [SEEN-PRIVACY] Response:', JSON.stringify(seenPrivacyResult));

    // Aguardar antes da pr√≥xima configura√ß√£o
    await new Promise(resolve => setTimeout(resolve, 500));

    // 3. Definir status do perfil
    console.log('üìù [PROFILE-3] Aplicando status do perfil...');
    const profileStatusResponse = await fetch(`${YUMER_BASE_URL}/api/v2/instance/${instanceId}/whatsapp/update/profile-status`, {
      method: 'PATCH',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${businessToken}`
      },
      body: JSON.stringify({ profileStatus: 'Atendimento automatizado ativo' })
    });

    if (!profileStatusResponse.ok) {
      throw new Error(`Profile status failed: ${profileStatusResponse.status}`);
    }

    const profileStatusResult = await profileStatusResponse.json();
    console.log('üìù [PROFILE-STATUS] Response:', JSON.stringify(profileStatusResult));

    console.log('‚úÖ [PROFILE-SEQUENCE] Todas as configura√ß√µes aplicadas com sucesso');
    
  } catch (error) {
    console.error('‚ùå [PROFILE-SEQUENCE] Erro na aplica√ß√£o sequencial:', error);
    throw error;
  }
}

// ==================== FUN√á√ïES DE PROCESSAMENTO MULTIM√çDIA ====================

/**
 * Processar imagem com GPT-4 Vision
 */
async function processImageWithVision(imageBase64: string, apiKey: string): Promise<string> {
  try {
    console.log('üñºÔ∏è [IMAGE-VISION] Processando imagem com GPT-4 Vision');
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'Analise esta imagem detalhadamente em portugu√™s. Descreva o que voc√™ v√™, identifique textos se houver, e forne√ßa informa√ß√µes √∫teis para um assistente de atendimento ao cliente.'
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:image/jpeg;base64,${imageBase64}`
                }
              }
            ]
          }
        ],
        max_tokens: 1000
      }),
    });

    if (!response.ok) {
      throw new Error(`Erro na API OpenAI: ${response.status}`);
    }

    const data = await response.json();
    const analysis = data.choices[0].message.content;
    
    console.log('‚úÖ [IMAGE-VISION] An√°lise conclu√≠da:', analysis.substring(0, 100));
    return analysis;
    
  } catch (error) {
    console.error('‚ùå [IMAGE-VISION] Erro ao processar imagem:', error);
    return '[Erro ao analisar imagem]';
  }
}

/**
 * Transcrever √°udio
 */
async function processAudioTranscription(audioBase64: string, apiKey: string): Promise<string> {
  try {
    console.log('üéµ [AUDIO] Transcrevendo √°udio');
    
    // Converter base64 para blob
    const binaryString = atob(audioBase64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    
    const formData = new FormData();
    const blob = new Blob([bytes], { type: 'audio/ogg' });
    formData.append('file', blob, 'audio.ogg');
    formData.append('model', 'whisper-1');
    formData.append('language', 'pt');

    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
      },
      body: formData,
    });

    if (!response.ok) {
      throw new Error(`Erro na API OpenAI: ${response.status}`);
    }

    const data = await response.json();
    console.log('‚úÖ [AUDIO] Transcri√ß√£o conclu√≠da:', data.text);
    return data.text || '[√Åudio n√£o p√¥de ser transcrito]';
    
  } catch (error) {
    console.error('‚ùå [AUDIO] Erro ao transcrever √°udio:', error);
    return '[Erro ao transcrever √°udio]';
  }
}

/**
 * Analisar v√≠deo (extra√ß√£o de frame + an√°lise)
 */
async function processVideoAnalysis(videoBase64: string, apiKey: string): Promise<string> {
  try {
    console.log('üé¨ [VIDEO] Analisando v√≠deo');
    
    // Para v√≠deos, vamos extrair o primeiro frame como imagem
    // Em uma implementa√ß√£o mais avan√ßada, poder√≠amos usar FFmpeg
    // Por enquanto, retornamos uma an√°lise b√°sica
    
    console.log('‚ö†Ô∏è [VIDEO] An√°lise b√°sica - extra√ß√£o de frames n√£o implementada');
    return '[V√≠deo recebido - an√°lise visual completa em desenvolvimento. Descreva brevemente o conte√∫do do v√≠deo para melhor atendimento.]';
    
  } catch (error) {
    console.error('‚ùå [VIDEO] Erro ao analisar v√≠deo:', error);
    return '[Erro ao analisar v√≠deo]';
  }
}

/**
 * Extrair texto de documentos
 */
async function processDocumentExtraction(documentBase64: string, mimeType: string): Promise<string> {
  try {
    console.log('üìÑ [DOCUMENT] Extraindo texto de documento:', mimeType);
    
    if (mimeType?.includes('pdf')) {
      return await extractPDFText(documentBase64);
    } else if (mimeType?.includes('text')) {
      // Texto simples
      const text = atob(documentBase64);
      return text.length > 2000 ? text.substring(0, 2000) + '...' : text;
    } else {
      console.log('üìÑ [DOCUMENT] Tipo de documento n√£o suportado para extra√ß√£o:', mimeType);
      return `[Documento ${mimeType} recebido - extra√ß√£o de texto n√£o suportada para este formato]`;
    }
    
  } catch (error) {
    console.error('‚ùå [DOCUMENT] Erro ao extrair texto:', error);
    return '[Erro ao extrair texto do documento]';
  }
}

/**
 * Detectar se mensagem tem estrutura de t√≥picos
 */
function hasTopicStructure(message: string): boolean {
  const topicPatterns = [
    /^\d+\.\s*\*\*[^*]+\*\*/m,     // "1. **T√≠tulo:**"
    /^\*\*\d+\.\s*[^*]+\*\*/m,     // "**1. T√≠tulo**"
    /^\d+\.\s*[A-Z√Å√ä√á√ï√É√ç√ö√Ç√î√Ä√ú]/m,  // "1. Texto"
    /^‚Ä¢\s*\*\*[^*]+\*\*/m,         // "‚Ä¢ **Item:**"
    /^\*\*[^*]+:\*\*\s*$/m,        // "**T√≠tulo:**"
    /^\s*[-‚Ä¢]\s*\*\*[^*]+\*\*/m,   // "- **Item:**" ou "‚Ä¢ **Item:**"
    /^\d+\)\s*[A-Z√Å√ä√á√ï√É√ç√ö√Ç√î√Ä√ú]/m,  // "1) Texto"
  ];
  
  // Contar quantos padr√µes de t√≥picos encontramos
  const matches = topicPatterns.reduce((count, pattern) => {
    const found = message.match(new RegExp(pattern.source, 'gm'));
    return count + (found ? found.length : 0);
  }, 0);
  
  console.log(`üîç [TOPIC-DETECT] Padr√µes encontrados: ${matches}`);
  return matches >= 2; // Pelo menos 2 t√≥picos para considerar estruturada
}

/**
 * Dividir mensagem por t√≥picos numerados ou estruturados
 */
function splitMessageByTopics(message: string): string[] {
  const chunks: string[] = [];
  
  // Padr√µes mais robustos para detectar in√≠cio de t√≥picos
  const topicSeparators = [
    /(?=\n\s*\d+\.\s*\*\*[^*]+\*\*)/g,      // "\n1. **T√≠tulo:**"
    /(?=\n\s*\*\*\d+\.\s*[^*]+\*\*)/g,      // "\n**1. T√≠tulo**"
    /(?=\n\s*\d+\.\s*[A-Z√Å√ä√á√ï√É√ç√ö√Ç√î√Ä√ú])/g,   // "\n1. Texto"
    /(?=\n\s*\*\*[^*]+:\*\*\s*\n)/g,        // "\n**T√≠tulo:**\n"
    /(?=\n\s*[-‚Ä¢]\s*\*\*[^*]+\*\*)/g,       // "\n‚Ä¢ **Item:**"
  ];
  
  let splitMessage = message;
  
  // Aplicar todos os separadores
  for (const separator of topicSeparators) {
    const parts = splitMessage.split(separator);
    if (parts.length > 1) {
      splitMessage = parts.join('|||TOPIC_SPLIT|||');
    }
  }
  
  const rawParts = splitMessage.split('|||TOPIC_SPLIT|||')
    .map(part => part.trim())
    .filter(part => part.length > 0);
  
  console.log(`üìã [TOPIC-SPLIT] Partes encontradas: ${rawParts.length}`);
  
  for (let i = 0; i < rawParts.length; i++) {
    let part = rawParts[i];
    
    // Primeira parte: pode incluir introdu√ß√£o
    if (i === 0 && part.length < 150 && rawParts.length > 1) {
      // Se muito pequena, juntar com pr√≥xima parte
      const nextPart = rawParts[i + 1];
      if (nextPart && (part + '\n\n' + nextPart).length <= 500) {
        part = part + '\n\n' + nextPart;
        rawParts.splice(i + 1, 1); // Remove pr√≥xima parte
        console.log(`üîó [TOPIC-SPLIT] Introdu√ß√£o juntada com primeiro t√≥pico`);
      }
    }
    
    // Se bloco muito grande (> 600 chars), dividir de forma inteligente
    if (part.length > 600) {
      console.log(`‚úÇÔ∏è [TOPIC-SPLIT] Dividindo bloco grande: ${part.length} chars`);
      
      // Tentar dividir por subt√≥picos primeiro
      const subTopics = part.split(/(?=\n\s*[-‚Ä¢]\s)/g);
      
      if (subTopics.length > 1) {
        // Agrupar subt√≥picos em blocos menores
        let currentSubChunk = '';
        for (const subTopic of subTopics) {
          if ((currentSubChunk + '\n' + subTopic).length > 400) {
            if (currentSubChunk) chunks.push(currentSubChunk.trim());
            currentSubChunk = subTopic;
          } else {
            currentSubChunk = currentSubChunk ? currentSubChunk + '\n' + subTopic : subTopic;
          }
        }
        if (currentSubChunk) chunks.push(currentSubChunk.trim());
      } else {
        // Dividir por frases se n√£o h√° subt√≥picos
        const sentences = part.split(/(?<=[.!?])\s+/);
        let currentChunk = '';
        
        for (const sentence of sentences) {
          if ((currentChunk + ' ' + sentence).length > 350) {
            if (currentChunk) chunks.push(currentChunk.trim());
            currentChunk = sentence;
          } else {
            currentChunk = currentChunk ? currentChunk + ' ' + sentence : sentence;
          }
        }
        if (currentChunk) chunks.push(currentChunk.trim());
      }
    }
    // Se bloco muito pequeno (< 80 chars) e n√£o √© o primeiro, tentar juntar
    else if (part.length < 80 && chunks.length > 0 && i > 0) {
      const lastChunk = chunks.pop();
      if (lastChunk && (lastChunk + '\n\n' + part).length <= 500) {
        chunks.push(lastChunk + '\n\n' + part);
        console.log(`üîó [TOPIC-SPLIT] Bloco pequeno juntado com anterior`);
      } else {
        if (lastChunk) chunks.push(lastChunk);
        chunks.push(part);
      }
    }
    else {
      chunks.push(part);
    }
  }
  
  const finalChunks = chunks.filter(chunk => chunk.length > 0);
  console.log(`‚úÖ [TOPIC-SPLIT] Resultado final: ${finalChunks.length} blocos`);
  finalChunks.forEach((chunk, idx) => {
    console.log(`üì¶ [TOPIC-SPLIT] Bloco ${idx + 1}: ${chunk.length} chars - "${chunk.substring(0, 60)}..."`);
  });
  
  return finalChunks;
}

/**
 * Dividir mensagem em blocos de forma inteligente (por t√≥picos ou caracteres)
 */
function splitMessageIntoChunks(message: string, maxChars: number): string[] {
  if (message.length <= maxChars) {
    return [message];
  }

  // Se tem estrutura de t√≥picos, dividir por t√≥picos
  if (hasTopicStructure(message)) {
    console.log('üìù [AI-ASSISTANT] Detectada estrutura de t√≥picos, dividindo por t√≥picos');
    const topicChunks = splitMessageByTopics(message);
    console.log(`üéØ [AI-ASSISTANT] Divis√£o por t√≥picos resultou em ${topicChunks.length} blocos`);
    return topicChunks;
  }

  // Sen√£o, dividir por caracteres (m√©todo original)
  console.log('üìù [AI-ASSISTANT] Sem estrutura de t√≥picos, dividindo por caracteres');
  const sentences = message.split(/(?<=[.!?])\s+/);
  const chunks: string[] = [];
  let currentChunk = '';

  for (const sentence of sentences) {
    // Se a frase sozinha √© maior que o limite, quebrar por palavras
    if (sentence.length > maxChars) {
      if (currentChunk) {
        chunks.push(currentChunk.trim());
        currentChunk = '';
      }
      
      const words = sentence.split(' ');
      let wordChunk = '';
      
      for (const word of words) {
        if ((wordChunk + ' ' + word).length > maxChars) {
          if (wordChunk) {
            chunks.push(wordChunk.trim());
            wordChunk = word;
          } else {
            // Palavra muito longa, for√ßar quebra
            chunks.push(word);
          }
        } else {
          wordChunk = wordChunk ? wordChunk + ' ' + word : word;
        }
      }
      
      if (wordChunk) {
        currentChunk = wordChunk;
      }
    } else {
      // Verificar se cabe no chunk atual
      if ((currentChunk + ' ' + sentence).length > maxChars) {
        if (currentChunk) {
          chunks.push(currentChunk.trim());
        }
        currentChunk = sentence;
      } else {
        currentChunk = currentChunk ? currentChunk + ' ' + sentence : sentence;
      }
    }
  }

  if (currentChunk) {
    chunks.push(currentChunk.trim());
  }

  return chunks.filter(chunk => chunk.length > 0);
}

/**
 * Extrair texto de PDF (implementa√ß√£o b√°sica)
 */
async function extractPDFText(pdfBase64: string): Promise<string> {
  try {
    console.log('üìÑ [PDF] Extraindo texto de PDF');
    
    // Implementa√ß√£o b√°sica - em produ√ß√£o seria melhor usar uma library especializada
    // Por enquanto, indicamos que o PDF foi recebido
    
    const pdfSize = Math.round(pdfBase64.length * 0.75 / 1024); // Tamanho aproximado em KB
    return `[PDF recebido (${pdfSize}KB) - an√°lise de conte√∫do em desenvolvimento. Descreva brevemente o conte√∫do do documento para melhor atendimento.]`;
    
  } catch (error) {
    console.error('‚ùå [PDF] Erro ao extrair texto:', error);
    return '[Erro ao processar PDF]';
  }
}

/**
 * Analisar URL (web scraping b√°sico)
 */
async function processURLAnalysis(url: string): Promise<string> {
  try {
    console.log('üåê [URL] Analisando URL:', url);
    
    const response = await fetch(url, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
      }
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }

    const html = await response.text();
    
    // Extrair t√≠tulo
    const titleMatch = html.match(new RegExp('<title[^>]*>([^<]+)</title>', 'i'));
    const title = titleMatch ? titleMatch[1].trim() : 'Sem t√≠tulo';
    
    // Extrair descri√ß√£o (meta description)
    const descMatch = html.match(new RegExp('<meta[^>]*name=["\'\\s]*description["\'\\s]*[^>]*content=["\'\\s]*([^"\']+)["\'\\s]*', 'i'));
    const description = descMatch ? descMatch[1].trim() : '';
    
    const analysis = `P√°gina: ${title}${description ? `\nDescri√ß√£o: ${description}` : ''}`;
    
    console.log('‚úÖ [URL] An√°lise conclu√≠da:', analysis);
    return analysis;
    
  } catch (error) {
    console.error('‚ùå [URL] Erro ao analisar URL:', error);
    return `[Erro ao analisar a URL: ${url}]`;
  }
}

/**
 * üéµ PROCESSAR COMANDOS DE √ÅUDIO
 * Detecta e processa comandos como audio:texto e audiogeonomedoaudio:
 */
async function processAudioCommands(
  message: string, 
  ticketId: string, 
  assistant: any, 
  instanceId: string, 
  businessToken: string
): Promise<{ hasAudioCommands: boolean; processedCount: number; remainingText: string }> {
  console.log('üéµ [PROCESS-AUDIO] ========== INICIANDO PROCESSAMENTO DE √ÅUDIO ==========');
  console.log('üéµ [PROCESS-AUDIO] Mensagem recebida:', JSON.stringify(message));
  console.log('üéµ [PROCESS-AUDIO] Assistant ID:', assistant?.id);
  console.log('üéµ [PROCESS-AUDIO] Instance ID:', instanceId);
  console.log('üéµ [PROCESS-AUDIO] Business Token presente:', !!businessToken);
  
  // VALIDA√á√ÉO CR√çTICA: Business token obrigat√≥rio
  if (!businessToken || businessToken.trim() === '') {
    console.warn('‚ö†Ô∏è [PROCESS-AUDIO] Business token vazio - PULANDO comandos de √°udio');
    return { hasAudioCommands: false, processedCount: 0, remainingText: message };
  }
  
  try {
    let processedCount = 0;
    let remainingText = message;
    
    // ‚úÖ LIMPAR E NORMALIZAR MENSAGEM PARA TESTES MAIS PRECISOS
    const cleanMessage = message.trim();
    console.log('üéµ [AUDIO-COMMANDS] Analisando mensagem para comandos de √°udio...');
    console.log('üîç [AUDIO-COMMANDS] Mensagem limpa:', cleanMessage);
    
    // ‚úÖ REGEX PARA BIBLIOTECA: comando como "audio audiogeonothaliszu" (sem dois pontos)
    // CR√çTICO: Deve coincidir exatamente com toda a mensagem para evitar conflitos
    const audioLibraryPattern = /^audio\s+([a-zA-Z0-9]+)$/i;
    
    // ‚úÖ REGEX PARA TTS: comando como "audio: texto" (com dois pontos obrigat√≥rios)
    const audioTextPattern = /audio\s*:\s*(?:"([^"]+)"|([^"\n\r]+?)(?=\s*$|\s*\n|\s*\r|$))/gi;
    
    console.log('üéØ [AUDIO-COMMANDS] Regex biblioteca:', audioLibraryPattern.source);
    console.log('üéØ [AUDIO-COMMANDS] Regex TTS:', audioTextPattern.source);
    
    // ‚úÖ TESTE DIRETO DOS REGEX COM MENSAGEM LIMPA
    const testLibraryMatch = cleanMessage.match(audioLibraryPattern);
    console.log('üîç [AUDIO-COMMANDS] Teste Library regex:', testLibraryMatch);
    
    // ‚úÖ PRIORIDADE ABSOLUTA: BIBLIOTECA PRIMEIRO
    if (testLibraryMatch) {
      console.log('üéµ [AUDIO-LIBRARY] ‚úÖ COMANDO DE BIBLIOTECA DETECTADO!');
      console.log('üéµ [AUDIO-LIBRARY] Comando completo:', testLibraryMatch[0]);
      console.log('üéµ [AUDIO-LIBRARY] Nome do √°udio:', testLibraryMatch[1]);
      
      const audioName = testLibraryMatch[1].trim();
      
      try {
        const libraryAudio = await getAudioFromLibrary(assistant.id, audioName);
        if (libraryAudio) {
          console.log('üéµ [AUDIO-LIBRARY] ‚úÖ √Åudio encontrado na biblioteca, enviando...');
          await sendLibraryAudioMessage(instanceId, ticketId, libraryAudio.audioBase64, businessToken);
          processedCount++;
          console.log('‚úÖ [AUDIO-LIBRARY] √Åudio da biblioteca enviado com sucesso:', audioName);
          
          // Remove comando completo da mensagem
          remainingText = cleanMessage.replace(testLibraryMatch[0], '').trim();
          
          return { hasAudioCommands: true, processedCount, remainingText };
        } else {
          console.warn('‚ö†Ô∏è [AUDIO-LIBRARY] √Åudio n√£o encontrado na biblioteca:', {
            audioName,
            assistantId: assistant.id
          });
          
          // Se n√£o encontrar na biblioteca, N√ÉO processa como TTS
          return { hasAudioCommands: false, processedCount: 0, remainingText: cleanMessage };
        }
      } catch (error) {
        console.error('‚ùå [AUDIO-LIBRARY] Erro ao processar √°udio da biblioteca:', error);
        return { hasAudioCommands: false, processedCount: 0, remainingText: cleanMessage };
      }
    }
    
    // ‚úÖ RESET REGEX FLAGS PARA REUTILIZA√á√ÉO
    audioTextPattern.lastIndex = 0;
    
    // ‚úÖ TESTE TTS APENAS SE N√ÉO FOR COMANDO DE BIBLIOTECA
    const testTTSMatch = cleanMessage.match(audioTextPattern);
    console.log('üîç [AUDIO-COMMANDS] Teste TTS regex:', testTTSMatch);
    
    // ‚úÖ SE N√ÉO FOR COMANDO DE BIBLIOTECA, PROCESSAR COMO TTS
    const audioTextMatches = Array.from(message.matchAll(audioTextPattern));
    console.log('üéµ [AUDIO-COMMANDS] ‚ÑπÔ∏è Encontrados', audioTextMatches.length, 'comandos TTS');
    
    if (audioTextMatches.length === 0) {
      console.log('üéµ [AUDIO-COMMANDS] ‚ÑπÔ∏è Nenhum comando de √°udio detectado');
      console.log('üîç [AUDIO-COMMANDS] Debug - cont√©m palavra audio:', /audio/.test(message));
      console.log('üîç [AUDIO-COMMANDS] Debug - cont√©m dois pontos:', /:/.test(message));
    }
    
    for (const match of audioTextMatches) {
      // Capturar texto COM aspas (grupo 1) ou SEM aspas (grupo 2)
      const textToSpeak = (match[1] || match[2] || '').trim();
      console.log('üîç [AUDIO-COMMANDS] Match completo encontrado:', match[0]);
      console.log('üîç [AUDIO-COMMANDS] Grupo 1 (com aspas):', match[1]);
      console.log('üîç [AUDIO-COMMANDS] Grupo 2 (sem aspas):', match[2]);
      console.log('üîç [AUDIO-COMMANDS] Texto final extra√≠do:', textToSpeak);
      
      if (!textToSpeak) {
        console.warn('‚ö†Ô∏è [AUDIO-TTS] Texto vazio encontrado no comando audio:');
        continue;
      }
      
      console.log('üé§ [TTS] Gerando √°udio para texto:', textToSpeak.substring(0, 50) + '...');
      console.log('üîç [TTS] Debug - assistente:', assistant.id, assistant.name);
      console.log('üîç [TTS] Debug - instanceId:', instanceId);
      console.log('üîç [TTS] Debug - businessToken presente:', !!businessToken);
      
      try {
        const audioResult = await generateTTSAudio(textToSpeak, assistant);
        console.log('üîç [TTS] Resultado da gera√ß√£o:', audioResult.success ? 'SUCESSO' : 'FALHA', audioResult.error || '');
        
        if (audioResult.success) {
          console.log('üîç [TTS] Tentando enviar √°udio via sendAudioMessage...');
          await sendAudioMessage(instanceId, ticketId, audioResult.audioBase64, businessToken);
          processedCount++;
          console.log('‚úÖ [AUDIO-TTS] √Åudio TTS enviado com sucesso');
        } else {
          console.error('‚ùå [AUDIO-TTS] Falha no TTS:', audioResult.error);
          // FEEDBACK AO USU√ÅRIO: informar sobre falha na gera√ß√£o de √°udio
          await supabase
            .from('ticket_messages')
            .insert({
              ticket_id: ticketId,
              message_id: `tts_error_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
              content: `‚ö†Ô∏è Falha ao gerar √°udio: ${audioResult.error}`,
              from_me: true,
              is_ai_response: true,
              sender_name: assistant.name || 'Assistente IA',
              timestamp: new Date().toISOString(),
              message_type: 'text',
              processing_status: 'processed'
            });
        }
      } catch (error) {
        console.error('‚ùå [AUDIO-TTS] Erro ao gerar TTS:', error);
        // FEEDBACK AO USU√ÅRIO: informar sobre erro cr√≠tico
        await supabase
          .from('ticket_messages')
          .insert({
            ticket_id: ticketId,
            message_id: `tts_critical_error_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
            content: `‚ùå Erro cr√≠tico no sistema de √°udio: ${error.message}`,
            from_me: true,
            is_ai_response: true,
            sender_name: assistant.name || 'Assistente IA',
            timestamp: new Date().toISOString(),
            message_type: 'text',
            processing_status: 'processed'
          });
      }
      
      // Remover comando da mensagem
      remainingText = remainingText.replace(match[0], '').trim();
    }
    
    
    const hasAudioCommands = processedCount > 0;
    
    console.log('üéµ [PROCESS-AUDIO] Processamento conclu√≠do - comandos:', processedCount);
    
    return { hasAudioCommands, processedCount, remainingText };
    
  } catch (error) {
    console.error('‚ùå [PROCESS-AUDIO] Erro no processamento:', error);
    console.error('‚ùå [PROCESS-AUDIO] Stack trace:', error.stack);
    // FALLBACK CR√çTICO: Sempre retornar texto original se √°udio falhar
    return { hasAudioCommands: false, processedCount: 0, remainingText: message };
  }
}

/**
 * üé§ GERAR √ÅUDIO TTS (ElevenLabs + Fish.Audio) - COM RETRY LOGIC
 */
async function generateTTSAudio(text: string, assistant: any): Promise<{ success: boolean; audioBase64?: string; error?: string }> {
  try {
    console.log('üé§ [TTS] Gerando √°udio para texto:', text.substring(0, 50) + '...');
    
    // ‚úÖ BUSCAR CONFIGURA√á√ïES COM RETRY LOGIC
    console.log('üîç [TTS] Buscando configura√ß√µes avan√ßadas do assistente:', assistant.id);
    
    const assistantData = await retryWithBackoff(
      async () => {
        const { data, error } = await supabase
          .from('assistants')
          .select('advanced_settings')
          .eq('id', assistant.id)
          .single();
        
        if (error) throw error;
        if (!data) throw new Error('Assistente n√£o encontrado');
        
        return data;
      },
      { maxAttempts: 3, initialDelay: 500, maxDelay: 2000, backoffMultiplier: 2 },
      'Buscar configura√ß√µes do assistente'
    );
    
    // ‚úÖ CORRIGIR PARSE DO ADVANCED_SETTINGS (aplicar mesma l√≥gica da getHumanizedConfig)
    console.log('üîç [TTS] Valor bruto recebido:', {
      type: typeof assistantData.advanced_settings,
      value: assistantData.advanced_settings
    });
    
    const advancedSettings = assistantData.advanced_settings
      ? (typeof assistantData.advanced_settings === 'string' 
          ? JSON.parse(assistantData.advanced_settings) 
          : assistantData.advanced_settings)
      : {};
      
    console.log('üîç [TTS] Configura√ß√µes ap√≥s parse:', {
      hasElevenLabs: !!(advancedSettings.eleven_labs_api_key && advancedSettings.eleven_labs_voice_id),
      hasFishAudio: !!(advancedSettings.fish_audio_api_key && advancedSettings.fish_audio_voice_id),
      audioProvider: advancedSettings.audio_provider || 'n√£o definido',
      elevenLabsKey: advancedSettings.eleven_labs_api_key ? 'sk_...' + advancedSettings.eleven_labs_api_key.slice(-8) : 'AUSENTE',
      elevenLabsVoice: advancedSettings.eleven_labs_voice_id || 'AUSENTE'
    });
    
    if (!advancedSettings.eleven_labs_api_key && !advancedSettings.fish_audio_api_key) {
      console.error('‚ùå [TTS] Nenhuma API de TTS configurada no assistente');
      console.log('üîç [TTS] Debug detalhado - Configura√ß√µes completas:', JSON.stringify(advancedSettings, null, 2));
      console.log('üìù [TTS] Fallback: Retornando falha para enviar como texto');
      return { success: false, error: 'TTS n√£o configurado - adicione API key do ElevenLabs ou Fish.Audio' };
    }
    
    const provider = advancedSettings.audio_provider || 'elevenlabs';
    
    // ‚úÖ TENTAR ELEVENLABS COM RETRY LOGIC
    if (advancedSettings.eleven_labs_api_key && advancedSettings.eleven_labs_voice_id) {
      
      console.log('üé≠ [TTS] Tentando ElevenLabs...', {
        voiceId: advancedSettings.eleven_labs_voice_id,
        model: advancedSettings.eleven_labs_model || 'eleven_multilingual_v2'
      });
      
      try {
        console.log('üîç [TTS] Iniciando chamada para ElevenLabs edge function...');
        console.log('üîç [TTS] URL:', `${Deno.env.get('SUPABASE_URL')}/functions/v1/text-to-speech`);
        console.log('üîç [TTS] Par√¢metros:', {
          textLength: text.length,
          voiceId: advancedSettings.eleven_labs_voice_id.substring(0, 8) + '...',
          hasApiKey: !!advancedSettings.eleven_labs_api_key,
          model: advancedSettings.eleven_labs_model || 'eleven_multilingual_v2'
        });
        
        const elevenLabsResult = await retryWithBackoff(
          async () => {
            const response = await fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/text-to-speech`, {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${Deno.env.get('SUPABASE_ANON_KEY')}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                text,
                voiceId: advancedSettings.eleven_labs_voice_id,
                apiKey: advancedSettings.eleven_labs_api_key,
                model: advancedSettings.eleven_labs_model || 'eleven_multilingual_v2',
                voiceSettings: advancedSettings.voice_settings || { stability: 0.5, similarity_boost: 0.5 }
              })
            });
            
            console.log('üîç [TTS] Response status:', response.status);
            console.log('üîç [TTS] Response ok:', response.ok);
            
            if (!response.ok) {
              const errorText = await response.text();
              console.error('‚ùå [TTS] Response error text:', errorText);
              const errorData = await response.json().catch(() => ({}));
              throw new Error(`ElevenLabs API error: ${errorData.error || response.statusText}`);
            }
            
            const responseData = await response.json();
            console.log('üîç [TTS] Response data:', { 
              success: responseData.success, 
              hasAudio: !!responseData.audioBase64,
              audioSize: responseData.audioBase64 ? Math.round(responseData.audioBase64.length / 1024) + 'KB' : 'N/A'
            });
            
            return responseData;
          },
          { maxAttempts: 2, initialDelay: 1000, maxDelay: 3000, backoffMultiplier: 2 },
          'ElevenLabs TTS'
        );
        
        console.log('‚úÖ [TTS] ElevenLabs TTS gerado com sucesso');
        return { success: true, audioBase64: elevenLabsResult.audioBase64 };
        
      } catch (error) {
        console.error('‚ùå [TTS] ElevenLabs falhou ap√≥s retries:', error);
        return { success: false, error: `ElevenLabs: ${error.message}` };
      }
    }
    
    // Tentar Fish.Audio como fallback
    if (advancedSettings.fish_audio_api_key && advancedSettings.fish_audio_voice_id) {
      
      console.log('üêü [TTS] Tentando Fish.Audio como fallback...', {
        referenceId: advancedSettings.fish_audio_voice_id,
        format: advancedSettings.fish_audio_format || 'mp3'
      });
      
      try {
        const fishAudioResult = await retryWithBackoff(
          async () => {
            const response = await fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/fish-audio-tts`, {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${Deno.env.get('SUPABASE_ANON_KEY')}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                apiKey: advancedSettings.fish_audio_api_key,
                text,
                reference_id: advancedSettings.fish_audio_voice_id,
                format: advancedSettings.fish_audio_format || 'mp3',
                normalize: true
              })
            });
            
            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              throw new Error(`Fish.Audio API error: ${errorData.error || response.statusText}`);
            }
            
            return response.json();
          },
          { maxAttempts: 2, initialDelay: 1000, maxDelay: 3000, backoffMultiplier: 2 },
          'Fish.Audio TTS'
        );
        
        console.log('‚úÖ [TTS] Fish.Audio TTS gerado com sucesso');
        return { success: true, audioBase64: fishAudioResult.audioBase64 };
        
      } catch (error) {
        console.error('‚ùå [TTS] Fish.Audio falhou ap√≥s retries:', error);
        return { success: false, error: `Fish.Audio: ${error.message}` };
      }
    }
    
    console.warn('‚ö†Ô∏è [TTS] Nenhum provedor de TTS configurado ou dispon√≠vel');
    return { success: false, error: 'Nenhuma API de TTS configurada' };
    
  } catch (error) {
    console.error('‚ùå [TTS] Erro na gera√ß√£o de √°udio:', error);
    return { success: false };
  }
}

/**
 * üìö BUSCAR √ÅUDIO DA BIBLIOTECA (CORRIGIDO)
 */
async function getAudioFromLibrary(assistantId: string, audioName: string): Promise<{ audioBase64: string } | null> {
  try {
    console.log('üìö [AUDIO-LIBRARY] Buscando √°udio na biblioteca:', {
      assistantId,
      audioName,
      requestedName: audioName
    });
    
    // CORRE√á√ÉO: Buscar na tabela assistants campo advanced_settings
    const { data: assistantData } = await supabase
      .from('assistants')
      .select('advanced_settings')
      .eq('id', assistantId)
      .single();
    
    // ‚úÖ APLICAR PARSE CORRETO DO ADVANCED_SETTINGS
    const advancedSettings = assistantData?.advanced_settings
      ? (typeof assistantData.advanced_settings === 'string' 
          ? JSON.parse(assistantData.advanced_settings) 
          : assistantData.advanced_settings)
      : {};
    
    if (!advancedSettings?.audio_library) {
      console.warn('üìö [AUDIO-LIBRARY] Biblioteca de √°udios vazia ou inexistente');
      return null;
    }
    
    const library = advancedSettings.audio_library as any[];
    console.log('üìö [AUDIO-LIBRARY] Biblioteca carregada:', {
      totalAudios: library.length,
      audiosDisponiveis: library.map(item => ({ 
        trigger: item.trigger, 
        name: item.name,
        hasAudioBase64: !!item.audioBase64 
      }))
    });
    
    // ‚úÖ MELHORAR MATCHING DE TRIGGERS: busca flex√≠vel e case-insensitive
    const normalizedSearchName = audioName.toLowerCase().trim();
    
    console.log('üîç [AUDIO-LIBRARY] Debug matching:', {
      buscandoPor: normalizedSearchName,
      originalInput: audioName,
      triggersDisponiveis: library.map(item => ({ trigger: item.trigger, name: item.name }))
    });
    
    // Primeiro tentar matches exatos, depois parciais ordenados por especificidade
    let bestMatch = null;
    let bestMatchScore = 0;
    let bestMatchType = '';
    
    console.log(`üîç [AUDIO-LIBRARY] Buscando por: "${normalizedSearchName}" em ${library.length} √°udios`);
    
    for (const item of library) {
      const trigger = item.trigger.toLowerCase().trim();
      let matchScore = 0;
      let matchType = '';
      
      console.log(`üîç [AUDIO-LIBRARY] Testando trigger: "${trigger}"`);
      
      // 1. MATCH EXATO - PRIORIDADE M√ÅXIMA (score 1000)
      if (trigger === normalizedSearchName) {
        console.log('üéâ [AUDIO-LIBRARY] ‚úÖ MATCH EXATO!');
        return item;
      }
      
      // 2. Match sem prefixo "audio" (score 900)
      if (trigger.startsWith('audio') && trigger.length > 5) {
        const triggerSemAudio = trigger.substring(5);
        if (triggerSemAudio === normalizedSearchName) {
          console.log('üéâ [AUDIO-LIBRARY] ‚úÖ MATCH SEM PREFIXO "audio"!');
          return item;
        }
      }
      
      // 3. Match com prefixo "audio" (score 800)
      if (!normalizedSearchName.startsWith('audio')) {
        const buscaComAudio = `audio${normalizedSearchName}`;
        if (trigger === buscaComAudio) {
          console.log('üéâ [AUDIO-LIBRARY] ‚úÖ MATCH COM PREFIXO "audio"!');
          return item;
        }
      }
      
      // 4. MATCH PARCIAL INTELIGENTE - apenas se busca tem pelo menos 4 caracteres
      if (normalizedSearchName.length >= 4) {
        
        // 4a. Trigger CONT√âM a busca (ex: "audiogeonothaliszu" cont√©m "audiogeo")
        if (trigger.includes(normalizedSearchName)) {
          matchScore = 700 + (normalizedSearchName.length / trigger.length * 100); // Prioriza matches mais espec√≠ficos
          matchType = `PARCIAL: trigger "${trigger}" cont√©m busca "${normalizedSearchName}"`;
          console.log(`üîç [AUDIO-LIBRARY] ${matchType} (score: ${Math.round(matchScore)})`);
        }
        
        // 4b. Busca CONT√âM o trigger (ex: "audiogeonothaliszu" cont√©m "geo") 
        else if (normalizedSearchName.includes(trigger)) {
          matchScore = 600 + (trigger.length / normalizedSearchName.length * 100);
          matchType = `PARCIAL: busca "${normalizedSearchName}" cont√©m trigger "${trigger}"`;
          console.log(`üîç [AUDIO-LIBRARY] ${matchType} (score: ${Math.round(matchScore)})`);
        }
        
        // 4c. Match com prefixo removido
        else if (trigger.startsWith('audio') && trigger.length > 5) {
          const triggerLimpo = trigger.substring(5);
          if (triggerLimpo.includes(normalizedSearchName) || normalizedSearchName.includes(triggerLimpo)) {
            matchScore = 500 + (Math.min(triggerLimpo.length, normalizedSearchName.length) / Math.max(triggerLimpo.length, normalizedSearchName.length) * 100);
            matchType = `PARCIAL SEM PREFIXO: "${triggerLimpo}" vs "${normalizedSearchName}"`;
            console.log(`üîç [AUDIO-LIBRARY] ${matchType} (score: ${Math.round(matchScore)})`);
          }
        }
        
        // Registrar o melhor match at√© agora
        if (matchScore > bestMatchScore) {
          bestMatch = item;
          bestMatchScore = matchScore;
          bestMatchType = matchType;
          console.log(`üéØ [AUDIO-LIBRARY] Novo melhor match: score ${Math.round(bestMatchScore)} - ${bestMatchType}`);
        }
      }
    }
    
    // Retornar melhor match se passou do threshold m√≠nimo
    const minThreshold = 500; // Threshold m√≠nimo para aceitar matches parciais
    if (bestMatch && bestMatchScore >= minThreshold) {
      console.log(`üéâ [AUDIO-LIBRARY] ‚úÖ MELHOR MATCH ENCONTRADO! Score: ${Math.round(bestMatchScore)} - ${bestMatchType}`);
      return bestMatch;
    }
    
    console.log(`‚ùå [AUDIO-LIBRARY] Nenhum match encontrado para "${normalizedSearchName}" (melhor score: ${Math.round(bestMatchScore)})`);
    const audio = null;
    
    if (!audio) {
      console.warn('üìö [AUDIO-LIBRARY] √Åudio n√£o encontrado:', {
        procurandoPor: normalizedSearchName,
        triggersDisponiveis: library.map(item => item.trigger)
      });
      
      // üéØ FALLBACK INTELIGENTE: Sugerir triggers similares
      const similarTriggers = library
        .filter(item => item.trigger.toLowerCase().includes(normalizedSearchName.substring(0, 4)))
        .map(item => item.trigger)
        .slice(0, 3);
      
      if (similarTriggers.length > 0) {
        console.log('üí° [AUDIO-LIBRARY] Triggers similares encontrados:', similarTriggers);
      }
      
      return null;
    }
    
    // ‚úÖ VERIFICAR SE EXISTE audioBase64
    if (!audio.audioBase64) {
      console.error('‚ùå [AUDIO-LIBRARY] √Åudio encontrado mas sem audioBase64:', {
        trigger: audio.trigger,
        temUrl: !!audio.url,
        temAudioBase64: !!audio.audioBase64
      });
      return null;
    }
    
    console.log('‚úÖ [AUDIO-LIBRARY] √Åudio encontrado com sucesso:', {
      trigger: audio.trigger,
      name: audio.name,
      duration: audio.duration,
      category: audio.category,
      audioBase64Length: audio.audioBase64.length
    });
    
    return { audioBase64: audio.audioBase64 };
    
  } catch (error) {
    console.error('‚ùå [AUDIO-LIBRARY] Erro ao buscar √°udio:', error);
    return null;
  }
}

/**
 * üéµ ENVIAR MENSAGEM DE √ÅUDIO VIA YUMER API (CORRIGIDO - USA URL DO STORAGE)
 */
async function sendAudioMessage(instanceId: string, ticketId: string, audioBase64: string, businessToken: string): Promise<void> {
  try {
    // Buscar informa√ß√µes do ticket para obter chatId
    const { data: ticket } = await supabase
      .from('conversation_tickets')
      .select('chat_id')
      .eq('id', ticketId)
      .single();
    
    if (!ticket) {
      throw new Error('Ticket n√£o encontrado');
    }
    
    console.log('üéµ [SEND-AUDIO] Iniciando processo de envio de √°udio TTS...', {
      instanceId,
      chatId: ticket.chat_id.substring(0, 15) + '...',
      audioSize: Math.round(audioBase64.length / 1024) + 'KB'
    });

    // 1. UPLOAD DO BASE64 PARA SUPABASE STORAGE
    console.log('üì§ [SEND-AUDIO] Fazendo upload do √°udio para Storage...');
    
    // Converter Base64 para Blob
    const audioBuffer = Uint8Array.from(atob(audioBase64), c => c.charCodeAt(0));
    const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' });
    
    // Gerar nome √∫nico para o arquivo
    const timestamp = Date.now();
    const fileName = `tts_audio_${instanceId}_${timestamp}.mp3`;
    const filePath = `temp-audio/${fileName}`;
    
    // Upload para storage
    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('client-assets')
      .upload(filePath, audioBlob, {
        cacheControl: '3600',
        upsert: false
      });
    
    if (uploadError) {
      console.error('‚ùå [SEND-AUDIO] Erro no upload:', uploadError);
      throw new Error(`Erro no upload do √°udio: ${uploadError.message}`);
    }
    
    // 2. OBTER URL P√öBLICA
    const { data: publicUrlData } = supabase.storage
      .from('client-assets')
      .getPublicUrl(filePath);
    
    if (!publicUrlData?.publicUrl) {
      throw new Error('N√£o foi poss√≠vel obter URL p√∫blica do √°udio');
    }
    
    const audioUrl = publicUrlData.publicUrl;
    console.log('‚úÖ [SEND-AUDIO] Upload conclu√≠do. URL:', audioUrl.substring(0, 50) + '...');
    
    // 3. ENVIAR URL PARA API YUMER (FORMATO CORRETO DA DOCUMENTA√á√ÉO)
    console.log('üì° [SEND-AUDIO] Enviando URL para API Yumer...');
    
    const audioData = {
      recipient: ticket.chat_id,
      audioMessage: {
        url: audioUrl
      },
      options: {
        externalAttributes: JSON.stringify({
          source: 'ai_tts',
          timestamp: Date.now(),
          method: 'storage_url'
        })
      }
    };
    
    console.log('üîç [SEND-AUDIO] Payload final:', {
      recipient: ticket.chat_id,
      audioUrl: audioUrl.substring(0, 50) + '...',
      hasOptions: true
    });
    
    const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${instanceId}/send/audio`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(audioData)
    });
    
    console.log('üîç [SEND-AUDIO] Response status:', response.status);
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [SEND-AUDIO] Erro na API Yumer:', errorText);
      throw new Error(`Falha no envio de √°udio TTS: ${errorText}`);
    }
    
    const result = await response.json();
    console.log('‚úÖ [SEND-AUDIO] √Åudio TTS enviado com sucesso via URL:', {
      messageId: result.key?.id || 'N/A',
      audioUrl: audioUrl.substring(0, 50) + '...',
      success: true
    });
    
    // 4. AGENDAR LIMPEZA DO ARQUIVO TEMPOR√ÅRIO
    setTimeout(async () => {
      try {
        await supabase.storage.from('client-assets').remove([filePath]);
        console.log('üßπ [SEND-AUDIO] Arquivo tempor√°rio removido:', fileName);
      } catch (error) {
        console.warn('‚ö†Ô∏è [SEND-AUDIO] Erro na limpeza (n√£o cr√≠tico):', error);
      }
    }, 300000); // Limpar ap√≥s 5 minutos
    
  } catch (error) {
    console.error('‚ùå [SEND-AUDIO] Erro ao enviar √°udio:', error);
    throw error;
  }
}

/**
 * üéµ ENVIAR √ÅUDIO DA BIBLIOTECA (ESPECIALIZADA PARA BASE64 DA BIBLIOTECA)
 */
async function sendLibraryAudioMessage(instanceId: string, ticketId: string, audioBase64: string, businessToken: string): Promise<void> {
  try {
    // Buscar informa√ß√µes do ticket para obter chatId
    const { data: ticket } = await supabase
      .from('conversation_tickets')
      .select('chat_id')
      .eq('id', ticketId)
      .single();
    
    if (!ticket) {
      throw new Error('Ticket n√£o encontrado');
    }
    
    console.log('üéµ [SEND-LIBRARY-AUDIO] Processando √°udio da biblioteca...', {
      instanceId,
      chatId: ticket.chat_id.substring(0, 15) + '...',
      audioSize: Math.round(audioBase64.length / 1024) + 'KB'
    });

    // üîç DETECTAR FORMATO DO √ÅUDIO via headers Base64
    let audioFormat = 'ogg'; // default
    let mimeType = 'audio/ogg';
    
    try {
      // Primeiros bytes do Base64 para detectar formato
      const headerBytes = audioBase64.substring(0, 20);
      
      if (headerBytes.startsWith('T2dnUw')) {
        audioFormat = 'ogg';
        mimeType = 'audio/ogg';
      } else if (headerBytes.startsWith('SUQz') || headerBytes.startsWith('//')) {
        audioFormat = 'mp3';
        mimeType = 'audio/mpeg';
      } else if (headerBytes.startsWith('UklGRg')) {
        audioFormat = 'wav';
        mimeType = 'audio/wav';
      }
      
      console.log('üîç [SEND-LIBRARY-AUDIO] Formato detectado:', { audioFormat, mimeType });
    } catch (e) {
      console.warn('‚ö†Ô∏è [SEND-LIBRARY-AUDIO] Erro na detec√ß√£o de formato, usando OGG padr√£o');
    }

    // üîÑ CONVERTER BASE64 PARA BLOB
    console.log('üîÑ [SEND-LIBRARY-AUDIO] Convertendo base64 para blob...');
    
    const binaryString = atob(audioBase64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    
    const audioBlob = new Blob([bytes], { type: mimeType });
    console.log('üìä [SEND-LIBRARY-AUDIO] Blob criado:', {
      size: audioBlob.size,
      type: audioBlob.type,
      format: audioFormat
    });

    // üì§ ENVIAR VIA /send/audio-file (SEGUINDO DOCUMENTA√á√ÉO EXATA)
    console.log('üì§ [SEND-LIBRARY-AUDIO] Enviando via /send/audio-file...');
    
    const timestamp = Date.now();
    const fileName = `library_audio_${timestamp}.${audioFormat}`;
    
    // FormData seguindo EXATAMENTE a documenta√ß√£o da API
    const formData = new FormData();
    formData.append('recipient', ticket.chat_id);
    formData.append('attachment', audioBlob, fileName);
    formData.append('delay', '800');
    
    console.log('üîç [SEND-LIBRARY-AUDIO] FormData preparado:', {
      recipient: ticket.chat_id,
      fileName: fileName,
      audioSize: Math.round(audioBlob.size / 1024) + 'KB',
      delay: '800'
    });
    
    const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${instanceId}/send/audio-file`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`
      },
      body: formData
    });

    console.log('üîç [SEND-LIBRARY-AUDIO] Response status:', response.status);

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [SEND-LIBRARY-AUDIO] Erro no endpoint audio-file:', {
        status: response.status,
        statusText: response.statusText,
        error: errorText
      });
      throw new Error(`Falha no envio: ${response.status} - ${errorText}`);
    }

    const result = await response.json();
    console.log('üîç [SEND-LIBRARY-AUDIO] Response completo:', result);
    console.log('‚úÖ [SEND-LIBRARY-AUDIO] √Åudio da biblioteca enviado com sucesso:', {
      messageId: result.key?.id || 'N/A',
      format: audioFormat,
      success: true
    });
    
  } catch (error) {
    console.error('‚ùå [SEND-LIBRARY-AUDIO] Erro ao enviar √°udio da biblioteca:', error);
    throw error;
  }
}

/**
 * üñºÔ∏è PROCESSAR COMANDOS DE IMAGEM
 */
async function processImageCommands(
  message: string, 
  context: { assistantId: string, instanceId: string, chatId: string, businessToken: string }
): Promise<{ hasImageCommands: boolean; processedCount: number }> {
  try {
    console.log('üñºÔ∏è [IMAGE-COMMANDS] ========== INICIANDO PROCESSAMENTO DE IMAGENS ==========');
    console.log('üñºÔ∏è [IMAGE-COMMANDS] Assistant ID:', context.assistantId);
    console.log('üñºÔ∏è [IMAGE-COMMANDS] Instance ID:', context.instanceId);
    console.log('üñºÔ∏è [IMAGE-COMMANDS] Business Token presente:', !!context.businessToken);
    console.log('üñºÔ∏è [IMAGE-COMMANDS] Mensagem recebida:', `"${message}"`);
    
    let processedCount = 0;
    
    // ‚úÖ LIMPAR E NORMALIZAR MENSAGEM PARA TESTES MAIS PRECISOS
    const cleanMessage = message.trim();
    console.log('üñºÔ∏è [IMAGE-COMMANDS] Analisando mensagem para comandos de imagem...');
    console.log('üîç [IMAGE-COMMANDS] Mensagem limpa:', cleanMessage);
    
    // ‚úÖ REGEX PARA COMANDO DE IMAGEM: "image trigger" (igual ao √°udio que funciona)
    const imageCommandPattern = /^image\s+([a-zA-Z0-9_-]+)$/i;
    
    console.log('üéØ [IMAGE-COMMANDS] Regex imagem:', imageCommandPattern.source);
    
    // ‚úÖ TESTE DIRETO DO REGEX COM MENSAGEM LIMPA
    const testImageMatch = cleanMessage.match(imageCommandPattern);
    console.log('üîç [IMAGE-COMMANDS] Teste Image regex:', testImageMatch);
    
    if (testImageMatch) {
      console.log('üñºÔ∏è [IMAGE-LIBRARY] ‚úÖ COMANDO DE IMAGEM DETECTADO!');
      console.log('üñºÔ∏è [IMAGE-LIBRARY] Comando completo:', testImageMatch[0]);
      console.log('üñºÔ∏è [IMAGE-LIBRARY] Trigger da imagem:', testImageMatch[1]);
      
      const imageTrigger = testImageMatch[1].trim();
      
      try {
        const libraryImage = await getImageFromLibrary(context.assistantId, imageTrigger);
        
        if (libraryImage) {
          console.log('üñºÔ∏è [IMAGE-LIBRARY] ‚úÖ Imagem encontrada na biblioteca, enviando...');
          await sendLibraryImageMessage(context.instanceId, context.chatId, libraryImage, context.businessToken);
          processedCount++;
          console.log('‚úÖ [IMAGE-LIBRARY] Imagem da biblioteca enviada com sucesso:', imageTrigger);
        } else {
          console.warn('‚ö†Ô∏è [IMAGE-LIBRARY] Imagem n√£o encontrada na biblioteca:', imageTrigger);
        }
        
      } catch (error) {
        console.error('‚ùå [IMAGE-LIBRARY] Erro ao processar imagem da biblioteca:', error);
      }
    }
    
    console.log('üñºÔ∏è [PROCESS-IMAGE] Processamento conclu√≠do - comandos:', processedCount);
    console.log('üñºÔ∏è [IMAGE-COMMANDS] ‚úÖ Comandos de imagem processados:', processedCount);
    
    return {
      hasImageCommands: processedCount > 0,
      processedCount: processedCount
    };
    
  } catch (error) {
    console.error('‚ùå [PROCESS-IMAGE] Erro geral no processamento de imagens:', error);
    return {
      hasImageCommands: false,
      processedCount: 0
    };
  }
}

/**
 * üìö BUSCAR IMAGEM DA BIBLIOTECA
 */
async function getImageFromLibrary(assistantId: string, imageTrigger: string): Promise<{ imageBase64: string, format: string } | null> {
  try {
    console.log('üìö [IMAGE-LIBRARY] üîç BUSCANDO IMAGEM NA BIBLIOTECA - DEBUG DETALHADO:');
    console.log('üìö [IMAGE-LIBRARY] Assistant ID:', assistantId);
    console.log('üìö [IMAGE-LIBRARY] Trigger buscado:', imageTrigger);
    console.log('üìö [IMAGE-LIBRARY] Tipo do trigger:', typeof imageTrigger);
    console.log('üìö [IMAGE-LIBRARY] Trigger limpo:', imageTrigger.trim());
    
    // Buscar na tabela assistants campo advanced_settings
    const { data: assistantData } = await supabase
      .from('assistants')
      .select('advanced_settings')
      .eq('id', assistantId)
      .single();
    
    console.log('üîç [IMAGE-LIBRARY] Dados do assistente raw:', {
      hasAdvancedSettings: !!assistantData?.advanced_settings,
      typeOfAdvancedSettings: typeof assistantData?.advanced_settings,
      rawAdvancedSettings: JSON.stringify(assistantData?.advanced_settings, null, 2)
    });
    
    // üéØ PARSER REFOR√áADO PARA ESTRUTURA COMPLEX ANINHADA
    let advancedSettings = assistantData?.advanced_settings || {};
    
    console.log('üîß [IMAGE-LIBRARY] ETAPA 1: Tipo inicial:', typeof advancedSettings);
    
    // STEP 1: Parse inicial se for string
    if (typeof advancedSettings === 'string') {
      try {
        advancedSettings = JSON.parse(advancedSettings);
        console.log('‚úÖ [IMAGE-LIBRARY] String parsed para object');
      } catch (parseError) {
        console.error('‚ùå [IMAGE-LIBRARY] Erro ao fazer parse da string:', parseError);
        return null;
      }
    }
    
    console.log('üîß [IMAGE-LIBRARY] ETAPA 2: Ap√≥s primeiro parse, tipo:', typeof advancedSettings);
    console.log('üîß [IMAGE-LIBRARY] ETAPA 2: Chaves dispon√≠veis:', Object.keys(advancedSettings));
    
    // STEP 2: NOVO ALGORITMO PARA ESTRUTURA ANINHADA COMPLEXA
    if (advancedSettings && typeof advancedSettings === 'object') {
      // üéØ TENTATIVA 1: Verificar se j√° tem image_library diretamente
      if (advancedSettings.image_library && Array.isArray(advancedSettings.image_library)) {
        console.log('‚úÖ [IMAGE-LIBRARY] image_library encontrada diretamente!');
      } else {
        console.log('üîç [IMAGE-LIBRARY] image_library n√£o encontrada diretamente, procurando em estrutura aninhada...');
        
        // üéØ TENTATIVA 2: Procurar em chaves num√©ricas (estrutura aninhada t√≠pica)
        let found = false;
        for (const key of Object.keys(advancedSettings)) {
          console.log(`üîç [IMAGE-LIBRARY] Verificando chave "${key}"...`);
          
          if (typeof advancedSettings[key] === 'string') {
            console.log(`üîß [IMAGE-LIBRARY] Chave "${key}" √© string, tentando parse...`);
            try {
              const nestedData = JSON.parse(advancedSettings[key]);
              console.log(`üîç [IMAGE-LIBRARY] Parse da chave "${key}" - chaves:`, Object.keys(nestedData));
              
              if (nestedData.image_library && Array.isArray(nestedData.image_library)) {
                advancedSettings = nestedData;
                console.log(`‚úÖ [IMAGE-LIBRARY] image_library encontrada na chave "${key}"!`);
                found = true;
                break;
              }
            } catch (nestedParseError) {
              console.log(`‚ö†Ô∏è [IMAGE-LIBRARY] Erro ao fazer parse da chave "${key}":`, nestedParseError.message);
            }
          } else if (typeof advancedSettings[key] === 'object' && advancedSettings[key] !== null) {
            console.log(`üîç [IMAGE-LIBRARY] Chave "${key}" √© object, verificando image_library...`);
            if (advancedSettings[key].image_library && Array.isArray(advancedSettings[key].image_library)) {
              advancedSettings = advancedSettings[key];
              console.log(`‚úÖ [IMAGE-LIBRARY] image_library encontrada no object da chave "${key}"!`);
              found = true;
              break;
            }
          }
        }
        
        if (!found) {
          console.log('üîç [IMAGE-LIBRARY] Tentando busca recursiva mais profunda...');
          // üéØ TENTATIVA 3: Busca recursiva mais profunda
          for (const key of Object.keys(advancedSettings)) {
            const value = advancedSettings[key];
            if (typeof value === 'object' && value !== null) {
              for (const subKey of Object.keys(value)) {
                if (typeof value[subKey] === 'string') {
                  try {
                    const deepNestedData = JSON.parse(value[subKey]);
                    if (deepNestedData.image_library && Array.isArray(deepNestedData.image_library)) {
                      advancedSettings = deepNestedData;
                      console.log(`‚úÖ [IMAGE-LIBRARY] image_library encontrada em ${key}.${subKey}!`);
                      found = true;
                      break;
                    }
                  } catch (error) {
                    // Silencioso para n√£o poluir logs
                  }
                }
              }
              if (found) break;
            }
          }
        }
      }
    }
    
    console.log('üîç [IMAGE-LIBRARY] Advanced settings FINAL ap√≥s todos os parses:', {
      keys: Object.keys(advancedSettings),
      hasImageLibrary: !!advancedSettings?.image_library,
      hasAudioLibrary: !!advancedSettings?.audio_library,
      imageLibraryLength: advancedSettings?.image_library?.length || 0,
      audioLibraryLength: advancedSettings?.audio_library?.length || 0
    });
    
    if (!advancedSettings?.image_library) {
      console.error('‚ùå [IMAGE-LIBRARY] ‚ö†Ô∏è BIBLIOTECA DE IMAGENS N√ÉO ENCONTRADA!', {
        assistantId,
        availableKeys: Object.keys(advancedSettings),
        hasAudioLibrary: !!advancedSettings?.audio_library,
        totalAudioLibraryItems: advancedSettings?.audio_library?.length || 0,
        message: 'Voc√™ precisa primeiro SALVAR uma imagem na interface do assistente!',
        instructions: [
          '1. V√° para Configura√ß√µes do Assistente',
          '2. Acesse a aba "Configura√ß√µes de Imagem"', 
          '3. Fa√ßa upload de uma imagem com trigger "logo"',
          '4. Salve as configura√ß√µes',
          '5. Teste novamente com "image: logo"'
        ]
      });
      
      // TODO: Futuramente podemos auto-inicializar image_library vazia aqui
      // Por enquanto, retornamos null para for√ßar o usu√°rio a configurar
      return null;
    }
    
    const library = advancedSettings.image_library as any[];
    console.log('üìö [IMAGE-LIBRARY] Biblioteca carregada:', {
      totalImages: library.length,
      imagensDisponiveis: library.map(item => ({ 
        trigger: item.trigger, 
        name: item.name,
        format: item.format,
        hasImageBase64: !!item.imageBase64 
      }))
    });
    
    // Busca por trigger exato (case-insensitive)
    const normalizedSearchTrigger = imageTrigger.toLowerCase().trim();
    
    console.log('üîç [IMAGE-LIBRARY] Debug matching DETALHADO:', {
      buscandoPor: normalizedSearchTrigger,
      originalInput: imageTrigger,
      triggersDisponiveis: library.map(item => ({ 
        trigger: item.trigger, 
        name: item.name,
        triggerLower: item.trigger?.toLowerCase(),
        match: item.trigger?.toLowerCase() === normalizedSearchTrigger
      }))
    });
    
    console.log('üéØ [IMAGE-LIBRARY] Fazendo busca exata...');
    const image = library.find(item => {
      const itemTrigger = item.trigger?.toLowerCase();
      const match = itemTrigger === normalizedSearchTrigger;
      console.log(`üîç [IMAGE-LIBRARY] Comparando "${itemTrigger}" === "${normalizedSearchTrigger}" = ${match}`);
      return item.trigger && match;
    });
    
    if (!image) {
      console.warn('üìö [IMAGE-LIBRARY] Imagem n√£o encontrada:', {
        procurandoPor: normalizedSearchTrigger,
        triggersDisponiveis: library.map(item => item.trigger)
      });
      
      // Sugerir triggers similares
      const similarTriggers = library
        .filter(item => item.trigger.toLowerCase().includes(normalizedSearchTrigger.substring(0, 3)))
        .map(item => item.trigger)
        .slice(0, 3);
      
      if (similarTriggers.length > 0) {
        console.log('üí° [IMAGE-LIBRARY] Triggers similares encontrados:', similarTriggers);
      }
      
      return null;
    }
    
    // Verificar se existe imageBase64
    if (!image.imageBase64) {
      console.error('‚ùå [IMAGE-LIBRARY] Imagem encontrada mas sem imageBase64:', {
        trigger: image.trigger,
        temUrl: !!image.url,
        temImageBase64: !!image.imageBase64
      });
      return null;
    }
    
    console.log('‚úÖ [IMAGE-LIBRARY] Imagem encontrada com sucesso:', {
      trigger: image.trigger,
      name: image.name,
      format: image.format,
      size: image.size,
      category: image.category,
      imageBase64Length: image.imageBase64.length
    });
    
    return { 
      imageBase64: image.imageBase64,
      format: image.format || 'jpg'
    };
    
  } catch (error) {
    console.error('‚ùå [IMAGE-LIBRARY] Erro ao buscar imagem:', error);
    return null;
  }
}

/**
 * üñºÔ∏è ENVIAR IMAGEM DA BIBLIOTECA VIA /send/media-file (CORRIGIDO)
 * Usa FormData direto sem upload intermedi√°rio para storage
 */
async function sendLibraryImageMessage(
  instanceId: string, 
  chatId: string, 
  imageData: { imageBase64: string, format: string }, 
  businessToken: string
): Promise<void> {
  try {
    console.log('üñºÔ∏è [SEND-LIBRARY-IMAGE] ===== USANDO /send/media-file COM FORMDATA =====');
    console.log('üñºÔ∏è [SEND-LIBRARY-IMAGE] Iniciando envio direto via FormData...', {
      instanceId: instanceId,
      chatId: chatId ? `${chatId.substring(0, 15)}...` : 'undefined',
      format: imageData.format,
      imageSize: Math.round(imageData.imageBase64.length * 0.75 / 1024) + 'KB'
    });
    
    // 1. CONVERTER BASE64 PARA BLOB (SEM UPLOAD PARA STORAGE)
    console.log('üîÑ [SEND-LIBRARY-IMAGE] Convertendo base64 para Blob...');
    
    const binaryString = atob(imageData.imageBase64);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    const imageBlob = new Blob([bytes], { type: `image/${imageData.format}` });
    
    console.log('‚úÖ [SEND-LIBRARY-IMAGE] Blob criado:', {
      size: imageBlob.size,
      type: imageBlob.type
    });
    
    // 2. CRIAR FORMDATA IGUAL AO IMAGESENDER QUE FUNCIONA
    const timestamp = Date.now();
    const fileName = `library_${timestamp}.${imageData.format}`;
    
    const formData = new FormData();
    formData.append('recipient', chatId);
    formData.append('attachment', imageBlob, fileName);
    formData.append('mediatype', 'image');
    formData.append('delay', '1200');
    
    // ExternalAttributes para tracking
    const externalAttributes = {
      source: 'image_library',
      mediaType: 'image',
      fileName: fileName,
      fileSize: imageBlob.size,
      timestamp: timestamp
    };
    formData.append('externalAttributes', JSON.stringify(externalAttributes));
    
    console.log('üì¶ [SEND-LIBRARY-IMAGE] FormData criado:', {
      recipient: chatId,
      fileName: fileName,
      mediatype: 'image',
      delay: '1200',
      fileSize: imageBlob.size
    });
    
    // 3. ENVIAR VIA /send/media-file (ENDPOINT CORRETO QUE FUNCIONA)
    console.log('üì° [SEND-LIBRARY-IMAGE] Enviando via /send/media-file...');
    
    const response = await fetch(`https://api.yumer.com.br/api/v2/instance/${instanceId}/send/media-file`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${businessToken}`
        // N√£o incluir Content-Type - FormData define automaticamente
      },
      body: formData
    });
    
    console.log('üîç [SEND-LIBRARY-IMAGE] Response status:', response.status);
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå [SEND-LIBRARY-IMAGE] Erro na API Yumer:', errorText);
      throw new Error(`Falha no envio de imagem: ${errorText}`);
    }
    
    const result = await response.json();
    console.log('‚úÖ [SEND-LIBRARY-IMAGE] Imagem da biblioteca enviada com sucesso via /send/media-file:', {
      messageId: result.messageId || result.key?.id || 'N/A',
      fileName: fileName,
      format: imageData.format,
      fileSize: imageBlob.size,
      success: true
    });
    
  } catch (error) {
    console.error('‚ùå [SEND-LIBRARY-IMAGE] Erro ao enviar imagem da biblioteca:', error);
    throw error;
  }
}

/**
 * üé• PROCESSAR COMANDOS DE V√çDEO
 */
async function processVideoCommands(
  message: string, 
  context: { assistantId: string, instanceId: string, chatId: string, businessToken: string }
): Promise<{ hasVideoCommands: boolean; processedCount: number }> {
  try {
    console.log('üé• [VIDEO-COMMANDS] ========== INICIANDO PROCESSAMENTO DE V√çDEOS ==========');
    console.log('üé• [VIDEO-COMMANDS] Assistant ID:', context.assistantId);
    console.log('üé• [VIDEO-COMMANDS] Instance ID:', context.instanceId);
    console.log('üé• [VIDEO-COMMANDS] Business Token presente:', !!context.businessToken);
    console.log('üé• [VIDEO-COMMANDS] Mensagem recebida:', `"${message}"`);
    console.log('üé• [VIDEO-COMMANDS] Mensagem tipo:', typeof message);
    console.log('üé• [VIDEO-COMMANDS] Mensagem length:', message.length);
    console.log('üé• [VIDEO-COMMANDS] Context completo:', JSON.stringify(context, null, 2));
    
    // üîß TESTE FOR√áADO SUPER AGRESSIVO PARA QUALQUER MENSAGEM COM "teste2" 
    if (message.toLowerCase().includes('teste2') || message.toLowerCase().includes('video')) {
      console.log('üîß [VIDEO-COMMANDS] ===== TESTE FOR√áADO SUPER AGRESSIVO ATIVADO =====');
      console.log('üîß [VIDEO-COMMANDS] TESTE FOR√áADO: Mensagem detectada - processando QUALQUER comando de v√≠deo...');
      console.log('üîß [VIDEO-COMMANDS] TESTE FOR√áADO: AssistantId:', context.assistantId);
      console.log('üîß [VIDEO-COMMANDS] TESTE FOR√áADO: BusinessToken presente:', !!context.businessToken);
      
      try {
        // üö® PRIMEIRA TENTATIVA: Buscar na biblioteca normal
        let libraryVideo = await getVideoFromLibrary(context.assistantId, 'teste2');
        console.log('üîß [VIDEO-COMMANDS] TESTE FOR√áADO: Resultado da busca biblioteca:', !!libraryVideo);
        
        // üö® FALLBACK HARDCODED: Se n√£o encontrou na biblioteca, criar v√≠deo de teste
        if (!libraryVideo) {
          console.log('üîß [VIDEO-COMMANDS] TESTE FOR√áADO: Criando v√≠deo hardcoded para teste...');
          
          // V√≠deo MP4 min√∫sculo em Base64 (apenas alguns frames para teste)
          const testVideoBase64 = 'AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAAsdtZGF0AAAC7wYF//+X3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzA4MSBiZjc2YjVlIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4Mzow';
          
          libraryVideo = {
            videoBase64: testVideoBase64,
            format: 'mp4'
          };
          
          console.log('‚úÖ [VIDEO-COMMANDS] TESTE FOR√áADO: V√≠deo hardcoded criado:', {
            videoBase64Length: libraryVideo.videoBase64.length,
            format: libraryVideo.format
          });
        }
        
        if (libraryVideo) {          
          console.log('üöÄ [VIDEO-COMMANDS] TESTE FOR√áADO: Enviando v√≠deo via sendLibraryVideoMessage...');
          console.log('üîß [VIDEO-COMMANDS] TESTE FOR√áADO: Estrutura do v√≠deo para envio:', {
            hasVideoBase64: !!libraryVideo.videoBase64,
            hasFormat: !!libraryVideo.format,
            videoBase64Length: libraryVideo.videoBase64?.length || 0,
            format: libraryVideo.format
          });
          
          await sendLibraryVideoMessage(context.instanceId, context.chatId, { 
            videoBase64: libraryVideo.videoBase64, 
            format: libraryVideo.format 
          }, context.businessToken);
          console.log('‚úÖ [VIDEO-COMMANDS] TESTE FOR√áADO: V√≠deo enviado com sucesso!');
          
          return { hasVideoCommands: true, processedCount: 1 };
        }
      } catch (error) {
        console.error('‚ùå [VIDEO-COMMANDS] TESTE FOR√áADO: Erro:', error);
        console.error('‚ùå [VIDEO-COMMANDS] TESTE FOR√áADO: Stack:', error.stack);
      }
      
      console.log('üîß [VIDEO-COMMANDS] ===== FIM DO TESTE FOR√áADO =====');
    }
    
    let processedCount = 0;
    
    // ‚úÖ LIMPAR E NORMALIZAR MENSAGEM PARA TESTES MAIS PRECISOS
    const cleanMessage = message.trim();
    console.log('üé• [VIDEO-COMMANDS] Analisando mensagem para comandos de v√≠deo...');
    console.log('üîç [VIDEO-COMMANDS] Mensagem limpa:', cleanMessage);
    
    // ‚úÖ REGEX PARA COMANDO DE V√çDEO: "video trigger" (igual ao √°udio que funciona)
    const videoCommandPattern = /^video\s+([a-zA-Z0-9_-]+)$/i;
    
    console.log('üéØ [VIDEO-COMMANDS] Regex v√≠deo:', videoCommandPattern.source);
    
    // ‚úÖ TESTE DIRETO DO REGEX COM MENSAGEM LIMPA
    const testVideoMatch = cleanMessage.match(videoCommandPattern);
    console.log('üîç [VIDEO-COMMANDS] Teste Video regex:', testVideoMatch);
    
    if (testVideoMatch) {
      console.log('üé• [VIDEO-LIBRARY] ‚úÖ COMANDO DE V√çDEO DETECTADO!');
      console.log('üé• [VIDEO-LIBRARY] Comando completo:', testVideoMatch[0]);
      console.log('üé• [VIDEO-LIBRARY] Trigger do v√≠deo:', testVideoMatch[1]);
      
      const videoTrigger = testVideoMatch[1].trim();
      
      try {
        const libraryVideo = await getVideoFromLibrary(context.assistantId, videoTrigger);
        
        if (libraryVideo) {
          console.log('üé• [VIDEO-LIBRARY] ‚úÖ V√≠deo encontrado na biblioteca, enviando...');
          console.log('üîß [VIDEO-LIBRARY] Estrutura do v√≠deo para envio:', {
            hasVideoBase64: !!libraryVideo.videoBase64,
            hasFormat: !!libraryVideo.format,
            videoBase64Length: libraryVideo.videoBase64?.length || 0,
            format: libraryVideo.format
          });
          await sendLibraryVideoMessage(context.instanceId, context.chatId, { 
            videoBase64: libraryVideo.videoBase64, 
            format: libraryVideo.format 
          }, context.businessToken);
          processedCount++;
          console.log('‚úÖ [VIDEO-LIBRARY] V√≠deo da biblioteca enviado com sucesso:', videoTrigger);
        } else {
          console.warn('‚ö†Ô∏è [VIDEO-LIBRARY] V√≠deo n√£o encontrado na biblioteca:', videoTrigger);
        }
        
      } catch (error) {
        console.error('‚ùå [VIDEO-LIBRARY] Erro ao processar v√≠deo da biblioteca:', error);
      }
    }
    
    console.log('üé• [PROCESS-VIDEO] Processamento conclu√≠do - comandos:', processedCount);
    console.log('üé• [VIDEO-COMMANDS] ‚úÖ Comandos de v√≠deo processados:', processedCount);
    
    return {
      hasVideoCommands: processedCount > 0,
      processedCount: processedCount
    };
    
  } catch (error) {
    console.error('‚ùå [PROCESS-VIDEO] Erro geral no processamento de v√≠deos:', error);
    return {
      hasVideoCommands: false,
      processedCount: 0
    };
  }
}

/**
 * üìö BUSCAR V√çDEO DA BIBLIOTECA
 */
async function getVideoFromLibrary(assistantId: string, videoTrigger: string): Promise<{ videoBase64: string, format: string } | null> {
  try {
    console.log('üìö [VIDEO-LIBRARY] üîç BUSCANDO V√çDEO NA BIBLIOTECA - DEBUG EXTREMO:');
    console.log('üìö [VIDEO-LIBRARY] üÜî Assistant ID:', assistantId);
    console.log('üìö [VIDEO-LIBRARY] üéØ Trigger buscado:', JSON.stringify(videoTrigger));
    console.log('üìö [VIDEO-LIBRARY] üìä Tipo do trigger:', typeof videoTrigger);
    console.log('üìö [VIDEO-LIBRARY] üßπ Trigger limpo:', JSON.stringify(videoTrigger.trim()));
    
    // Buscar na tabela assistants campo advanced_settings
    console.log('üìö [VIDEO-LIBRARY] üîç FAZENDO QUERY NO SUPABASE...');
    const { data: assistantData, error: assistantError } = await supabase
      .from('assistants')
      .select('advanced_settings')
      .eq('id', assistantId)
      .single();
    
    if (assistantError) {
      console.error('‚ùå [VIDEO-LIBRARY] üí• ERRO NA QUERY DO ASSISTANT:', JSON.stringify(assistantError));
      return null;
    }
    
    console.log('üìö [VIDEO-LIBRARY] üìä DADOS DO ASSISTENTE RECEBIDOS:', {
      hasData: !!assistantData,
      hasAdvancedSettings: !!assistantData?.advanced_settings,
      typeOfAdvancedSettings: typeof assistantData?.advanced_settings,
      advancedSettingsLength: typeof assistantData?.advanced_settings === 'string' ? assistantData.advanced_settings.length : 'not string',
      rawAdvancedSettingsPreview: typeof assistantData?.advanced_settings === 'string' ? assistantData.advanced_settings.substring(0, 200) + '...' : 'not string'
    });
    
    if (!assistantData?.advanced_settings) {
      console.log('‚ùå [VIDEO-LIBRARY] üö´ ASSISTANT SEM ADVANCED_SETTINGS');
      return null;
    }
    
    // üéØ PARSER REFOR√áADO PARA ESTRUTURA COMPLEXA ANINHADA
    let advancedSettings = assistantData.advanced_settings;
    
    console.log('üîß [VIDEO-LIBRARY] üìä ETAPA 1 - PARSING: Tipo inicial:', typeof advancedSettings);
    
    // STEP 1: Parse inicial se for string
    if (typeof advancedSettings === 'string') {
      try {
        console.log('üîß [VIDEO-LIBRARY] üìÑ Fazendo JSON.parse da string...');
        advancedSettings = JSON.parse(advancedSettings);
        console.log('‚úÖ [VIDEO-LIBRARY] üéâ String parsed para object com sucesso');
        console.log('üìä [VIDEO-LIBRARY] üìã Keys do objeto parseado:', Object.keys(advancedSettings));
      } catch (parseError) {
        console.error('‚ùå [VIDEO-LIBRARY] üí• Erro ao fazer parse da string:', parseError);
        console.error('üîß [VIDEO-LIBRARY] üìÑ String que causou erro:', assistantData.advanced_settings.substring(0, 500));
        return null;
      }
    }
    
    console.log('üîß [VIDEO-LIBRARY] ETAPA 2: Ap√≥s primeiro parse, tipo:', typeof advancedSettings);
    console.log('üîß [VIDEO-LIBRARY] ETAPA 2: Chaves dispon√≠veis:', Object.keys(advancedSettings));
    
    // STEP 2: NOVO ALGORITMO PARA ESTRUTURA ANINHADA COMPLEXA
    if (advancedSettings && typeof advancedSettings === 'object') {
      // üéØ TENTATIVA 1: Verificar se j√° tem video_library diretamente
      if (advancedSettings.video_library && Array.isArray(advancedSettings.video_library)) {
        console.log('‚úÖ [VIDEO-LIBRARY] video_library encontrada diretamente!');
      } else {
        console.log('üîç [VIDEO-LIBRARY] video_library n√£o encontrada diretamente, procurando em estrutura aninhada...');
        
        // üéØ TENTATIVA 2: Procurar em chaves num√©ricas (estrutura aninhada t√≠pica)
        let found = false;
        for (const key of Object.keys(advancedSettings)) {
          console.log(`üîç [VIDEO-LIBRARY] Verificando chave "${key}"...`);
          
          if (typeof advancedSettings[key] === 'string') {
            console.log(`üîß [VIDEO-LIBRARY] Chave "${key}" √© string, tentando parse...`);
            try {
              const nestedData = JSON.parse(advancedSettings[key]);
              console.log(`üîç [VIDEO-LIBRARY] Parse da chave "${key}" - chaves:`, Object.keys(nestedData));
              
              if (nestedData.video_library && Array.isArray(nestedData.video_library)) {
                advancedSettings = nestedData;
                console.log(`‚úÖ [VIDEO-LIBRARY] video_library encontrada na chave "${key}"!`);
                found = true;
                break;
              }
            } catch (nestedParseError) {
              console.log(`‚ö†Ô∏è [VIDEO-LIBRARY] Erro ao fazer parse da chave "${key}":`, nestedParseError.message);
            }
          } else if (typeof advancedSettings[key] === 'object' && advancedSettings[key] !== null) {
            console.log(`üîç [VIDEO-LIBRARY] Chave "${key}" √© object, verificando video_library...`);
            if (advancedSettings[key].video_library && Array.isArray(advancedSettings[key].video_library)) {
              advancedSettings = advancedSettings[key];
              console.log(`‚úÖ [VIDEO-LIBRARY] video_library encontrada no object da chave "${key}"!`);
              found = true;
              break;
            }
          }
        }
        
        if (!found) {
          console.log('üîç [VIDEO-LIBRARY] Tentando busca recursiva mais profunda...');
          // üéØ TENTATIVA 3: Busca recursiva mais profunda
          for (const key of Object.keys(advancedSettings)) {
            const value = advancedSettings[key];
            if (typeof value === 'object' && value !== null) {
              for (const subKey of Object.keys(value)) {
                if (typeof value[subKey] === 'string') {
                  try {
                    const deepNestedData = JSON.parse(value[subKey]);
                    if (deepNestedData.video_library && Array.isArray(deepNestedData.video_library)) {
                      advancedSettings = deepNestedData;
                      console.log(`‚úÖ [VIDEO-LIBRARY] video_library encontrada em ${key}.${subKey}!`);
                      found = true;
                      break;
                    }
                  } catch (error) {
                    // Silencioso para n√£o poluir logs
                  }
                }
              }
              if (found) break;
            }
          }
        }
      }
    }
    
    console.log('üîç [VIDEO-LIBRARY] Advanced settings FINAL ap√≥s todos os parses:', {
      keys: Object.keys(advancedSettings),
      hasVideoLibrary: !!advancedSettings?.video_library,
      hasAudioLibrary: !!advancedSettings?.audio_library,
      hasImageLibrary: !!advancedSettings?.image_library,
      videoLibraryLength: advancedSettings?.video_library?.length || 0,
      audioLibraryLength: advancedSettings?.audio_library?.length || 0,
      imageLibraryLength: advancedSettings?.image_library?.length || 0
    });
    
    if (!advancedSettings?.video_library) {
      console.error('‚ùå [VIDEO-LIBRARY] ‚ö†Ô∏è BIBLIOTECA DE V√çDEOS N√ÉO ENCONTRADA!', {
        assistantId,
        availableKeys: Object.keys(advancedSettings),
        hasAudioLibrary: !!advancedSettings?.audio_library,
        hasImageLibrary: !!advancedSettings?.image_library,
        totalAudioLibraryItems: advancedSettings?.audio_library?.length || 0,
        totalImageLibraryItems: advancedSettings?.image_library?.length || 0,
        message: 'Voc√™ precisa primeiro SALVAR um v√≠deo na interface do assistente!',
        instructions: [
          '1. V√° para Configura√ß√µes do Assistente',
          '2. Acesse a aba "Configura√ß√µes de V√≠deo"', 
          '3. Fa√ßa upload de um v√≠deo com trigger "teste"',
          '4. Salve as configura√ß√µes',
          '5. Teste novamente com "video teste"'
        ]
      });
      
      // TODO: Futuramente podemos auto-inicializar video_library vazia aqui
      // Por enquanto, retornamos null para for√ßar o usu√°rio a configurar
      return null;
    }
    
    const library = advancedSettings.video_library as any[];
    console.log('üìö [VIDEO-LIBRARY] Biblioteca carregada:', {
      totalVideos: library.length,
      videosDisponiveis: library.map(item => ({ 
        trigger: item.trigger, 
        name: item.name,
        format: item.format,
        hasVideoBase64: !!item.videoBase64 
      }))
    });
    
    // Busca por trigger exato (case-insensitive)
    const normalizedSearchTrigger = videoTrigger.toLowerCase().trim();
    
    console.log('üîç [VIDEO-LIBRARY] Debug matching DETALHADO:', {
      buscandoPor: normalizedSearchTrigger,
      originalInput: videoTrigger,
      triggersDisponiveis: library.map(item => ({ 
        trigger: item.trigger, 
        name: item.name,
        triggerLower: item.trigger?.toLowerCase(),
        match: item.trigger?.toLowerCase() === normalizedSearchTrigger
      }))
    });
    
    console.log('üéØ [VIDEO-LIBRARY] Fazendo busca exata...');
    const video = library.find(item => {
      const itemTrigger = item.trigger?.toLowerCase();
      const match = itemTrigger === normalizedSearchTrigger;
      console.log(`üîç [VIDEO-LIBRARY] Comparando "${itemTrigger}" === "${normalizedSearchTrigger}" = ${match}`);
      return item.trigger && match;
    });
    
    if (!video) {
      console.warn('üìö [VIDEO-LIBRARY] V√≠deo n√£o encontrado:', {
        procurandoPor: normalizedSearchTrigger,
        triggersDisponiveis: library.map(item => item.trigger)
      });
      
      // Sugerir triggers similares
      const similarTriggers = library
        .filter(item => item.trigger.toLowerCase().includes(normalizedSearchTrigger.substring(0, 3)))
        .map(item => item.trigger)
        .slice(0, 3);
      
      if (similarTriggers.length > 0) {
        console.log('üí° [VIDEO-LIBRARY] Triggers similares encontrados:', similarTriggers);
      }
      
      return null;
    }
    
    console.log('‚úÖ [VIDEO-LIBRARY] üéâ V√çDEO ENCONTRADO!');
    console.log('üìä [VIDEO-LIBRARY] üìã DADOS COMPLETOS DO V√çDEO:', {
      trigger: video.trigger,
      name: video.name,
      format: video.format,
      hasVideoBase64: !!video.videoBase64,
      hasVideoData: !!video.video_data,
      videoBase64Length: video.videoBase64?.length || 0,
      videoDataLength: video.video_data?.length || 0,
      allKeys: Object.keys(video)
    });
    
    // NORMALIZAR DADOS DO V√çDEO
    const videoBase64 = video.videoBase64 || video.video_data;
    const format = video.format || 'mp4';
    
    if (!videoBase64) {
      console.error('‚ùå [VIDEO-LIBRARY] üö´ V√çDEO SEM DADOS BASE64!');
      console.error('üîß [VIDEO-LIBRARY] üìä Estrutura do v√≠deo:', JSON.stringify(video, null, 2));
      return null;
    }
    
    console.log('‚úÖ [VIDEO-LIBRARY] üìã V√çDEO NORMALIZADO E PRONTO PARA ENVIO:', {
      trigger: video.trigger,
      format: format,
      videoBase64Length: videoBase64.length,
      videoBase64Sample: videoBase64.substring(0, 100) + '...'
    });
    
    return {
      videoBase64: videoBase64,
      format: format
    };
    
  } catch (error) {
    console.error('‚ùå [VIDEO-LIBRARY] üí• ERRO GERAL NA BUSCA:', error);
    console.error('üîß [VIDEO-LIBRARY] üìä Stack trace:', error.stack);
    return null;
  }
}

/**
 * üì§ ENVIAR V√çDEO DA BIBLIOTECA
 */
async function sendLibraryVideoMessage(instanceId: string, chatId: string, videoData: any, businessToken: string) {
  try {
    console.log('üì§ [VIDEO-SEND] üöÄ INICIANDO ENVIO DE V√çDEO DA BIBLIOTECA');
    console.log('üì§ [VIDEO-SEND] üÜî Instance ID:', instanceId);
    console.log('üì§ [VIDEO-SEND] üí¨ Chat ID:', chatId);
    console.log('üì§ [VIDEO-SEND] üîë Business Token presente:', !!businessToken);
    console.log('üì§ [VIDEO-SEND] üìä DADOS RECEBIDOS PARA ENVIO:', {
      type: typeof videoData,
      keys: Object.keys(videoData || {}),
      hasVideoBase64: !!videoData?.videoBase64,
      videoBase64Length: videoData?.videoBase64?.length || 0,
      format: videoData?.format,
      videoBase64Sample: videoData?.videoBase64?.substring(0, 100) + '...' || 'N/A'
    });

    // VALIDA√á√ïES CR√çTICAS
    if (!videoData) {
      console.error('‚ùå [VIDEO-SEND] üö´ VIDEO_DATA √â NULL/UNDEFINED');
      throw new Error('VideoData n√£o fornecido');
    }

    if (!videoData.videoBase64) {
      console.error('‚ùå [VIDEO-SEND] üö´ VIDEO_BASE64 N√ÉO ENCONTRADO');
      console.error('üîß [VIDEO-SEND] üìä Estrutura recebida:', JSON.stringify(videoData, null, 2));
      throw new Error('Video base64 n√£o encontrado');
    }

    if (!videoData.format) {
      console.error('‚ùå [VIDEO-SEND] üö´ FORMATO N√ÉO ENCONTRADO');
      console.error('üîß [VIDEO-SEND] üìä Estrutura recebida:', JSON.stringify(videoData, null, 2));
      // Usar fallback para mp4 se n√£o tiver formato
      videoData.format = 'mp4';
      console.log('üîß [VIDEO-SEND] üìã Usando formato fallback: mp4');
    }

    console.log('‚úÖ [VIDEO-SEND] üìã VALIDA√á√ïES INICIAIS PASSARAM');
    console.log('üì§ [VIDEO-SEND] üìä Base64 original length:', videoData.videoBase64.length);

    // PROCESSAR BASE64 
    let cleanBase64 = videoData.videoBase64;
    
    // Remover prefixo data URL se existir
    if (cleanBase64.startsWith('data:')) {
      const commaIndex = cleanBase64.indexOf(',');
      if (commaIndex !== -1) {
        cleanBase64 = cleanBase64.substring(commaIndex + 1);
        console.log('üîß [VIDEO-SEND] üìÑ Prefixo data: removido');
      }
    }
    
    console.log('üì§ [VIDEO-SEND] üìä Base64 limpo length:', cleanBase64.length);
    
    // CRIAR BLOB DO V√çDEO
    let videoBlob;
    try {
      console.log('üì§ [VIDEO-SEND] üîÑ Convertendo Base64 para Blob...');
      const binaryString = atob(cleanBase64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      videoBlob = new Blob([bytes], { type: `video/${videoData.format}` });
      console.log('‚úÖ [VIDEO-SEND] üì¶ BLOB CRIADO COM SUCESSO:', {
        size: videoBlob.size,
        type: videoBlob.type
      });
    } catch (blobError) {
      console.error('‚ùå [VIDEO-SEND] üí• ERRO AO CRIAR BLOB:', blobError);
      console.error('üîß [VIDEO-SEND] üìä Base64 sample (primeiros 100 chars):', cleanBase64.substring(0, 100));
      throw new Error(`Erro ao processar video base64: ${blobError.message}`);
    }

    // CRIAR ARQUIVO E FORMDATA
    const fileName = `video.${videoData.format}`;
    const mimeType = `video/${videoData.format}`;
    console.log('üì§ [VIDEO-SEND] üìÅ Preparando arquivo:', { fileName, mimeType });

    let videoFile, formData;
    try {
      videoFile = new File([videoBlob], fileName, { type: mimeType });
      console.log('‚úÖ [VIDEO-SEND] üìÅ ARQUIVO CRIADO:', {
        name: videoFile.name,
        size: videoFile.size,
        type: videoFile.type,
        lastModified: videoFile.lastModified
      });

      formData = new FormData();
      formData.append('recipient', chatId);
      formData.append('attachment', videoFile);
      formData.append('mediatype', 'video');
      formData.append('delay', '1200');
      
      // ExternalAttributes para tracking (igual ao videosender)
      const externalAttributes = {
        source: 'video_library',
        mediaType: 'video',
        fileName: fileName,
        fileSize: videoFile.size,
        timestamp: Date.now()
      };
      formData.append('externalAttributes', JSON.stringify(externalAttributes));
      
      console.log('‚úÖ [VIDEO-SEND] üìã FORMDATA PREPARADO (FORMATO CORRETO)');
      
      // LOG DETALHADO DO FORMDATA
      console.log('üì§ [VIDEO-SEND] üìä FORMDATA ENTRIES DETALHADO:');
      for (const [key, value] of formData.entries()) {
        if (key === 'file') {
          console.log(`  üóÇÔ∏è ${key}: File(name="${value.name}", size=${value.size}, type="${value.type}")`);
        } else {
          console.log(`  üìù ${key}: "${value}"`);
        }
      }
    } catch (formError) {
      console.error('‚ùå [VIDEO-SEND] üí• ERRO AO CRIAR FORMDATA:', formError);
      throw new Error(`Erro ao criar FormData: ${formError.message}`);
    }

    // ENVIAR VIA API YUMER (ENDPOINT CORRETO)
    const apiUrl = `https://api.yumer.com.br/api/v2/instance/${instanceId}/send/media-file`;
    console.log('üì§ [VIDEO-SEND] üåê FAZENDO REQUISI√á√ÉO PARA:', apiUrl);
    console.log('üì§ [VIDEO-SEND] üîë Authorization header presente:', !!businessToken);
    console.log('üì§ [VIDEO-SEND] üìã Headers que ser√£o enviados:', {
      'Authorization': businessToken ? `Bearer ${businessToken.substring(0, 20)}...` : 'MISSING',
      'Content-Type': 'multipart/form-data (autom√°tico)'
    });

    let response;
    try {
      console.log('üì§ [VIDEO-SEND] üöÄ FAZENDO REQUISI√á√ÉO HTTP...');
      const startTime = Date.now();
      
      response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${businessToken}`,
        },
        body: formData
      });
      
      const endTime = Date.now();
      console.log('üì§ [VIDEO-SEND] üìä RESPOSTA RECEBIDA:', {
        status: response.status,
        statusText: response.statusText,
        ok: response.ok,
        tempo: `${endTime - startTime}ms`,
        url: response.url,
        headers: Object.fromEntries(response.headers.entries())
      });
    } catch (fetchError) {
      console.error('‚ùå [VIDEO-SEND] üí• ERRO NA REQUISI√á√ÉO HTTP:', fetchError);
      console.error('üîß [VIDEO-SEND] üìä Detalhes do erro:', {
        name: fetchError.name,
        message: fetchError.message,
        stack: fetchError.stack
      });
      throw new Error(`Erro na requisi√ß√£o HTTP: ${fetchError.message}`);
    }

    // PROCESSAR RESPOSTA
    if (!response.ok) {
      console.error('‚ùå [VIDEO-SEND] üö´ RESPOSTA HTTP N√ÉO OK');
      let errorText = 'Erro desconhecido';
      try {
        errorText = await response.text();
        console.error('üì§ [VIDEO-SEND] üìÑ TEXTO DO ERRO DA API:', errorText);
        
        // Tentar fazer parse do JSON se poss√≠vel
        try {
          const errorJson = JSON.parse(errorText);
          console.error('üì§ [VIDEO-SEND] üìã JSON DO ERRO:', errorJson);
        } catch (jsonParseError) {
          console.log('üì§ [VIDEO-SEND] üìÑ Erro n√£o √© JSON v√°lido');
        }
      } catch (textError) {
        console.error('üì§ [VIDEO-SEND] üí• Erro ao ler texto da resposta:', textError);
      }
      throw new Error(`API retornou status ${response.status}: ${errorText}`);
    }

    // PROCESSAR RESPOSTA DE SUCESSO
    let result;
    try {
      result = await response.json();
      console.log('‚úÖ [VIDEO-SEND] üéâ V√çDEO ENVIADO COM SUCESSO!');
      console.log('üì§ [VIDEO-SEND] üìä RESULTADO COMPLETO:', JSON.stringify(result, null, 2));
      console.log('üì§ [VIDEO-SEND] üìã RESUMO DO SUCESSO:', {
        messageId: result?.messageId || result?.key?.id || result?.id || 'N/A',
        success: result?.success !== false,
        status: result?.status || 'success',
        fileName: fileName,
        fileSize: videoFile.size,
        format: videoData.format
      });
    } catch (jsonError) {
      console.error('‚ùå [VIDEO-SEND] üí• ERRO AO PARSEAR JSON DA RESPOSTA:', jsonError);
      const responseText = await response.text();
      console.log('üì§ [VIDEO-SEND] üìÑ Resposta raw (n√£o √© JSON):', responseText);
      
      // Retornar resultado baseado no status HTTP
      result = { 
        success: true, 
        rawResponse: responseText,
        status: response.status,
        statusText: response.statusText
      };
      console.log('‚úÖ [VIDEO-SEND] üéØ Assumindo sucesso baseado no status HTTP:', response.status);
    }
    
    return result;
    
  } catch (error) {
    console.error('‚ùå [VIDEO-SEND] üí• ERRO GERAL NO ENVIO DE V√çDEO:', error);
    console.error('üîß [VIDEO-SEND] üìä Stack trace completo:', error.stack);
    console.error('üîß [VIDEO-SEND] üìä Detalhes do erro:', {
      name: error.name,
      message: error.message,
      cause: error.cause,
      videoDataKeys: videoData ? Object.keys(videoData) : 'videoData is null'
    });
    throw error;
  }
}
