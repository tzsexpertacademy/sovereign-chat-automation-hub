import { useEffect, useRef } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { directMediaDownloadService } from '@/services/directMediaDownloadService';
import { aiConfigService } from '@/services/aiConfigService';

/**
 * Hook para processar √°udios automaticamente quando recebidos
 */
export const useAudioAutoProcessor = (clientId: string) => {
  const processingRef = useRef<Set<string>>(new Set());

  useEffect(() => {
    if (!clientId) {
      console.log('üéµ [AUDIO-AUTO] ‚ùå ClientId n√£o fornecido - hook n√£o ativo');
      return;
    }

    console.log('üéµ [AUDIO-AUTO] ‚úÖ INICIANDO processamento autom√°tico de √°udios para cliente:', clientId);
    console.log('üéµ [AUDIO-AUTO] üîß Hook ativo e configurado corretamente');

    // Listener para novas mensagens de √°udio
    const channel = supabase
      .channel('audio_auto_processor')
      .on(
        'postgres_changes',
        {
          event: 'INSERT',
          schema: 'public',
          table: 'ticket_messages',
          filter: `message_type=in.(audio,ptt)`
        },
        async (payload) => {
          const newMessage = payload.new as any;
          
          console.log('üéµ [AUDIO-AUTO] üì® NOVA MENSAGEM DETECTADA:', {
            messageId: newMessage.message_id,
            messageType: newMessage.message_type,
            fromMe: newMessage.from_me,
            isAiResponse: newMessage.is_ai_response,
            hasMediaKey: !!newMessage.media_key,
            processingStatus: newMessage.processing_status
          });
          
          // Verificar se √© uma mensagem do cliente (N√ÉO from_me e N√ÉO is_ai_response)
          if (newMessage.from_me === true || newMessage.is_ai_response === true) {
            console.log('üéµ [AUDIO-AUTO] ‚è≠Ô∏è Ignorando √°udio do assistente ou enviado pelo sistema');
            return;
          }

          // Verificar se j√° est√° sendo processado
          if (processingRef.current.has(newMessage.message_id)) {
            console.log('üéµ [AUDIO-AUTO] √Åudio j√° em processamento:', newMessage.message_id);
            return;
          }

          // Buscar ticket para verificar se √© do cliente correto
          const { data: ticket } = await supabase
            .from('conversation_tickets')
            .select('client_id, chat_id, instance_id')
            .eq('id', newMessage.ticket_id)
            .single();

          if (!ticket || ticket.client_id !== clientId) {
            console.log('üéµ [AUDIO-AUTO] ‚ö†Ô∏è Ticket n√£o pertence ao cliente atual:', {
              ticketClientId: ticket?.client_id,
              currentClientId: clientId
            });
            return;
          }

          // Verificar se j√° foi processado
          if (newMessage.processing_status === 'completed' || newMessage.processing_status === 'failed') {
            console.log('üéµ [AUDIO-AUTO] ‚è≠Ô∏è √Åudio j√° processado:', newMessage.processing_status);
            return;
          }

          console.log('üéµ [AUDIO-AUTO] üéØ NOVO √ÅUDIO V√ÅLIDO PARA PROCESSAMENTO:', {
            messageId: newMessage.message_id,
            ticketId: newMessage.ticket_id,
            chatId: ticket.chat_id,
            processingStatus: newMessage.processing_status
          });

          // Marcar como em processamento
          processingRef.current.add(newMessage.message_id);

          try {
            await processAudioMessage(newMessage, ticket, clientId);
          } finally {
            // Remover do set de processamento
            processingRef.current.delete(newMessage.message_id);
          }
        }
      )
      .subscribe();

    return () => {
      console.log('üéµ [AUDIO-AUTO] Parando processamento autom√°tico de √°udios');
      supabase.removeChannel(channel);
    };
  }, [clientId]);

  /**
   * Processar mensagem de √°udio automaticamente - VERS√ÉO SIMPLIFICADA
   */
  const processAudioMessage = async (message: any, ticket: any, clientId: string) => {
    try {
      console.log('üéµ [AUDIO-AUTO] ===== PROCESSANDO √ÅUDIO AUTOMATICAMENTE =====');
      console.log('üéµ [AUDIO-AUTO] üìã Dados completos da mensagem:', {
        messageId: message.message_id,
        hasMediaKey: !!message.media_key,
        hasMediaUrl: !!message.media_url,
        hasAudioBase64: !!message.audio_base64,
        mediaKeyType: typeof message.media_key,
        mediaUrlPreview: message.media_url?.substring(0, 100),
        mimetype: message.media_mime_type,
        directPath: message.direct_path,
        processingStatus: message.processing_status
      });

      // Marcar como "processing" imediatamente
      await supabase
        .from('ticket_messages')
        .update({ processing_status: 'processing' })
        .eq('message_id', message.message_id);

      console.log('üîÑ [AUDIO-AUTO] Status atualizado para "processing"');

      let audioBase64 = '';

      // 1. ESTRAT√âGIA SIMPLIFICADA: Priorizar media_key para descriptografia
      if (message.media_key && message.media_url) {
        console.log('üîê [AUDIO-AUTO] üîë √Åudio criptografado detectado - iniciando descriptografia');
        console.log('üîê [AUDIO-AUTO] üìä Par√¢metros de descriptografia:', {
          instanceId: ticket.instance_id,
          mediaKeyLength: typeof message.media_key === 'string' ? message.media_key.length : 'object',
          mediaUrlDomain: new URL(message.media_url).hostname,
          directPath: message.direct_path,
          mimetype: message.media_mime_type || 'audio/ogg'
        });
        
        const downloadResult = await directMediaDownloadService.downloadMedia(
          ticket.instance_id,
          message.media_url,
          message.media_key,
          message.direct_path,
          message.media_mime_type || 'audio/ogg',
          'audio'
        );

        if (downloadResult.success && downloadResult.mediaUrl) {
          console.log('‚úÖ [AUDIO-AUTO] üéâ √Åudio descriptografado com sucesso pelo servidor');
          console.log('‚úÖ [AUDIO-AUTO] üìÅ URL descriptografada:', downloadResult.mediaUrl.substring(0, 50) + '...');
          
          // Converter blob URL para base64 com tratamento robusto
          try {
            console.log('üîÑ [AUDIO-AUTO] Convertendo blob URL para base64...');
            const response = await fetch(downloadResult.mediaUrl);
            
            if (!response.ok) {
              throw new Error(`Falha ao fetch blob: ${response.status}`);
            }
            
            const blob = await response.blob();
            console.log('üì¶ [AUDIO-AUTO] Blob obtido:', {
              size: blob.size,
              type: blob.type
            });
            
            if (blob.size === 0) {
              throw new Error('Blob vazio recebido');
            }
            
            const arrayBuffer = await blob.arrayBuffer();
            audioBase64 = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
            console.log('‚úÖ [AUDIO-AUTO] üéØ Base64 gerado:', {
              length: audioBase64.length,
              preview: audioBase64.substring(0, 50) + '...'
            });
          } catch (convertError) {
            console.error('‚ùå [AUDIO-AUTO] Erro na convers√£o blob->base64:', convertError);
            throw new Error(`Falha na convers√£o: ${convertError.message}`);
          }
        } else {
          console.error('‚ùå [AUDIO-AUTO] üí• Falha na descriptografia:', downloadResult.error);
          throw new Error(downloadResult.error || 'Servi√ßo de descriptografia falhou');
        }
      } else if (message.audio_base64) {
        console.log('üìÅ [AUDIO-AUTO] Usando √°udio base64 da mensagem');
        audioBase64 = message.audio_base64;
      } else {
        console.error('‚ùå [AUDIO-AUTO] Nenhum dado de √°udio dispon√≠vel');
        throw new Error('Nenhum dado de √°udio dispon√≠vel para transcri√ß√£o');
      }

      // 2. Validar se temos √°udio para processar
      if (!audioBase64 || audioBase64.length < 100) {
        console.error('‚ùå [AUDIO-AUTO] Dados de √°udio inv√°lidos:', {
          hasAudioBase64: !!audioBase64,
          length: audioBase64?.length || 0
        });
        throw new Error('Dados de √°udio inv√°lidos ou muito pequenos');
      }

      // 3. Buscar OpenAI API key do cliente
      console.log('üîë [AUDIO-AUTO] Buscando configura√ß√£o IA do cliente...');
      const aiConfig = await aiConfigService.getClientConfig(clientId);

      if (!aiConfig?.openai_api_key) {
        console.error('‚ùå [AUDIO-AUTO] API key da OpenAI n√£o encontrada para cliente:', clientId);
        throw new Error('API key da OpenAI n√£o configurada para este cliente');
      }

      console.log('‚úÖ [AUDIO-AUTO] API key encontrada, length:', aiConfig.openai_api_key.length);

      // 4. Chamar edge function speech-to-text com logs detalhados
      console.log('üé§ [AUDIO-AUTO] üöÄ Invocando speech-to-text edge function...');
      console.log('üé§ [AUDIO-AUTO] üìã Par√¢metros da chamada:', {
        hasAudio: !!audioBase64,
        audioLength: audioBase64.length,
        hasApiKey: !!aiConfig.openai_api_key,
        messageId: message.message_id,
        audioPreview: audioBase64.substring(0, 50) + '...'
      });

      const { data: transcriptionResult, error: transcriptionError } = await supabase.functions.invoke('speech-to-text', {
        body: {
          audio: audioBase64,
          openaiApiKey: aiConfig.openai_api_key,
          messageId: message.message_id
        }
      });

      console.log('üé§ [AUDIO-AUTO] üì• Resposta da edge function:', {
        hasData: !!transcriptionResult,
        hasError: !!transcriptionError,
        dataPreview: transcriptionResult ? Object.keys(transcriptionResult) : 'N/A'
      });

      if (transcriptionError) {
        console.error('‚ùå [AUDIO-AUTO] üí• Erro na edge function speech-to-text:', transcriptionError);
        throw new Error(`Edge function falhou: ${transcriptionError.message || 'Erro desconhecido'}`);
      }

      if (!transcriptionResult) {
        console.error('‚ùå [AUDIO-AUTO] Edge function retornou dados vazios');
        throw new Error('Edge function speech-to-text retornou resposta vazia');
      }

      const transcription = transcriptionResult?.text || '';
      console.log('‚úÖ [AUDIO-AUTO] üéØ Transcri√ß√£o recebida:', {
        hasText: !!transcription,
        length: transcription.length,
        preview: transcription.substring(0, 100) + (transcription.length > 100 ? '...' : ''),
        language: transcriptionResult?.language,
        success: transcriptionResult?.success
      });

      // 5. Salvar transcri√ß√£o no banco com valida√ß√£o
      if (transcription && transcription.trim().length > 0) {
        console.log('üíæ [AUDIO-AUTO] Salvando transcri√ß√£o no banco...');
        
        const { error: updateError } = await supabase
          .from('ticket_messages')
          .update({
            media_transcription: transcription.trim(),
            processing_status: 'completed',
            content: `üéµ √Åudio - Transcri√ß√£o: ${transcription.trim()}`
          })
          .eq('message_id', message.message_id);

        if (updateError) {
          console.error('‚ùå [AUDIO-AUTO] Erro ao salvar transcri√ß√£o:', updateError);
          throw new Error(`Falha ao salvar transcri√ß√£o: ${updateError.message}`);
        }

        console.log('‚úÖ [AUDIO-AUTO] üíæ Transcri√ß√£o salva com sucesso no banco');

        // 6. Processar com assistente IA automaticamente
        console.log('ü§ñ [AUDIO-AUTO] üöÄ Enviando transcri√ß√£o para processamento IA...');
        
        const { error: aiError } = await supabase.functions.invoke('ai-assistant-process', {
          body: {
            ticketId: message.ticket_id,
            messages: [{
              content: transcription.trim(),
              messageId: message.message_id,
              timestamp: new Date().toISOString(),
              customerName: message.sender_name || 'Cliente',
              phoneNumber: ticket.chat_id.split('@')[0]
            }],
            context: {
              chatId: ticket.chat_id,
              customerName: message.sender_name || 'Cliente',
              phoneNumber: ticket.chat_id.split('@')[0],
              clientMessage: true
            }
          }
        });

        if (aiError) {
          console.error('‚ùå [AUDIO-AUTO] Erro ao processar com IA:', aiError);
          // N√£o falhar o processo por erro na IA - transcri√ß√£o j√° foi salva
        } else {
          console.log('‚úÖ [AUDIO-AUTO] ü§ñ Transcri√ß√£o enviada para IA com sucesso');
        }
      } else {
        console.log('‚ö†Ô∏è [AUDIO-AUTO] ‚ùå Transcri√ß√£o vazia ou inv√°lida');
        
        const { error: updateError } = await supabase
          .from('ticket_messages')
          .update({
            processing_status: 'failed',
            media_transcription: '[Transcri√ß√£o vazia - √°udio n√£o p√¥de ser processado]',
            content: `üéµ √Åudio - [Falha na transcri√ß√£o]`
          })
          .eq('message_id', message.message_id);

        if (updateError) {
          console.error('‚ùå [AUDIO-AUTO] Erro ao marcar falha:', updateError);
        }
        
        throw new Error('Transcri√ß√£o resultou em texto vazio');
      }

    } catch (error) {
      console.error('‚ùå [AUDIO-AUTO] üí• ERRO CR√çTICO no processamento autom√°tico:', error);
      console.error('‚ùå [AUDIO-AUTO] Stack trace:', error.stack);
      
      // Marcar como erro no banco com detalhes
      const { error: updateError } = await supabase
        .from('ticket_messages')
        .update({
          processing_status: 'failed',
          media_transcription: `[Erro no processamento]: ${error.message}`,
          content: `üéµ √Åudio - [Erro: ${error.message}]`
        })
        .eq('message_id', message.message_id);

      if (updateError) {
        console.error('‚ùå [AUDIO-AUTO] Erro ao salvar status de falha:', updateError);
      }
      
      // Re-throw para debugging se necess√°rio
      console.error('‚ùå [AUDIO-AUTO] Processamento falhou para mensagem:', message.message_id);
    }
  };

  return {};
};